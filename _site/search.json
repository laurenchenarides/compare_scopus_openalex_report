[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Federal agencies like the USDA track how their datasets are referenced in research papers and disseminate data usage statistics through platforms like DemocratizingData.ai and NASS’s 5’s Data Usage Dashboard. This report presents a methodology for comparing citation databases as potential data sources for identifying dataset mentions within research papers, using Scopus and OpenAlex as a test case. The methods described can be applied to evaluate other citation databases such as Web of Science, Crossref, Dimensions, and Microsoft Academic, to name a few.\nCitation databases track academic research output. Different databases curate content (i.e., research output) in different ways - some focus on peer-reviewed journals while others include preprints and technical reports. Tracking dataset usage requires developing methods that scan publication text for dataset mentions. The accuracy of dataset tracking depends on the scope of research output we can access and analyze. Not to mention, dataset tracking requires reliable citation data from citation databases.\nThe two citation databases we are comparing are Elsevier’s Scopus and OpenAlex. Scopus charges for access to its citation database. It focuses on peer-reviewed literature and provides metadata about authors, institutions, and citations for academic journals. OpenAlex, an open-source platform, offers free metadata access. It covers both traditional academic publications and other research outputs like preprints and technical reports.\nOur methodology provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. We developed procedures for:\n\nDeduplicating author records\nStandardizing institution names\nCross-referencing publications between datasets\nAnalyzing research themes and institutional representation\n\nBeyond platform comparison, this methodology examines inclusivity in research coverage, particularly representation of MSIs. This component helps identify potential gaps in dataset accessibility and adoption across different types of research institutions.\nOur comparison of Scopus and OpenAlex found:\n\nAfter deduplication, the number of distinct authors decreased by XX% in Scopus and XX% in OpenAlex, indicating significant duplicate entries in the raw data\nInstitutional coverage was broader in XX, with XX% more institutions represented compared to XX\nAnalysis revealed XX major themes in USDA dataset usage, with ?? and ?? being the most prominent\nMinority-Serving Institutions (MSIs) represented only XX% of institutional users, highlighting opportunities for broader engagement\n\nThe methodology produced these reusable components:\n\nCode repository for data cleaning and standardization\nCleaned author tables with disambiguated names and institutional affiliations\nStandardized institution tables using IPEDS identifiers\nCrosswalk table structure linking Scopus and OpenAlex publication records, authors, and institutions\nData schema documentation [Last updated: January 3, 2025]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]