[
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The project workflow outlines the steps involved to evaluate how different citation databases track USDA dataset mentions in research papers. In searching for dataset mentions, the goal is to identify a set of publications that can be compared across the citation database test cases.\n\nThe process of deriving the list of publications from a citation database consists of four steps. Each step produces an output which is used as the input for the following step:\n\n\n\nIdentify USDA datasets that will be searched for and tracked.\nCollect official dataset names along with common abbreviations, acronyms, and alternative references used.\n\nResult: A structured list of dataset names and aliases.\n\n\n\n\nConduct searches across citation databases using multiple methods:\n\nFull-Text (String) Search: Scan entire articles for relevant dataset names.\nReference Search: Identify dataset citations within publication references.\nMachine Learning Models: Apply Kaggle competition models trained to detect dataset mentions.\n\n\nNote: In cases where full-text search is not supported by the citation database API (e.g., Scopus), an initial seed corpus of publications was collected separately to train machine learning models. Refer to “Creating a Seed Corpus” for more details.\nResult: Publication dataset for each data asset across each citation database.\n\n\n\n\nPre-process and clean publication metadata generated from each citation database.\nStandardize journal, institution, and author names.\nDeduplicate records.\n\nResult: Cleaned publication metadata, removed of duplicates, inconsistencies, and missing information.\n\n\n\n\nCompare dataset coverage across Scopus, OpenAlex, and Dimensions.\nApply fuzzy matching techniques to identify overlapping and unique dataset mentions.\nAnalyze differences in journal coverage, citation patterns, and author affiliations.\n\nResult: A set of statistics used to evaluate dataset tracking accuracy.",
    "crumbs": [
      "Appendices",
      "Project Workflow"
    ]
  },
  {
    "objectID": "workflow.html#define-scope-of-data-assets-to-be-searched",
    "href": "workflow.html#define-scope-of-data-assets-to-be-searched",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Identify USDA datasets that will be searched for and tracked.\nCollect official dataset names along with common abbreviations, acronyms, and alternative references used.\n\nResult: A structured list of dataset names and aliases.",
    "crumbs": [
      "Appendices",
      "Project Workflow"
    ]
  },
  {
    "objectID": "workflow.html#extract-dataset-mentions-from-publications",
    "href": "workflow.html#extract-dataset-mentions-from-publications",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Conduct searches across citation databases using multiple methods:\n\nFull-Text (String) Search: Scan entire articles for relevant dataset names.\nReference Search: Identify dataset citations within publication references.\nMachine Learning Models: Apply Kaggle competition models trained to detect dataset mentions.\n\n\nNote: In cases where full-text search is not supported by the citation database API (e.g., Scopus), an initial seed corpus of publications was collected separately to train machine learning models. Refer to “Creating a Seed Corpus” for more details.\nResult: Publication dataset for each data asset across each citation database.",
    "crumbs": [
      "Appendices",
      "Project Workflow"
    ]
  },
  {
    "objectID": "workflow.html#pre-process-and-clean-publication-datasets",
    "href": "workflow.html#pre-process-and-clean-publication-datasets",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Pre-process and clean publication metadata generated from each citation database.\nStandardize journal, institution, and author names.\nDeduplicate records.\n\nResult: Cleaned publication metadata, removed of duplicates, inconsistencies, and missing information.",
    "crumbs": [
      "Appendices",
      "Project Workflow"
    ]
  },
  {
    "objectID": "workflow.html#compare-across-citation-databases",
    "href": "workflow.html#compare-across-citation-databases",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Compare dataset coverage across Scopus, OpenAlex, and Dimensions.\nApply fuzzy matching techniques to identify overlapping and unique dataset mentions.\nAnalyze differences in journal coverage, citation patterns, and author affiliations.\n\nResult: A set of statistics used to evaluate dataset tracking accuracy.",
    "crumbs": [
      "Appendices",
      "Project Workflow"
    ]
  },
  {
    "objectID": "workflow/step03/04scopus.html",
    "href": "workflow/step03/04scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON"
  },
  {
    "objectID": "workflow/step03/04scopus.html#scopus",
    "href": "workflow/step03/04scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "To analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON"
  },
  {
    "objectID": "workflow/step02_02/02scopus.html",
    "href": "workflow/step02_02/02scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later."
  },
  {
    "objectID": "workflow/step02_02/02scopus.html#scopus",
    "href": "workflow/step02_02/02scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later."
  },
  {
    "objectID": "workflow/step02_02/02dimensions.html",
    "href": "workflow/step02_02/02dimensions.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The seed corpus approach was only applied to Scopus."
  },
  {
    "objectID": "workflow/step02_02/02dimensions.html#dimensions",
    "href": "workflow/step02_02/02dimensions.html#dimensions",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The seed corpus approach was only applied to Scopus."
  },
  {
    "objectID": "workflow/step02_01/03scopus.html",
    "href": "workflow/step02_01/03scopus.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases."
  },
  {
    "objectID": "workflow/step02_01/03scopus.html#scopus",
    "href": "workflow/step02_01/03scopus.html#scopus",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "The search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases."
  },
  {
    "objectID": "workflow/step02_01/03scopus.html#footnotes",
    "href": "workflow/step02_01/03scopus.html#footnotes",
    "title": "Citation Database Assessment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExplanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.↩︎\nExplanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.↩︎"
  },
  {
    "objectID": "workflow/step02_01/03dimensions.html",
    "href": "workflow/step02_01/03dimensions.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Coming Soon"
  },
  {
    "objectID": "workflow/step02_01/03dimensions.html#dimensions",
    "href": "workflow/step02_01/03dimensions.html#dimensions",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Coming Soon"
  },
  {
    "objectID": "workflow/results/compare_pub_data.html",
    "href": "workflow/results/compare_pub_data.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to develop statistics that measure dataset tracking accuracy.\n\n\n\n\nContinuing with our case study, we use the datasets produced in Step 4 to produce counts of the number of journals with Ag Census publications that:\n\nonly appear in Scopus,\nonly appear in OpenAlex, or\nappear in both.\n\nFor journals that contain Ag Census data in both citation databases, we summarize the coverage of publications that appear in both Scopus and OpenAlex.\nThen, we investigate discrepancies based on factors like missing identifiers, mismatched journal information (ISSNs), and additional publications accessed through OpenAlex’s API.\nAdd here: What are the steps in producing Table AA\n\nScopusOpenAlex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section presents results after matching (which type varies – deterministic vs fuzzy)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of Matching Methods\n\n\n\n\n\n\nRule-based matching for exact matches\nProbabilistic matching for handling variations\nMachine learning methods for complex cases\n\n\n\n\nTable 1: Summary of Methods\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nConsiderations\nExample\nPros\nCons\n\n\n\n\nSearching for dataset names within Scopus\n\n\n\n\n\n\nSearching for dataset names within OpenAlex\n“Location” field set to “journal”\n\n\n\n\n\nDisambiguation of authors\n\n\n\n\n\n\nDisambiguation of institutions\n\n\n\n\n\n\nStandardization of institutions\n\n\n\n\n\n\nSearching based on the frequency of dataset appearance in journals\n\n\n\n\n\n\nMORE . . .\n\n\n\n\n\n\nFiltering on keywords to determine themes\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll appendices referenced throughout the report are located on this page.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 04: Compare Results"
    ]
  },
  {
    "objectID": "workflow/results/compare_pub_data.html#sec-matching",
    "href": "workflow/results/compare_pub_data.html#sec-matching",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to develop statistics that measure dataset tracking accuracy.\n\n\n\n\nContinuing with our case study, we use the datasets produced in Step 4 to produce counts of the number of journals with Ag Census publications that:\n\nonly appear in Scopus,\nonly appear in OpenAlex, or\nappear in both.\n\nFor journals that contain Ag Census data in both citation databases, we summarize the coverage of publications that appear in both Scopus and OpenAlex.\nThen, we investigate discrepancies based on factors like missing identifiers, mismatched journal information (ISSNs), and additional publications accessed through OpenAlex’s API.\nAdd here: What are the steps in producing Table AA\n\nScopusOpenAlex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis section presents results after matching (which type varies – deterministic vs fuzzy)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary of Matching Methods\n\n\n\n\n\n\nRule-based matching for exact matches\nProbabilistic matching for handling variations\nMachine learning methods for complex cases\n\n\n\n\nTable 1: Summary of Methods\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\nConsiderations\nExample\nPros\nCons\n\n\n\n\nSearching for dataset names within Scopus\n\n\n\n\n\n\nSearching for dataset names within OpenAlex\n“Location” field set to “journal”\n\n\n\n\n\nDisambiguation of authors\n\n\n\n\n\n\nDisambiguation of institutions\n\n\n\n\n\n\nStandardization of institutions\n\n\n\n\n\n\nSearching based on the frequency of dataset appearance in journals\n\n\n\n\n\n\nMORE . . .\n\n\n\n\n\n\nFiltering on keywords to determine themes\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll appendices referenced throughout the report are located on this page.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 04: Compare Results"
    ]
  },
  {
    "objectID": "terminology.html",
    "href": "terminology.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Terminology\nCitation databases form the foundation of modern research tracking and analysis. Digital repositories, like the test cases featured in this report, systematically catalog scholarly publications and their references to each other (De Bellis, 2009). Citation databases differ in their approaches to curating and maintaining this information. Some focus exclusively on peer-reviewed journal articles with strict inclusion criteria, while others index a broader range of research outputs including preprints, technical reports, and conference proceedings (Martín-Martín et al., 2021; Mongeon & Paul-Hus, 2016). These curation approaches affect how comprehensively each database captures research impact (Visser et al., 2021).\nUnderstanding how these databases work requires familiarity with bibliometrics - the statistical analysis of published works and their impact (Broadus, 1987). Bibliometric analysis examines patterns in publication, citation networks, and research influence (Hood & Wilson, 2001). The field emerged from early citation indices, which mapped relationships between papers through their references (Garfield, 1955).\nFor tracking USDA dataset usage, these concepts directly apply. Accurate tracking of dataset usage in scientific literature serves multiple purposes. For federal agencies like the USDA, it helps monitor the return on public data investments, find gaps in dataset use, plan future data collection, and support evidence-based policy decisions. This tracking requires reliable citation data from citation databases. Unlike standard citations, researchers often reference datasets within the text of their publications rather than citing them formally. This makes tracking dataset usage more complex.\nTo solve this tracking challenge, methods have been developed that scan publication text for dataset mentions (Lane et al., 2022). The scope and accuracy of our dataset tracking depends on what publications we can access and analyze. Because different databases curate content in different ways, it creates variation in what dataset mentions they capture and their frequency. Variations in content across sources affect our ability to accurately track dataset impact and adoption. The DemocratizingData.ai platform, for example, uses bibliometric data to monitor these dataset usage patterns, helping USDA understand how its data supports research. By comparing how different citation databases track this information, we can better understand their strengths and limitations for monitoring research impact.\n\n\n\n\n\n\n\n\n1 References\n\nBroadus, R. N. (1987). Toward a definition of “bibliometrics.” Scientometrics, 12, 373–379. https://doi.org/10.1007/bf02016680\n\n\nDe Bellis, N. (2009). Bibliometrics and citation analysis: From the science citation index to cybermetrics. Scarecrow Press. https://doi.org/10.1002/asi.21181\n\n\nGarfield, E. (1955). Citation indexes for science: A new dimension in documentation through association of ideas. Science, 122(3159), 108–111. https://doi.org/10.1126/science.122.3159.108\n\n\nHood, W. W., & Wilson, C. S. (2001). The literature of bibliometrics, scientometrics, and informetrics. Scientometrics, 52, 291–314. https://doi.org/10.1023/A:1017919924342\n\n\nLane, J., Gimeno, E., Levitskaya, E., Zhang, Z., & Zigoni, A. (2022). Data inventories for the modern age? Using data science to open government data. Harvard Data Science Review, 4(2). https://doi.org/10.1162/99608f92.8a3f2336\n\n\nMartín-Martín, A., Thelwall, M., Orduna-Malea, E., & Delgado López-Cózar, E. (2021). Google scholar, microsoft academic, scopus, dimensions, web of science, and OpenCitations’ COCI: A multidisciplinary comparison of coverage via citations. Scientometrics, 126(1), 871–906. https://doi.org/10.1007/s11192-020-03690-4\n\n\nMongeon, P., & Paul-Hus, A. (2016). The journal coverage of web of science and scopus: A comparative analysis. Scientometrics, 106, 213–228. https://doi.org/10.1007/s11192-015-1765-5\n\n\nVisser, M., Van Eck, N. J., & Waltman, L. (2021). Large-scale comparison of bibliographic data sources: Scopus, web of science, dimensions, crossref, and microsoft academic. Quantitative Science Studies, 2(1), 20–41. https://doi.org/10.1162/qss_a_00112",
    "crumbs": [
      "Appendices",
      "Terminology"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Tracking how federal datasets are used in academic research has been a priority for agencies such as the U.S. Department of Agriculture (USDA). The DemocratizingData.ai platform was created to support this effort by reporting on dataset usage through citation analysis. The platform was developed to ingest publication metadata from Scopus, a proprietary citation database, to identify and count publications that reference USDA datasets. Scopus offers reliable metadata and a structured indexing system, bu it is costly to access and does not fully align with goals around open science and public transparency.\nAs interest in open-access infrastructure has grown, OpenAlex, a free and open-source citation database developed by OurResearch, has emerged as a potential alternative. OpenAlex claims broad coverage of research outputs, including journal articles, preprints, conference proceedings, and reports. Replacing Scopus with OpenAlex could lower operational costs for federal agencies and align with broader efforts to promote open data ecosystems. However, transitioning platforms raises important questions about data reliability, coverage completeness, and potential trade-offs in representation.\nTo support an informed decision about this transition, a systematic comparison was conducted across three citation databases—Scopus, OpenAlex, and Dimensions—to assess their relative strengths and weaknesses for tracking dataset mentions in agricultural and food systems research. Dimensions, a third database developed by Digital Science, offers a hybrid model combining free and subscription-based access and was included to provide a broader benchmark across commercial and open platforms.\nInitial comparisons between Scopus and OpenAlex revealed unexpected differences in coverage, with notable gaps in publication indexing and metadata quality. These patterns suggest that simply substituting one citation source for another could lead to incomplete or biased tracking of dataset usage, potentially affecting public reporting and research visibility. This project responds to those concerns by developing a structured, reproducible methodology for evaluating database coverage across multiple dimensions: publication metadata, journal inclusion, dataset topic area, institutional affiliation, and authorship.\n\n\nThe objective of this project is to assess whether open-access citation databases, such as OpenAlex, can serve as viable alternatives to proprietary platforms like Scopus for tracking the use of USDA datasets in academic research. To inform this decision, we compare the coverage, structure, and metadata quality of three citation databases—Scopus, OpenAlex, and Dimensions—focusing on their ability to support consistent and transparent dataset usage metrics across the research landscape.\n\n\n\n\nEvaluate differences in publication coverage across citation databases. Measure the extent to which Scopus, OpenAlex, and Dimensions capture research publications that reference USDA datasets. Identify how publication inclusion varies across platforms.\nCompare journal indexing and scope. Compare the journals indexed by each database and examine how differences in journal coverage influence visibility of dataset-linked research.\nAnalyze topic coverage. Examine the research areas where USDA datasets are mentioned. Identify patterns in topic classification and assess how different citation databases support subject-level tracking of dataset usage.\nExamine institutional representation. Evaluate how each platform captures and standardizes institutional affiliations. Pay particular attention to differences in coverage for Minority-Serving Institutions (MSIs), land-grant universities, and other public or underrepresented institutions.\nEvaluate author representation. Compare how author names are recorded across platforms, including the completeness of author metadata and potential implications for attribution and visibility.\nDevelop a reproducible methodology for cross-platform comparison. Create a generalizable workflow for comparing citation databases, including steps for record linkage, deduplication, author and institution standardization, and identification of dataset mentions.\n\nThese aims guide the development of a methodology for comparing citation databases, focusing on four areas:\n\nPublication tracking:\n\n\nComparing how each platform captures publications within indexed journals\n\n\nJournal coverage:\n\n\nDetermining which journals each platform indexes\n\n\nTopic scope:\n\n\nEvaluating the research areas of publications that cite USDA datasets\n\n\nInstitution recognition:\n\n\nDetermining how each platform records institutional information\n\nThe scope of work includes comparing publication coverage across Scopus, OpenAlex, and Dimensions that mention select USDA datasets. This inclusion provides a comprehensive assessment of citation databases, particularly in evaluating dataset coverage across both proprietary and open-access platforms. For more information on each citation database, refer to this Appendix. The methodology described in this report provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. It also examines variations in dataset usage across different types of research institutions. These methods can be applied to other citation databases as alternatives to current data sources.",
    "crumbs": [
      "Project Background"
    ]
  },
  {
    "objectID": "index.html#project-objective",
    "href": "index.html#project-objective",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The objective of this project is to assess whether open-access citation databases, such as OpenAlex, can serve as viable alternatives to proprietary platforms like Scopus for tracking the use of USDA datasets in academic research. To inform this decision, we compare the coverage, structure, and metadata quality of three citation databases—Scopus, OpenAlex, and Dimensions—focusing on their ability to support consistent and transparent dataset usage metrics across the research landscape.",
    "crumbs": [
      "Project Background"
    ]
  },
  {
    "objectID": "index.html#specific-aims",
    "href": "index.html#specific-aims",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Evaluate differences in publication coverage across citation databases. Measure the extent to which Scopus, OpenAlex, and Dimensions capture research publications that reference USDA datasets. Identify how publication inclusion varies across platforms.\nCompare journal indexing and scope. Compare the journals indexed by each database and examine how differences in journal coverage influence visibility of dataset-linked research.\nAnalyze topic coverage. Examine the research areas where USDA datasets are mentioned. Identify patterns in topic classification and assess how different citation databases support subject-level tracking of dataset usage.\nExamine institutional representation. Evaluate how each platform captures and standardizes institutional affiliations. Pay particular attention to differences in coverage for Minority-Serving Institutions (MSIs), land-grant universities, and other public or underrepresented institutions.\nEvaluate author representation. Compare how author names are recorded across platforms, including the completeness of author metadata and potential implications for attribution and visibility.\nDevelop a reproducible methodology for cross-platform comparison. Create a generalizable workflow for comparing citation databases, including steps for record linkage, deduplication, author and institution standardization, and identification of dataset mentions.\n\nThese aims guide the development of a methodology for comparing citation databases, focusing on four areas:\n\nPublication tracking:\n\n\nComparing how each platform captures publications within indexed journals\n\n\nJournal coverage:\n\n\nDetermining which journals each platform indexes\n\n\nTopic scope:\n\n\nEvaluating the research areas of publications that cite USDA datasets\n\n\nInstitution recognition:\n\n\nDetermining how each platform records institutional information\n\nThe scope of work includes comparing publication coverage across Scopus, OpenAlex, and Dimensions that mention select USDA datasets. This inclusion provides a comprehensive assessment of citation databases, particularly in evaluating dataset coverage across both proprietary and open-access platforms. For more information on each citation database, refer to this Appendix. The methodology described in this report provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. It also examines variations in dataset usage across different types of research institutions. These methods can be applied to other citation databases as alternatives to current data sources.",
    "crumbs": [
      "Project Background"
    ]
  },
  {
    "objectID": "conclusions.html#expanding-dataset-usage",
    "href": "conclusions.html#expanding-dataset-usage",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Expanding Dataset Usage",
    "text": "Expanding Dataset Usage\nThis report analyzes USDA dataset usage patterns across both platforms and recommends specific strategies for expanding dataset use in underrepresented research communities.\nGiven the small percentage of MSI’s represented in our institutional analysis, it is evident that user engagement is central to increasing usage rates of the datasets, regardless of citation database.",
    "crumbs": [
      "Study Limitations"
    ]
  },
  {
    "objectID": "conclusions.html#next-steps",
    "href": "conclusions.html#next-steps",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Next Steps",
    "text": "Next Steps",
    "crumbs": [
      "Study Limitations"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html",
    "href": "appendices/app_scopus.html",
    "title": "Scopus Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html#sec-app-scopus",
    "href": "appendices/app_scopus.html#sec-app-scopus",
    "title": "Scopus Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html#data-dictionary",
    "href": "appendices/app_scopus.html#data-dictionary",
    "title": "Scopus Data Dictionary",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\n\n\n\n\n\nDownload Scopus Source Files\n\n\n\nYou can download the source files from this link.\n\n\n\npublication.csv (Primary table)\n\nDescription: Central table with metadata about publications.\nColumns:\n\nid: Unique publication identifier\ntitle: Publication title\ndoi: Digital Object Identifier\nyear, month: Date of publication\ncitation_count, pub_type: Additional metadata\n\n\n\n\ndataset_alias.csv\n\nDescription: Lists dataset aliases (alternate names).\nColumns:\n\nalias_id: Unique alias identifier\nparent_alias_id: Primary alias identifier (if alias_id = parent_alias_id, it’s primary)\nalias: Name of the alias\n\nHow to use:\n\nIdentify primary aliases where alias_id = parent_alias_id\nFind all aliases by filtering on parent_alias_id\n\n\n\n\ndyad.csv\n\nDescription: Links publications (publication.csv) and dataset aliases (dataset_alias.csv).\nColumns:\n\nid: Unique identifier for each mention (dyad)\npublication_id: Foreign key to publication.csv\nalias_id: Foreign key to dataset_alias.csv\nmention_candidate: Mention text from publication\n\n\n\n\nmodel.csv\n\nDescription: Lists methods/models for identifying dataset mentions.\nColumns:\n\nid: Unique model identifier\nname: Name of the identification model\n\n\n\n\ndyad_model.csv\n\nDescription: Connects dyads and models used to identify them.\nColumns:\n\ndyad_id: Foreign key to dyad.csv\nmodel_id: Foreign key to model.csv\nscore: Confidence or relevance score\n\nHow to use:\n\nFilter mentions by joining with dyad.csv on dyad_id and filtering by model_id",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html#sample-data",
    "href": "appendices/app_scopus.html#sample-data",
    "title": "Scopus Data Dictionary",
    "section": "Sample Data",
    "text": "Sample Data\n\npublication.csvdataset_alias.csvdyad.csvmodel.csvdyad_model.csv\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntitle\ndoi\nyear\nmonth\n\n\n\n\n321613\nNew estimates for CRNA vacancies\n\n2009\n4\n\n\n321614\nCrossing county lines: The impact of crash location and driver’s…\n10.1016/j.aap.2006…\n2006\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nalias_id\nparent_alias_id\nalias\n\n\n\n\n1676\n87\n89\nCensus of Agriculture\n\n\n1673\n12\n282\nARMS Farm Financial and Crop Production Practices\n\n\n\n\n\n\n\n\nid\npublication_id\nalias_id\nmention_candidate\n\n\n\n\n2569\n1211491\n87\ncensus of agriculture\n\n\n2573\n1199598\n88\nusda census of agriculture\n\n\n\n\n\n\n\n\nid\nname\n\n\n\n\n1\nstring_matching\n\n\n5\nrefmatch\n\n\n\n\n\n\n\n\nid\ndyad_id\nmodel_id\nscore\n\n\n\n\n4928\n2569\n1\n2.0\n\n\n4929\n2569\n4\n1.0\n\n\n4930\n2569\n2\n1.0",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html#how-to-extract-publications-for-a-specific-dataset",
    "href": "appendices/app_scopus.html#how-to-extract-publications-for-a-specific-dataset",
    "title": "Scopus Data Dictionary",
    "section": "How to Extract Publications for a Specific Dataset",
    "text": "How to Extract Publications for a Specific Dataset\nTo find all publications associated with a particular dataset, such as the NASS Census of Agriculture, follow these steps:\n\nIdentify the Main Alias:\n\nFind the alias_id where alias_id equals parent_alias_id for the dataset.\nFor NASS Census of Agriculture, the main alias has alias_id = 89.\n\nGet All Aliases:\n\nIn dataset_alias.csv, filter rows where parent_alias_id equals 89.\nThis gives you all aliases associated with the NASS Census of Agriculture dataset.\n\nLink Aliases to Publications:\n\nIn dyad.csv, filter rows where alias_id matches any of the alias_ids obtained in step 2.\nThis will give you publication_ids of publications mentioning any alias of the dataset.\n\nRetrieve Publication Details:\n\nUsing the publication_ids from step 3, retrieve the corresponding records from publication.csv.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_scopus.html#filtering-publications-by-specific-models",
    "href": "appendices/app_scopus.html#filtering-publications-by-specific-models",
    "title": "Scopus Data Dictionary",
    "section": "Filtering Publications by Specific Models",
    "text": "Filtering Publications by Specific Models\nSince we’re interested in mentions identified by the string_matching and refmatch models (models with id 1 and 5), follow these steps:\n\nFilter Dyads by Model:\n\nIn dyad_model.csv, filter rows where model_id is 1 or 5.\nThis gives you dyad_ids linked to these models.\n\nGet Relevant Dyads:\n\nPerform an inner join with dyad.csv on dyad_id.\nThis filters dyads to only those identified by the specified models.\n\nProceed as Before:\n\nContinue with the steps in the previous section, but using the filtered dyads from step 2.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Scopus Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_msi.html",
    "href": "appendices/app_msi.html",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "",
    "text": "The Minority-Serving Institutions (MSI) Data captures institutions eligible for federal MSI programs, as determined by the U.S. Department of Education and other sources. In this project, MSI data is used to analyze institutional characteristics in relation to research publications identified in Scopus, OpenAlex, and Dimensions.\nThis dataset provides information on institutions eligible or potentially eligible for at least one MSI designation and includes data from 2017 to 2023. The MSI dataset integrates information from multiple sources and is merged with IPEDS data to track research output across different institution types.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#summary-of-the-msi-data",
    "href": "appendices/app_msi.html#summary-of-the-msi-data",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Summary of the MSI data",
    "text": "Summary of the MSI data\n\nTotal Institutions by MSI StatusPrivate Institutions by MSI StatusPrivate For-Profit Institutions by MSI StatusPrivate Not-for-Profit Institutions by MSI StatusPublic Institutions by MSI StatusPublic 2-year Institutions by MSI StatusPublic 4-year Institutions by MSI StatusPrivate 2-year Institutions by MSI StatusPrivate 4-year Institutions by MSI Status\n\n\n\n\n\nYear\nTotal\nMSI %\nNot_MSI %\n\n\n\n\n2017\n5242\n8.13\n91.87\n\n\n2018\n5242\n7.69\n92.31\n\n\n2019\n5242\n7.84\n92.16\n\n\n2020\n5242\n7.80\n92.20\n\n\n2021\n5242\n8.81\n91.19\n\n\n2022\n5242\n16.73\n83.27\n\n\n2023\n5242\n16.58\n83.42\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1837\n5.66\n94.34\n\n\n2018\n1837\n5.72\n94.28\n\n\n2019\n1837\n5.72\n94.28\n\n\n2020\n1837\n5.77\n94.23\n\n\n2021\n1837\n5.88\n94.12\n\n\n2022\n1837\n14.81\n85.19\n\n\n2023\n1837\n14.81\n85.19\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1409\n0.00\n100.00\n\n\n2018\n1409\n0.00\n100.00\n\n\n2019\n1409\n0.00\n100.00\n\n\n2020\n1409\n0.00\n100.00\n\n\n2021\n1409\n0.00\n100.00\n\n\n2022\n1409\n0.14\n99.86\n\n\n2023\n1409\n0.21\n99.79\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n26\n0.00\n100.00\n\n\n2018\n26\n0.00\n100.00\n\n\n2019\n26\n0.00\n100.00\n\n\n2020\n26\n0.00\n100.00\n\n\n2021\n26\n0.00\n100.00\n\n\n2022\n26\n3.85\n96.15\n\n\n2023\n26\n3.85\n96.15\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1678\n19.18\n80.81\n\n\n2018\n1678\n17.76\n82.24\n\n\n2019\n1678\n18.24\n81.76\n\n\n2020\n1678\n18.06\n81.94\n\n\n2021\n1678\n21.10\n78.90\n\n\n2022\n1678\n33.86\n66.15\n\n\n2023\n1678\n35.34\n64.66\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n933\n19.72\n80.28\n\n\n2018\n933\n16.93\n83.07\n\n\n2019\n933\n17.04\n82.96\n\n\n2020\n933\n17.15\n82.85\n\n\n2021\n933\n20.15\n79.85\n\n\n2022\n933\n36.66\n63.34\n\n\n2023\n933\n35.05\n64.95\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n807\n17.10\n82.90\n\n\n2018\n807\n17.35\n82.65\n\n\n2019\n807\n18.22\n81.78\n\n\n2020\n807\n17.82\n82.18\n\n\n2021\n807\n20.57\n79.43\n\n\n2022\n807\n32.09\n67.91\n\n\n2023\n807\n32.96\n67.04\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n139\n2.88\n97.12\n\n\n2018\n139\n2.88\n97.12\n\n\n2019\n139\n2.16\n97.84\n\n\n2020\n139\n2.16\n97.84\n\n\n2021\n139\n2.88\n97.12\n\n\n2022\n139\n12.23\n87.77\n\n\n2023\n139\n12.23\n87.77\n\n\n\n\n\n\n\n\nYear\nTotal\n% MSI\n% Not MSI\n\n\n\n\n2017\n1714\n5.83\n94.17\n\n\n2018\n1714\n5.84\n94.16\n\n\n2019\n1714\n5.95\n94.05\n\n\n2020\n1714\n6.01\n93.99\n\n\n2021\n1714\n6.07\n93.93\n\n\n2022\n1714\n14.88\n85.12\n\n\n2023\n1714\n14.88\n85.12",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#data-processing-and-standardization",
    "href": "appendices/app_msi.html#data-processing-and-standardization",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Data Processing and Standardization",
    "text": "Data Processing and Standardization\n\nVariable Name Changes and Formatting:\n\nyear was added to track MSI status over time.\nUNITID is the primary key to merge MSI and IPEDS datasets.\n\nHandling Missing Data and Filters:\n\nInstitutions without UNITID were excluded.\nNon-relevant columns were removed.\n\nMerging Strategy:\n\nThe 2017-2021 MSI data was directly compatible with IPEDS.\nThe 2022-2023 MSI data required additional formatting before merging.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#how-to-merge-with-ipeds-data",
    "href": "appendices/app_msi.html#how-to-merge-with-ipeds-data",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "How to Merge with IPEDS Data",
    "text": "How to Merge with IPEDS Data\nThe MSI dataset can be linked with IPEDS data using the UNITID and year variables. This allows for:\n\nTracking institutional MSI status over time.\nComparing MSI and non-MSI institutions within Scopus, OpenAlex, and Dimensions.\nAssessing dataset usage patterns across different institution types.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_msi.html#footnotes",
    "href": "appendices/app_msi.html#footnotes",
    "title": "Identifying Minority Serving Institutions (MSIs)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 2017-2021 MSI data was sourced from the Minority Serving Institutions (MSI) Data Project by Nguyen et al. (2023), which merges the U.S. Department of Education’s MSI eligibility metrics (2017-2021) with IPEDS data.↩︎\nThe 2022-2023 MSI data was obtained from the Rutgers Graduate School of Education, which maintains annual MSI eligibility lists.↩︎\nThe 2022-2023 MSI data was obtained from the Rutgers Graduate School of Education, which maintains annual MSI eligibility lists.↩︎",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Identifying Minority Serving Institutions (MSIs)"
    ]
  },
  {
    "objectID": "appendices/app_dyads.html",
    "href": "appendices/app_dyads.html",
    "title": "Data Dyads: Assets and Aliases",
    "section": "",
    "text": "alias_id\nparent_alias_id\nalias\nalias_type\nusda_dataset\n\n\n\n\n12\n282\nARMS Farm Financial and Crop Production Practices\nalias\nagricultural resource management survey\n\n\n21\n282\nAgricultural Resource Management Survey\nalias\nagricultural resource management survey\n\n\n46\n282\nAgricultural Resources Management Survey\nalias\nagricultural resource management survey\n\n\n282\n282\nAgricultural Resource Management Survey (ARMS)\nmain\nagricultural resource management survey\n\n\n283\n282\nFarm Financial and Crop Production Practices (ERS)\nalias\nagricultural resource management survey\n\n\n284\n282\nFarm Income and Financial Forecast (ERS)\nalias\nagricultural resource management survey\n\n\n285\n282\nFarm Household Income and Characteristics (ERS)\nalias\nagricultural resource management survey\n\n\n286\n282\nFarm Income and Wealth Statistics (ERS)\nalias\nagricultural resource management survey\n\n\n287\n282\nFarm Production Expenditures (NASS)\nalias\nagricultural resource management survey\n\n\n288\n282\nAgricultural Resource Management Study\nalias\nagricultural resource management survey\n\n\n289\n282\nAgricultural Resources Management Study\nalias\nagricultural resource management survey\n\n\n87\n89\nCensus of Agriculture\nalias\ncensus of agriculture\n\n\n88\n89\nUSDA Census of Agriculture\nalias\ncensus of agriculture\n\n\n89\n89\nNASS Census of Agriculture\nmain\ncensus of agriculture\n\n\n279\n89\nAgricultural Census\nalias\ncensus of agriculture\n\n\n280\n89\nUSDA Census\nalias\ncensus of agriculture\n\n\n281\n89\nAG Census\nalias\ncensus of agriculture\n\n\n1006002\n1006002\nCurrent Population Survey Food Security Supplement,\nMain\ncurrent population survey food security supplement\n\n\n1006016\n1006002\nCPS-FSS\nAcronym\ncurrent population survey food security supplement\n\n\n1006017\n1006002\nCurrent Population Survey Food Security Supplement\nAlias\ncurrent population survey food security supplement\n\n\n1006003\n1006003\nFarm to School Census, \nMain\nfarm-to-school\n\n\n1006007\n1006007\nfood access research atlas\nMain\nfood access research atlas\n\n\n1006009\n1006009\nhousehold food security survey module\nMain\nhousehold food security survey module\n\n\n1006000\n1006000\nInformation Resources, Inc. (IRI) InfoScan\nMain\ninformation resources, inc.\n\n\n1006001\n1006001\nInformation Resources, Inc. (IRI) Consumer Network Panel\nMain\ninformation resources, inc.\n\n\n1006012\n1006000\nIRI Infoscan\nAlias\ninformation resources, inc.\n\n\n1006013\n1006001\nIRI Consumer Network Panel\nAlias\ninformation resources, inc.\n\n\n1006010\n1006010\nlocal food marketing practices survey\nMain\nlocal food marketing practices survey\n\n\n1006018\n1006010\nLFMPS\nAcronym\nlocal food marketing practices survey\n\n\n1006005\n1006005\nfood acquisition and purchase survey\nMain\nnational household food acquisition\n\n\n1006014\n1006005\nFoodAPS\nAcronym\nnational household food acquisition\n\n\n1006006\n1006006\nquarterly food at home price database\nMain\nquarterly food at home price database\n\n\n1006015\n1006006\nQFAHPD\nAcronym\nquarterly food at home price database\n\n\n1007000\n1007000\nRUCC\nmain\nrural-urban continuum codes\n\n\n1007001\n1007000\nRural-Urban Continuum Codes\nalias\nrural-urban continuum codes\n\n\n1007002\n1007000\nRural Urban Continuum Codes\nalias\nrural-urban continuum codes\n\n\n1007003\n1007000\nhttps://www.ers.usda.gov/data-products/rural-urban-continuum-codes.aspx\nalias\nrural-urban continuum codes\n\n\n1006019\n1006019\nTenure, ownership, and transition of agricultural land\nAlias\ntenure, ownership, and transition of agricultural land\n\n\n1006011\n1006011\ntransition of agricultural land survey\nMain\ntransition of agricultural land survey"
  },
  {
    "objectID": "appendices/app_crosswalk.html",
    "href": "appendices/app_crosswalk.html",
    "title": "Data Schemas",
    "section": "",
    "text": "Scopus Schema\n\n\nDimensions Schema\n\n\nOpenAlex Schemas\n\n\n\n\n\n\n  \n\n\n  \n\n\n  \n\nFull Text Search\n\n\n\n  \n\nSeed Corpus\nNote: All schemas were built using DBDiagram.io.",
    "crumbs": [
      "Appendices",
      "Data Schemas"
    ]
  },
  {
    "objectID": "appendices/app_crosswalk.html#file-inventory",
    "href": "appendices/app_crosswalk.html#file-inventory",
    "title": "Data Schemas",
    "section": "File Inventory",
    "text": "File Inventory\n\nScopus FilesOpenAlex FilesDimensions Files\n\n\n\nPrimary Table: publication\nSupporting Tables:\n\nagency_run\nasjc\nauthor\nauthor_affiliation\ndataset_alias\ndyad\ndyad_model\nissn\njournal\nmodel\npublication_affiliation\npublication_asjc\npublication_author\npublication_topic\npublication_ufc\npublisher\ntopic\n\n\nRefer to the schema for additional column-level details.\n\n\n\nFull Text\n\nPrimary Table: main\nSupporting Tables:\n\n_id\napc_list\napc_paid\nauthorships\nbest_oa_location\nbiblio\ncitation_normalized_percentile\ncited_by_percentile_year\ncorresponding_author_ids\ncorresponding_institution_ids\ncounts_by_year\ndataset\ndatasets\ngrants\nids\nindexed_in\nopen_access\nprimary_location\nprimary_topic\ntopics\n\n\n\n\nSeed Corpus\n\nPrimary Table: main\nSupporting Tables:\n\n\n\n\n\nPrimary Table: main\nSupporting Tables:\n\nThe accompanying schema focuses on the primary linking fields between tables. Due to the large number of columns within each table, only key identifiers are included.",
    "crumbs": [
      "Appendices",
      "Data Schemas"
    ]
  },
  {
    "objectID": "appendices/app_dimensions.html",
    "href": "appendices/app_dimensions.html",
    "title": "Dimensions Data Dictionary",
    "section": "",
    "text": "Research partners at the University of Utah have access to Dimensions.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Dimensions Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_dimensions.html#sec-app-dimensions",
    "href": "appendices/app_dimensions.html#sec-app-dimensions",
    "title": "Dimensions Data Dictionary",
    "section": "",
    "text": "Research partners at the University of Utah have access to Dimensions.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Dimensions Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html",
    "href": "appendices/app_ipeds.html",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "",
    "text": "The Integrated Postsecondary Education Data System (IPEDS) is a national dataset maintained by the National Center for Education Statistics (NCES). It collects data from all U.S. institutions participating in federal financial aid programs. In this project, IPEDS data is used to analyze institutional characteristics (e.g., size, classification, location, and financial indicators) in relation to research publications identified in Scopus, OpenAlex, and Dimensions.\nThe raw IPEDS data was obtained from the IPEDS website: IPEDS Data Center.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#summary-of-the-ipeds-data",
    "href": "appendices/app_ipeds.html#summary-of-the-ipeds-data",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "Summary of the IPEDS Data",
    "text": "Summary of the IPEDS Data\n\nDistinct institutions by yearDistinct institutions by year and controlDistinct institutions by year and level: Public UniversitiesDistinct institutions by year and level: Private Universities\n\n\n\n\n\nYear\nNo. Institutions\n\n\n\n\n2017\n7153\n\n\n2018\n6857\n\n\n2019\n6559\n\n\n2020\n6440\n\n\n2021\n6289\n\n\n2022\n6256\n\n\n2023\n6163\n\n\n\n\n\n\n\n\nYear\nPrivate for-profit\nPrivate not-for-profit\nPublic\n\n\n\n\n2017\n3093\n1959\n2069\n\n\n2018\n2793\n1930\n2077\n\n\n2019\n2566\n1905\n2056\n\n\n2020\n2463\n1889\n2036\n\n\n2021\n2411\n1868\n1994\n\n\n2022\n2352\n1855\n2019\n\n\n2023\n2299\n1836\n1999\n\n\n\n“Control” is defined as Public, Private Nonprofit, and Private For-Profit.\n\n\n\n\n\nYear\n2-year\n4-year\n\n\n\n\n2017\n1003\n817\n\n\n2018\n989\n840\n\n\n2019\n968\n852\n\n\n2020\n949\n852\n\n\n2021\n930\n829\n\n\n2022\n924\n859\n\n\n2023\n899\n868\n\n\n\n\n\n\n\n\nYear\n2-year\n4-year\n\n\n\n\n2017\n1034\n2371\n\n\n2018\n917\n2167\n\n\n2019\n774\n2081\n\n\n2020\n736\n2046\n\n\n2021\n709\n2016\n\n\n2022\n681\n2009\n\n\n2023\n664\n1996",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#data-processing-and-standardization",
    "href": "appendices/app_ipeds.html#data-processing-and-standardization",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "Data Processing and Standardization",
    "text": "Data Processing and Standardization\n\nVariable Name Changes and Formatting:\n\nUNITID and year serve as the primary keys to merge datasets for analysis.\nyear was added to datasets that lacked it.\n\nHandling Missing Data and Filters:\n\nNon-relevant columns were removed.\nDatasets were filtered to retain only institutions with complete enrollment and classification data.\n\nMerging Strategy:\n\nDatasets can be joined using UNITID and year as unique identifiers.\nInstitutions missing UNITID were excluded.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_ipeds.html#how-to-merge-with-msi-data",
    "href": "appendices/app_ipeds.html#how-to-merge-with-msi-data",
    "title": "Classifying Institutions with the IPEDS Database",
    "section": "How to Merge with MSI Data",
    "text": "How to Merge with MSI Data\nThe IPEDS dataset can be linked with the MSI dataset using the UNITID and year variables. This allows for:\n\nIdentifying MSI institutions within IPEDS to analyze institutional characteristics.\nComparing institutional characteristics of MSI and non-MSI institutions, such as enrollment size, Carnegie classification, and financial indicators.\n\n\n\n\n\n\n\nNote\n\n\n\nAfter merging the IPEDS-MSI data with the cleaned institutional data from the citation databases, this dataset also allows for assessing research output and dataset usage by institution type, and examining trends over time in MSI status and institutional characteristics.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "Classifying Institutions with the IPEDS Database"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html",
    "href": "appendices/app_openalex.html",
    "title": "OpenAlex Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html#sec-app-openalex",
    "href": "appendices/app_openalex.html#sec-app-openalex",
    "title": "OpenAlex Data Dictionary",
    "section": "",
    "text": "This section describes the process of construction CSV files extracted from a SQL Server database. These files contain interconnected data about publications and datasets, specifically focusing on how datasets are mentioned within publications. The main goal is to enable you to analyze the relationships between publications and datasets, particularly those identified using specific search models.\nBelow is a detailed explanation of primary tables and how they relate to one another. For a complete list of tables, please refer to the data schema.\n\n\nPLACEHOLDER\n\n\n\nCategory\nFile Path & Link\n\n\n\n\nProcessed IPEDS Dataset\ncompare_scopus_openalex/resources/IPEDS/IPEDS.csv\n\n\nRaw IPEDS Data\ncompare_scopus_openalex/resources/raw_data_IPEDS/\n\n\nData Processing Code\ncompare_scopus_openalex/resources/documentation/IPEDSdata.rmd\n\n\nData Documentation\ncompare_scopus_openalex/resources/documentation/IPEDS_Data.md",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html#data-dictionary",
    "href": "appendices/app_openalex.html#data-dictionary",
    "title": "OpenAlex Data Dictionary",
    "section": "Data Dictionary",
    "text": "Data Dictionary\n\n\n\n\n\n\nDownload OpenAlex Source Files\n\n\n\nYou can download the source files from this link.\n\n\n\ndataset.csv\n\nDescription: Lists all datasets identified in OpenAlex. This contains details of all USDA datasets.\n\n\n\npublication_dataset_links.csv\n\nDescription: Connects publications with one or more datasets in the OpenAlex data. Indicates which publications are associated with which datasets.\n\n\n\npublication.csv\n\nDescription: This file contains information about publications, which are the central entities in this dataset.\nKey Columns:\n\nid: Unique identifier for each publication.\ntitle: Title of the publication.\ndoi: Digital Object Identifier of the publication.\nyear and month: Publication date.\nOther metadata such as citation_count, pub_type, etc.\n\n\n\n\ndataset_alias.csv\n\nDescription: Contains all the aliases (alternative names) of datasets. This helps in identifying datasets that might be referred to by different names in publications.\nKey Columns:\n\nalias_id: Unique identifier for each alias.\nparent_alias_id: Identifies the main alias for a dataset. If parent_alias_id equals alias_id, it is the primary alias.\nalias: The alias name of the dataset.\n\n\nNote: The search in OpenAlex was performed using the same aliases and flag terms applied in the Scopus data, without any optimization.\nHow to Use:\n\nTo find the main alias of a dataset, look for rows where alias_id equals parent_alias_id.\nTo find all aliases of a dataset, filter by parent_alias_id corresponding to the main alias.\n\n\n\ndyad.csv\n\nDescription: Represents the mentions of dataset aliases found within publications. Acts as a linking table between publication.csv and dataset_alias.csv.\nKey Columns:\n\nid: Unique identifier for each dyad (mention).\npublication_id: References the id in publication.csv.\nalias_id: References the alias_id in dataset_alias.csv.\nmention_candidate: The actual text mentioning the dataset in the publication.\n\n\n\n\nmodel.csv\n\nDescription: Lists the different models or methods used to identify dataset mentions within publications.\nKey Columns:\n\nid: Unique identifier for each model.\nname: Name of the model (e.g., string_matching, refmatch).\n\n\nRelevant Models:\n\nModel ID 1: string_matching\nModel ID 5: refmatch\n\nThese are the models we are focusing on to compare with data extracted from OpenAlex, as no Kaggle model has been applied there.\n\n\ndyad_model.csv\n\nDescription: Connects dyads with the models that identified them. Allows filtering dyads based on the models used.\nKey Columns:\n\ndyad_id: References the id in dyad.csv.\nmodel_id: References the id in model.csv.\n\n\nHow to Use:\n\nTo filter dyads (and thus publications) identified by specific models, perform an inner join with dyad.csv on dyad_id and filter by model_id.\n\n\n\n\n\n\n\nHow the Files are Related\n\n\n\nThe files are structured to represent entities (publications, journals, institutions, authors) and their relationships. The main publication data is in publications_main.csv, and the details about journals, institutions, and authors are in their respective files.\nThe link files (publication_journal_links.csv, publication_institution_links.csv, publication_author_links.csv) represent the many-to-many relationships between publications and these entities.\nTo find all publications by a specific author, you can use authors.csv to find the author’s author_openalex_id and then use publication_author_links.csv to find the associated publications.\nTo analyze the distribution of publications across journals, you can join publications_main.csv, publication_journal_links.csv, and journals.csv on publication_openalex_id and journal_openalex_id.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html#sample-data",
    "href": "appendices/app_openalex.html#sample-data",
    "title": "OpenAlex Data Dictionary",
    "section": "Sample Data",
    "text": "Sample Data\n\npublication.csvdataset_alias.csvdyad.csvmodel.csvdyad_model.csv\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntitle\ndoi\nyear\nmonth\n\n\n\n\n321613\nNew estimates for CRNA vacancies\n\n2009\n4\n\n\n321614\nCrossing county lines: The impact of crash location and driver’s…\n10.1016/j.aap.2006…\n2006\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nalias_id\nparent_alias_id\nalias\n\n\n\n\n1676\n87\n89\nCensus of Agriculture\n\n\n1673\n12\n282\nARMS Farm Financial and Crop Production Practices\n\n\n1671\n88\n89\nUSDA Census of Agriculture\n\n\n\n\n\n\n\n\nid\npublication_id\nalias_id\nmention_candidate\n\n\n\n\n2569\n1211491\n87\ncensus of agriculture\n\n\n2573\n1199598\n88\nusda census of agriculture\n\n\n\n\n\n\n\n\nid\nname\n\n\n\n\n1\nstring_matching\n\n\n5\nrefmatch\n\n\n\n\n\n\n\n\nid\ndyad_id\nmodel_id\nscore\n\n\n\n\n4928\n2569\n1\n2.0\n\n\n4929\n2569\n4\n1.0\n\n\n4930\n2569\n2\n1.0",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html#how-to-extract-publications-for-a-specific-dataset",
    "href": "appendices/app_openalex.html#how-to-extract-publications-for-a-specific-dataset",
    "title": "OpenAlex Data Dictionary",
    "section": "How to Extract Publications for a Specific Dataset",
    "text": "How to Extract Publications for a Specific Dataset\nTo find all publications associated with a particular dataset, such as the NASS Census of Agriculture, follow these steps:\n\nIdentify the Main Alias:\n\nFind the alias_id where alias_id equals parent_alias_id for the dataset.\nFor NASS Census of Agriculture, the main alias has alias_id = 89.\n\nGet All Aliases:\n\nIn dataset_alias.csv, filter rows where parent_alias_id equals 89.\nThis gives you all aliases associated with the NASS Census of Agriculture dataset.\n\nLink Aliases to Publications:\n\nIn dyad.csv, filter rows where alias_id matches any of the alias_ids obtained in step 2.\nThis will give you publication_ids of publications mentioning any alias of the dataset.\n\nRetrieve Publication Details:\n\nUsing the publication_ids from step 3, retrieve the corresponding records from publication.csv.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendices/app_openalex.html#filtering-publications-by-specific-models",
    "href": "appendices/app_openalex.html#filtering-publications-by-specific-models",
    "title": "OpenAlex Data Dictionary",
    "section": "Filtering Publications by Specific Models",
    "text": "Filtering Publications by Specific Models\nSince we’re interested in mentions identified by the string_matching and refmatch models (models with id 1 and 5), follow these steps:\n\nFilter Dyads by Model:\n\nIn dyad_model.csv, filter rows where model_id is 1 or 5.\nThis gives you dyad_ids linked to these models.\n\nGet Relevant Dyads:\n\nPerform an inner join with dyad.csv on dyad_id.\nThis filters dyads to only those identified by the specified models.\n\nProceed as Before:\n\nContinue with the steps in the previous section, but using the filtered dyads from step 2.",
    "crumbs": [
      "Appendices",
      "Reference Files",
      "OpenAlex Data Dictionary"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Appendix\nLinks to Sources\n\n\n\n\nData Schema\nView the primary fields and table structure.\n\n\nScopus Reference Files\nView the Scopus source files.\n\n\nOpenAlex Reference Files\nView the OpenAlex source files.\n\n\nDimensions Reference Files\nView the Dimensions source files.\n\n\nIPEDS Reference Files\nView the IPEDS source files and methodology.\n\n\nMSI Reference Files\nView the MSI source files and methodology.",
    "crumbs": [
      "Appendices"
    ]
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "What Is the Issue?\nFederal datasets play an important role in supporting research across a range of disciplines. Measuring how these datasets are used can help evaluate their impact and inform future data investments. Agencies like the US Department of Agriculture (USDA) track how their datasets are referenced in research papers and disseminate data usage statistics through platforms like DemocratizingData.ai and NASS’s 5’s Data Usage Dashboard. These tools rely on identifying dataset mentions in published research. Beyond reporting usage volume, this type of analysis can also provide information about the research topics where federal datasets are applied. This helps characterize their disciplinary reach, including use in areas such as food security, nutrition, and climate, which are inherently multidisciplinary. It may also help identify alternative datasets and methods that researchers use to study similar questions across fields.\nThe process of identifying dataset mentions in academic research output requires the use of citation databases. However, different databases curate content (i.e., research output) in different ways - some focus on peer-reviewed journals while others include preprints and technical reports. Tracking dataset usage requires developing methods that scan publication text for dataset mentions. The accuracy of dataset tracking depends on the scope of research output we can access and analyze. Not to mention, dataset tracking requires reliable citation data from citation databases.\nThis report presents a methodology for identifying dataset mentions in research publications across various citation databases. In doing so, we compare publication, journal, and topic coverage across Scopus, OpenAlex, and Dimensions [forthcoming] as primary sources. The purpose is to establish a consistent set of statistics for comparing results and evaluating differences in dataset tracking across citation databases. This allows for insights into how publication scope and indexing strategies influence dataset usage statistics.\n\n\nHow Was the Study Conducted?\nThe three citation databases we are comparing are Elsevier’s Scopus, OurResearch’s OpenAlex, and Digital Science’s Dimensions.ai. Scopus charges for access to its citation database. It focuses on peer-reviewed literature and provides metadata about authors, institutions, and citations for academic journals. OpenAlex, an open-source platform, offers free metadata access. It covers both traditional academic publications and other research outputs like preprints and technical reports. Dimensions, developed by Digital Science, offers a hybrid model that provides both free and subscription-based access to its citation database. Unlike Scopus, which primarily indexes peer-reviewed journal articles, and OpenAlex, which emphasizes open-access content, Dimensions aggregates a broad spectrum of research outputs, including journal articles, books, clinical trials, patents, datasets, and policy documents. It integrates citation data with funding information, making it a useful tool for assessing the impact of research beyond traditional academic publishing.\nTo compare how these databases track dataset usage, we focus on six USDA datasets commonly used in agricultural, economic, and food policy research:\n\nAgricultural Resource Management Survey (ARMS)\nCensus of Agriculture (Ag Census)\nRural-Urban Continuum Code (RUCC)\nFood Access Research Atlas (FARA)\nFood Acquisition and Purchase Survey (FoodAPS)\nHousehold Food Security Survey Module (HHFSS)\n\nThese datasets were selected for their policy relevance, known usage frequency, and disciplinary breadth. We developed seed corpora for each dataset to identify relevant publications, then used those corpora to evaluate database coverage, topical scope, and metadata consistency.\n\n\nWhat Did the Study Find?\nAccurate tracking of dataset mentions relies heavily on how publications are indexed across citation databases. For two citation databases – Scopus and OpenAlex – carefully constructed seed corpora were needed to track dataset mentions.\nPreview of Results from Database Comparison:\n\nAcross databases, there is limited publication overlap between citation databases. For example:\n\n\nLess than 10% of DOIs typically appear in both Scopus and OpenAlex in any combination.\n51.8% of Food Access Research Atlas DOIs appear only in Scopus.\n60.9% of Household Food Security Survey Module DOIs appear only in Scopus.\n78.5% of ARMS DOIs appear only in OpenAlex Full Text.\n\n\nJournal coverage by source (Scopus or OpenAlex) varies significantly by dataset:\n\n\nScopus recovers the most publications MORE HERE.\nOpenAlex “Full Text” recovers the most publications MORE HERE.\nOpenAlex “Seed Search” identifies the most publications MORE HERE.\n\n\nTopical coverage reflects the varied policy and disciplinary relevance of each dataset:\n\n\nARMS: Research citing this dataset emphasizes agricultural management, accounting, and environmental topics.\nThe Census of Agriculture: Research mentioning this dataset has a wide breadth, spanning accounting and environmental applications.\nThe Rural-Urban Continuum Code: Research citing this dataset includes rural classification, regional planning, and spatial analysis.\nFood Access Research Atlas: Publications focus on food security, public health, and urban planning.\nFoodAPS: This dataset is mentioned in studies of consumer behavior, nutrition economics, and household spending.\nHHFSS: Research mentioning this dataset frequently cites topics such as food insecurity, poverty, and social policy evaluation.\n\nKey Takeaway: These patterns suggest that relying on a single citation database may undercount dataset usage, and may also obscure variation in the types of research being conducted with each dataset.\n\n\nWhat are the Contributions of this Study?\nOur methodology provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. We developed procedures for:\n\nIdentifying publication coverage across citation databases\nCross-referencing publications between datasets\nAnalyzing research themes and institutional representation\n\nThe methodology produced these reusable components:\n\nCode repository for data cleaning and standardization\nCrosswalk table structure linking Scopus and OpenAlex publication records and institutions\nData schemas by citation database \nStandardized institution tables using IPEDS identifiers\n\nThe methods described can be applied to evaluate other citation databases such as Web of Science, Crossref, and Microsoft Academic, to name a few.",
    "crumbs": [
      "Report Summary"
    ]
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "Download PDF Version",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#what-is-the-issue",
    "href": "report.html#what-is-the-issue",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "What Is the Issue?",
    "text": "What Is the Issue?\nFederal datasets play an important role in supporting research across a range of disciplines. Measuring how these datasets are used can help evaluate their impact and inform future data investments. Agencies like the US Department of Agriculture (USDA) track how their datasets are referenced in research papers and disseminate data usage statistics through platforms like Democratizing Data’s Food and Agricultural Research Data Usage Dashboard and NASS’s 5 W’s Data Usage Dashboard. These tools rely on identifying dataset mentions1 in published research to develop usage statistics. Beyond reporting usage statistics, this type of analysis can also provide information about the research topics where federal datasets are applied. Understanding where federal datasets are applied helps characterize their disciplinary reach, including use in areas such as food security, nutrition, and climate, which are inherently multidisciplinary. This informs future work on identifying alternative datasets that researchers use to study similar questions across fields.\nThe process of identifying dataset mentions in academic research output has two requirements. First, citation databases provide structured access to large volumes of publication metadata, including titles, abstracts, authors, affiliations, and sometimes full-text content. Second, tracking dataset usage requires developing methods that scan publication text for dataset mentions. It is feasible to systematically identify where specific datasets are referenced across a broad set of research outputs by applying machine-learning algorithms to publication corpora collected from citation databases, allowing for scalable search and retrieval of relevant publications where datasets are mentioned. The accuracy of dataset tracking depends on the scope of research output we can access and analyze. However, different databases curate content (i.e., research output) in different ways - some focus on peer-reviewed journals while others include preprints and technical reports - and dataset tracking requires reliable citation data from citation databases.\nThis report presents a methodology for identifying dataset mentions in research publications across various citation databases. In doing so, we compare publication, journal, and topic coverage across Scopus, OpenAlex, and Dimensions [forthcoming] as primary sources. The purpose is to establish a consistent set of statistics for comparing results and evaluating differences in dataset tracking across citation databases. This allows for insights into how publication scope and indexing strategies influence dataset usage statistics.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#how-was-the-study-conducted",
    "href": "report.html#how-was-the-study-conducted",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "How Was the Study Conducted?",
    "text": "How Was the Study Conducted?\nThree citation databases are compared: Elsevier’s Scopus, OurResearch’s OpenAlex, and Digital Science’s Dimensions.ai.\n\nScopus charges for access to its citation database. It indexes peer-reviewed, including journal articles, conference papers, and books, and provides metadata on authorship, institutional affiliation, funding sources, and citations. For this study, Scopus was used to identify dataset mentions through a two-step process: first, Elsevier executed queries against the full-text ScienceDirect corpus and reference lists within Scopus; second, publications likely to mention USDA datasets were filtered based on keyword matching and machine learning models.\nOpenAlex, an open-source platform, offers free metadata access. It covers both traditional academic publications and other research outputs like preprints and technical reports. In this study, we used two approaches to identify dataset mentions in OpenAlex: a full-text search, which scans publication metadata fields such as titles and abstracts for references to USDA datasets,2 and a seed corpus search, which starts with a targeted set of publications based on journal, author, and topic criteria, then downloads the full text of each paper to identify mentions of USDA datasets.3\nDimensions, developed by Digital Science, is a citation database that combines free and subscription-based access. It indexes a range of research outputs, including journal articles, books, clinical trials, patents, datasets, and policy documents. Dimensions also links publications to grant and funding information. For this study, publications in Dimensions that reference USDA datasets were identified by Add Rafael’s text. To maintain consistency with the criteria applied to Scopus and OpenAlex, the study focuses only on publications classified as journal articles.\n\nTo compare how these databases track dataset usage, we focus on six USDA datasets commonly used in agricultural, economic, and food policy research:\n\nAgricultural Resource Management Survey (ARMS)\nCensus of Agriculture (Ag Census)\nRural-Urban Continuum Code (RUCC)\nFood Access Research Atlas (FARA)\nFood Acquisition and Purchase Survey (FoodAPS)\nHousehold Food Security Survey Module (HHFSS)\n\nThese datasets were selected for their policy relevance, known usage frequency, and disciplinary breadth. We developed seed corpora for each dataset to identify relevant publications, then used those corpora to evaluate database coverage, topical scope, and metadata consistency.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#what-did-the-study-find",
    "href": "report.html#what-did-the-study-find",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "What Did the Study Find?",
    "text": "What Did the Study Find?\nAccurate tracking of dataset mentions relies heavily on how publications are indexed across citation databases. For two citation databases – Scopus and OpenAlex – carefully constructed seed corpora were needed to track dataset mentions.\nPreview of Results from Database Comparison:\n\nAcross databases, there is limited publication overlap between citation databases. For example:\n\n\nLess than 10% of DOIs typically appear in both Scopus and OpenAlex in any combination.\n51.8% of Food Access Research Atlas DOIs appear only in Scopus.\n60.9% of Household Food Security Survey Module DOIs appear only in Scopus.\n78.5% of ARMS DOIs appear only in OpenAlex Full Text.\n\n\nJournal coverage by source (Scopus or OpenAlex) varies significantly by dataset:\n\n\nScopus recovers the most publications MORE HERE.\nOpenAlex “Full Text” recovers the most publications MORE HERE.\nOpenAlex “Seed Search” identifies the most publications MORE HERE.\n\n\nTopical coverage reflects the varied policy and disciplinary relevance of each dataset:\n\n\nARMS: Research citing this dataset emphasizes agricultural management, accounting, and environmental topics.\nThe Census of Agriculture: Research mentioning this dataset has a wide breadth, spanning accounting and environmental applications.\nFood Access Research Atlas: Publications focus on food security, public health, and urban planning.\nThe Food Acquisition and Purchase Survey: This dataset is mentioned in studies of consumer behavior, nutrition economics, and household spending.\nThe Household Food Security Survey Module: Research mentioning this dataset frequently cites topics such as food insecurity, poverty, and social policy evaluation.\nThe Rural-Urban Continuum Code: Research citing this dataset includes rural classification, regional planning, and spatial analysis.\n\nKey Takeaway: These patterns suggest that relying on a single citation database may undercount dataset usage, and may also obscure variation in the types of research topics being conducted with each dataset.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#how-to-use-this-report",
    "href": "report.html#how-to-use-this-report",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "How to Use This Report",
    "text": "How to Use This Report\nThe report is preliminary in nature. It provides an initial approach to characterizing dataset mentions about food and agriculture research datasets in research papers reported in various databases, specifically Scopus, OpenAlex, and Dimensions. It includes procedures for:\n\nIdentifying publication coverage across citation databases\nCross-referencing publications between datasets\nAnalyzing research themes and institutional representation\n\nThe methodology produced these reusable components:\n\nCode repository for data cleaning and standardization\nData schemas by citation database \nStandardized institution tables using IPEDS identifiers\n\nThe methods described can be applied to evaluate other citation databases such as Web of Science, Crossref, and Microsoft Academic, to name a few.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#project-objective",
    "href": "report.html#project-objective",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "1.1 Project Objective",
    "text": "1.1 Project Objective\nThe objective of this project is to compare publication coverage across citation databases to determine how data usage varies depending on the database. These findings inform decisions about data preservation and future data investments,\nTo inform this decision, we compare the coverage, structure, and metadata quality of three citation databases—Scopus, OpenAlex, and Dimensions—focusing on their ability to support consistent and transparent dataset usage metrics across the research landscape.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#sec-aims",
    "href": "report.html#sec-aims",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "1.2 Specific Aims",
    "text": "1.2 Specific Aims\n\nEvaluate differences in publication coverage across citation databases. Measure the extent to which Scopus, OpenAlex, and Dimensions capture research publications that reference USDA datasets. Identify how publication inclusion varies across platforms.\nCompare journal indexing and scope. Compare the journals indexed by each database and examine how differences in journal coverage influence visibility of dataset-linked research.\nAnalyze topic coverage. Examine the research areas where USDA datasets are mentioned. Identify patterns in topic classification and assess how different citation databases support subject-level tracking of dataset usage.\nExamine institutional representation. Evaluate how each platform captures and standardizes institutional affiliations. Pay particular attention to differences in coverage for Minority-Serving Institutions (MSIs), land-grant universities, and other public or underrepresented institutions.\nEvaluate author representation. Compare how author names are recorded across platforms, including the completeness of author metadata and potential implications for attribution and visibility.\nDevelop a reproducible methodology for cross-platform comparison. Create a generalizable workflow for comparing citation databases, including steps for record linkage, deduplication, author and institution standardization, and identification of dataset mentions.\n\nThese aims guide the development of a methodology for comparing citation databases, focusing on four areas:\n\nPublication tracking: Comparing how each platform captures publications within indexed journals\nJournal coverage: Determining which journals each platform indexes\nTopic scope: Evaluating the research areas of publications that cite USDA datasets\nAuthor institutional affiliation: Determining how each platform records institutional information\n\nThe scope of work includes comparing publication coverage across Scopus, OpenAlex, and Dimensions that mention select USDA datasets. This inclusion provides a comprehensive assessment of citation databases, particularly in evaluating dataset coverage across both proprietary and open-access platforms. For more information on each citation database, refer to this Appendix.\nThe methodology described in this report provides a systematic approach for comparing publication coverage where federal datasets are mentioned across citation databases. These methods can be applied to other citation databases as alternatives to current data sources.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#scopus-approach",
    "href": "report.html#scopus-approach",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.1 Scopus Approach",
    "text": "2.1 Scopus Approach\nThe first citation database used is Scopus, a publication catalog managed by Elsevier. Ideally, direct Scopus API access would have been used to query full publication text for mentions of the Census of Agriculture. However, the project did not have access to the Scopus API. Only Elsevier, serving as a project partner, was able to execute queries within the Scopus environment. Consequently, the dataset mention search relied on outputs provided by Elsevier rather than independent querying.\nBecause of these constraints, a seed corpus approach was applied. First, Elsevier matched the names and aliases of selected datasets, including the Census of Agriculture, against full-text records available through ScienceDirect and reference sections of Scopus publications published between 2017 and 2023. This initial step identified journals, authors, and topics most likely to reference the Ag Census. A targeted search corpus was then constructed, narrowing the scope to approximately 1.45 million publications. These included various document types—articles, reviews, short surveys, notes, conference papers, chapters, books, editorials, letters, data papers, errata, and tombstones. For the purposes of this comparative report, only articles are considered.\nSeveral methods were used to identify mentions of USDA datasets in Scopus publications. First, a reference search was conducted, using exact-text matching across publication reference lists to capture formal citations of datasets. Second, full-text searches were performed using machine learning models applied to publication bodies, identifying less formal mentions of datasets. Third, machine learning routines developed through the 2021 Kaggle competition were applied to the full-text corpus to improve detection of dataset mentions, including instances where references were indirect or less structured. Details about the three machine learning models used are available here.\nBecause direct access to full publication text was not available, Elsevier shared only the extracted snippets and limited metadata. Manual validation, aided by the use of keyword flags (e.g., “USDA,” “NASS”), confirmed whether identified mentions accurately referred to the Census of Agriculture. To manage validation costs, only publications with at least one U.S.-based author were reviewed.\nFull documentation of the Scopus search routine, including query construction and extraction procedures, is available at the project’s report website.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#openalex-approach",
    "href": "report.html#openalex-approach",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.2 OpenAlex Approach",
    "text": "2.2 OpenAlex Approach\nThe second citation database used is OpenAlex, an open catalog of scholarly publications. OpenAlex offers public access to metadata and, when available, full-text content for open-access publications through its API. Unlike Scopus, which provides controlled access to licensed content, OpenAlex indexes only publications that are openly available or for which open metadata has been provided by publishers.\nFor OpenAlex, two approaches were used to identify publications referencing the Census of Agriculture. The first approach relied on a full-text search across OpenAlex publication records. The second approach applied a seed corpus methodology, similar to the strategy used for Scopus, to address limitations observed in the initial full-text search. In both approaches, the analysis was restricted to articles only. This decision reflects the open-access structure of OpenAlex, where multiple versions of the same work, such as preprints and accepted manuscripts, may be publicly available. To improve consistency and avoid duplication, we include only the final published version.\n\n2.2.1 OpenAlex Full-Text Search Approach\nThe methodology for collecting mentions of USDA datasets in OpenAlex relied on constructing search queries that combined dataset “aliases” and associated “flag terms” within the text of scholarly works. Dataset aliases represented alternative ways researchers refer to a dataset, such as variations on the Census of Agriculture’s official name. Flag terms represented the institutions or agencies responsible for maintaining the dataset. The combination of dataset alias and flag terms ensured that retrieved publications made an explicit connection to the correct data source. A mention was recorded only if at least one alias and one flag term appeared in the same publication, thereby increasing the likelihood of capturing genuine dataset references rather than incidental matches to individual words.4\nTo implement these searches efficiently, the OpenAlex API was accessed using the pyalex Python package.5\nSearch queries were constructed based on OpenAlex’s public API documentation, using both the “Filter Works” and “Search Works” endpoints. Filtering parameters were applied to restrict results to English-language publications, published after 2017, classified as articles or reviews, and available through open-access sources.\nBoolean logic was used to define the text search structure. For example, the query for the Census of Agriculture grouped several dataset aliases, including “Census of Agriculture,” “USDA Census of Agriculture,” “Agricultural Census,” and “USDA Census.” These aliases were combined using an OR operator. Separately, flag terms including “USDA,” “U.S. Department of Agriculture,” “United States Department of Agriculture,” “NASS,” and “National Agricultural Statistics Service” were also grouped using an OR operator. The final query ensured that both an alias and a flag term appeared by connecting the two groups with an AND operator:\n\n(“NASS Census of Agriculture” OR “Census of Agriculture” OR “USDA Census of Agriculture” OR “Agricultural Census” OR “USDA Census” OR “AG Census”) AND (USDA OR “US Department of Agriculture” OR “United States Department of Agriculture” OR NASS OR “National Agricultural Statistics Service”)\n\nThis structure required that each publication mention both a recognized variant of the Census of Agriculture name and a reference to the institution responsible for producing it.\nPublications matching the query were returned in JSON format, based on the OpenAlex “Work object” schema. Each record included metadata fields such as:\n\ndisplay_name (publication title)\nauthorships (authors and affiliations)\nhost_venue.display_name (journal)\ndoi (digital object identifier)\nconcepts (topics)\ncited_by_count (citation counts)\ntype (publication type, e.g., “article”)\npublication_year (year article was publish)\nlanguage (language, English only)\nis_oa (open access)\n\nAlthough a range of publication types were retrieved—including articles, book chapters, dissertations, preprints, and reviews—approximately 80–85 percent were classified as articles. To standardize the dataset for downstream analysis, results were filtered during the search process to retain only records identified as type = article. This step removed preprints and non-final versions of works, supporting a more standardized analysis of dataset mentions in peer-reviewed literature.\nThe code used to implement this querying and filtering process is publicly available here.\n\n2.2.1.1 Limitations of OpenAlex Full-Text Approach\nAlthough the OpenAlex API provides full-text search capabilities, limitations in how publication content is ingested and indexed introduce challenges for identifying dataset mentions accurately.\nOpenAlex receives publication text through two primary ingestion methods: PDF extraction and n-grams delivery. In the PDF ingestion method, OpenAlex extracts text directly from the article PDF. However, the references section is not included in the searchable text. References are processed separately to create citation pointers between scholarly works, meaning that mentions of datasets appearing only in bibliographies are not discoverable through full-text search.\nIn the n-grams ingestion method, OpenAlex does not receive the full article text. Instead, it receives a set of extracted word sequences (n-grams) from the publisher or author. These n-grams represent fragments of text—typically short sequences of one, two, or three words—which are not guaranteed to preserve full continuous phrases. As a result, complete dataset names may be broken apart or omitted, reducing the likelihood that search queries match the intended aliases.\nThese ingestion and indexing limitations affect the completeness of results when relying solely on OpenAlex full-text search. Mentions of the Census of Agriculture and other USDA datasets that appear either exclusively in references or are fragmented within n-grams may be missed. To address these limitations, an alternative search strategy was developed based on constructing a filtered seed corpus of publications for local full-text analysis.\n\n\n\n2.2.2 OpenAlex Seed Corpus Approach\nTo address limitations in OpenAlex’s full-text indexing methods, a seed corpus approach was applied. The objective was to create a filtered set of publications for local text search to better capture dataset mentions.\nTo construct the seed corpus, publications were filtered based on several criteria:\n\nLanguage: English\nPublication Year: 2017-2023\nPublication Type: Articles only\nOpen Access Status: Open-access publications only\n\nFiltering was further refined by selecting publications associated with high-relevance topics, journals, and authors. As an example, the tables shown for the Census of Agriculture dataset—Table 3 (top 25 topics), Table 4 (top 25 journals), and Table 5 (top 25 U.S.-affiliated authors)—illustrate how this filtering process was applied. Each table presents two key columns to support interpretation. The First Run Count refers to the number of publications linked to each entity (whether a topic, journal, or author) based on metadata from OpenAlex’s full-text search feature. This count reflects how often USDA datasets were mentioned within the full text of publications associated with a particular entity. The OpenAlex Total Count represents the total number of publications linked to that entity in the broader OpenAlex database, without applying any filters related to dataset mentions.\nTo create a more focused and manageable search corpus, we selected the top 25 entities in each category based on their First Run Count. This approach prioritizes journals, topics, and authors where USDA datasets are most frequently mentioned in the full text, which we interpret as being more representative of actual research activity involving these datasets. It also substantially reduces the workload by limiting the number of publications that need to be retrieved and processed. The results of this search generated a set of json files. The Python script used to flatten OpenAlex Seed Corpus JSON files is provided in this Appendix. UPDATE LINK\nChoosing this approach has a few important implications. First, it likely increases the relevance of the resulting corpus by concentrating on publications where USDA data are actively cited or discussed, rather than simply associated with a broader research area. Second, it helps avoid the need to download and process an unmanageable number of PDFs—estimated at around 1.7 million if all identified entities were included. However, this method may introduce some selection bias by favoring entities with higher immediate visibility in the first search pass. Some relevant but less frequently mentioned entities might be excluded, meaning that while efficiency improves, full comprehensiveness is slightly sacrificed. Overall, this trade-off supports a practical balance between depth and feasibility in building the final dataset of publication metadata.\nFor the Census of Agriculture, the resulting seed corpus included approximately 1,774,245 unique publications. An initial download of full texts achieved a success rate of roughly 35%, corresponding to an estimated 625,000 accessible full-text documents. Local full-text searches were conducted on this subset to improve detection of dataset mentions beyond what was possible through OpenAlex’s built-in search capabilities.\nAlthough the seed corpus approach allows for a more targeted retrieval, limitations remain. Full-text download success was constrained by incomplete or inaccessible open-access links, and processing the entire corpus was computationally intensive. Future efforts may require distributed processing or refined selection criteria to further improve efficiency.\nResults from both methods are compared to assess differences in dataset mention detection across approaches.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#dimensions",
    "href": "report.html#dimensions",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "2.3 Dimensions",
    "text": "2.3 Dimensions\nComing Soon [Rafael]\nIn the Dimensions dataset, publication records are classified under several document types, including “article”, “chapter”, “preprint”, “proceeding”, and “monograph”. For the purposes of this comparative report, only records classified as “article” are included. This restriction maintains consistency with the Scopus and OpenAlex approaches and helps minimize duplication across versions of the same work.\nAdditional filtering criteria, such as publication year, language, and open-access status, will be documented once the data extraction and cleaning processes are complete.",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#publication-coverage",
    "href": "report.html#publication-coverage",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "3.1 Publication Coverage",
    "text": "3.1 Publication Coverage\nAn objective of this report is to understand differences in publication coverage across Scopus and OpenAlex. Specifically, this section asks: (1) how many and which publications referencing USDA datasets appear in each citation database, and (2) how many and which journals publishing these articles overlap between the two sources. In addition, the analysis evaluates whether the different search strategies used in OpenAlex—the full-text metadata search versus the seed-corpus approach—yield substantially different sets of results.\nFor each of the six USDA datasets featured in this study, a treemap visualization is presented to summarize publication coverage across the citation databases. Because two search strategies were applied to OpenAlex, the results distinguish publications identified separately. Each treemap groups publications into mutually exclusive categories based on their presence in one or more of the data sources: Scopus, OpenAlex Full Text, OpenAlex Seed Corpus, Dimensions. The size of each box is proportional to the number of distinct DOIs in that group, providing a visual summary of the relative coverage across sources. For example, a large “Scopus only” segment indicates a high number of publications indexed exclusively in Scopus, while overlapping segments (e.g., “Scopus ∩ OA Seed”) reflect shared coverage between platforms.\n\nARMS Financial and Crop Production Practices\n\n  \n\n\n\nThe Census of Agriculture\n\n  \n\n\n\nFood Access Research Atlas\n\n  \n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\n\n  \n\n\n\nThe Household Food Security Survey Module\n\n  \n\n\n\nRural-Urban Continuum Code",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#journal-coverage",
    "href": "report.html#journal-coverage",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "3.2 Journal Coverage",
    "text": "3.2 Journal Coverage\nNow that we have compared journal coverage across the two citation databases, we next examine the publications within journals that are indexed in both Scopus and OpenAlex. We report these results for the full-text search approach and the seed-corpus approach in OpenAlex.\n\nARMS Financial and Crop Production Practices\n\n  \n\nClick to enlarge\n\n\n\n\nThe Census of Agriculture\n\n  \n\nClick to enlarge\n\n\n\n\nFood Access Research Atlas\n\n  \n\nClick to enlarge\n\n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\n\n  \n\nClick to enlarge\n\n\n\n\nThe Household Food Security Survey Module\n\n  \n\nClick to enlarge\n\n\n\n\nRural-Urban Continuum Code\n\n  \n\nClick to enlarge",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#publication-topics",
    "href": "report.html#publication-topics",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "3.3 Publication Topics",
    "text": "3.3 Publication Topics\n\nARMS Financial and Crop Production Practices\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\nThe Census of Agriculture\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\nFood Access Research Atlas\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\nThe Food Acquisition and Purchase Survey (FoodAPS)\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\nThe Household Food Security Survey Module\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions \n\n\n\n\nRural-Urban Continuum Code\n\n  \n\n\nTopics by Source\n\n 🔍 Scopus \n 🔍 OpenAlex \n 🔍 Dimensions",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#author-and-institutional-comparison",
    "href": "report.html#author-and-institutional-comparison",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "3.4 Author and Institutional Comparison",
    "text": "3.4 Author and Institutional Comparison\nIn addition to examining dataset mention coverage, the report also evaluates differences in institutional representation across Scopus, OpenAlex, and Dimensions. Each of the featured citation databases represent some portion of the global research landscape, yet their inclusion criteria and institutional coverage may vary. The purpose of this analysis is to assess which institutions are represented in each source, with particular attention to coverage of underrepresented and Minority-Serving Institutions (MSIs).\nTo create a harmonsized dataset of institutional coverage across datasets, institutional affiliation data associated with each publication’s athor(s) are linked to institutional records using IPEDS identifiers. Linking the publication metadata with IPEDS institutional data adds information not available in the publication affiliation data alone. This additional information includes public or private institution (control), degree level, MSI designation, and geographic location. Special attention is given to coverage of underrepresented institutions and Minority-Serving Institutions (MSIs).\n\n3.4.1 IPEDS and MSI Classifications\n\nFirst, a clean, panel-form dataset of U.S. higher education institutions, including consistent MSI designations over time is created. Two sources were used: (1) the MSI Data Project (Nguyen et al., 2023) identifies MSI institutions from 2017–2021 and (2) Rutgers CMSI identifies MSI institutions for 2022–2023. These datasets were cleaned and merged with IPEDS institutional data, filtered to include only 2- and 4-year institutions in the 50 U.S. states. Data cleaning steps included: addressing inconsistencies in eligibility labels, removing duplicates, and creating summary measures of MSI eligibility by year. The resulting visualization highlights both the number and percent of institutions designated as MSIs over time, with a sharp increase observed in 2022. The accompanying plot and source code are available in the report appendices7 and MSI8.\n\n  \n\nSource code used to generate graphic: Available here.\n\n\n\n\n3.4.2 Results of Institutional Comparision",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "report.html#footnotes",
    "href": "report.html#footnotes",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA dataset mention refers to an instance in which a specific dataset is referenced, cited, or named within a research publication. This can occur in various parts of the text, such as the abstract, methods, data section, footnotes, or references, and typically indicates that the dataset was used, analyzed, or discussed in the study.↩︎\nFull-text search in OpenAlex refers to querying the entire database for textual mentions of dataset names within titles, abstracts, and other fields.↩︎\nThe seed corpus search involves selecting a targeted set of publications based on journal, author, and topic filters. Full-text PDFs are downloaded and analyzed to identify mentions of USDA datasets not captured through metadata alone.↩︎\nInitial drafts of the query incorrectly included terms like “NASS” and “USDA” in the alias list. This was corrected to ensure that aliases strictly referred to dataset names, and flag terms referred to organizations.↩︎\nPyalex is an open-source library designed to facilitate interaction with the OpenAlex API; see https://help.openalex.org/hc/en-us/articles/27086501974551-Projects-Using-OpenAlex for more information. The package manages request formatting and automates compliance with OpenAlex’s “polite pool” rate limits, which restrict the number of requests per minute and impose backoff delays. Pyalex introduced automatic pauses between requests, with a default retry_backoff_factor of 100 milliseconds, to ensure stable and continuous retrieval. This setup enabled systematic querying while adhering to OpenAlex’s usage policies.↩︎\nIn cases where a publication appeared in more than one source, manual and programmatic checks confirmed that metadata values, such as journal titles and publication years, were consistent across sources. No conflicting values were detected.↩︎\nIPEDS appendix available here↩︎\nMSI appendix available here↩︎",
    "crumbs": [
      "Full Report"
    ]
  },
  {
    "objectID": "webinar_questionnaire.html",
    "href": "webinar_questionnaire.html",
    "title": "Questionnaire",
    "section": "",
    "text": "Complete Questionnaire \n\nLoading…\n\n\n\n\n\nInterested in staying involved? If you’d like to join a working group to continue the conversation and help shape next steps, please provide your contact information. Participation is completely optional.\n\n Sign Up Here \n\nLoading…",
    "crumbs": [
      "Questionnaire"
    ]
  },
  {
    "objectID": "workflow/step01/define_data_assets.html",
    "href": "workflow/step01/define_data_assets.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to compile a structured list of dataset names and their commonly used variations.\n\n\n\n\n\n\n\nNote\n\n\n\nThe data assets featured here consist of those collected by the USDA, primarily from the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). These data assets are widely used in agricultural economics and food systems research.\n\n\n\n\nIn late July 2023, an initial set of 21 reports were received containing a report name and a URL link to database curated by Cornell University. These reports are part of the USDA’s efforts to track data usage across various research applications. However, the names of these reports were highly generic, making it difficult to precisely identify them in citation databases. Examples include reports titled “Agricultural Prices” and “Farm Labor,” which lack specificity when compared to more structured dataset identifiers.\nData Processing and Standardization\nTo improve identification and searchability, the input was analyzed and transformed into a structured list that included:\n\nInternational Standard Serial Numbers (ISSNs): Each of the 21 reports was assigned an ISSN, where available, to provide a standardized identifier.\nAlias Creation: Generic report names were appended with the term report to better distinguish them from other similarly named publications in research literature.\nExpanded Search Terms: Additional variations of dataset names were included to account for different citation styles and possible ways authors reference these reports.\n\nThe final dataset classification involved:\n\nMain Data Asset (Parent Record): The original 21 reports, each representing a distinct dataset.\nAliases: ISSNs and URLs served as aliases to improve retrieval accuracy.\nSearch Term Expansion: Combining report names with different citation formats led to a total of 64 search terms (21 parent records + 43 aliases).\n\nThis standardization process improved the efficiency of identifying NASS datasets across publications indexed by citation databases such as Scopus, OpenAlex, and Dimensions.\n\n\n\nThe process of identifying ERS data assets occurred in two phases: (1) an initial dataset compilation, and (2) a refinement process incorporating feedback from a team of agricultural economists at Colorado State University (CSU). This process was meant to yield a list of data assets was both comprehensive and relevant to the research community tracking USDA dataset usage.\nPhase 1: Initial Compilation of ERS Data Assets\nIn October 2023, an initial list of 2,103 ERS records was compiled. These records included dataset names and, in some cases, associated aliases. The list was then reviewed by Professor Julia Lane, who identified and removed 144 records that were not suitable for machine learning-based dataset tracking.\nReasons for Exclusion\n\nRecords were too generic – Terms such as “Milk, Cotton, and CSV Format of National Data” were too broad to be meaningfully identified in citation databases.\nRecords were too specific – Entries such as “Table 15—Agricultural Chemical Input” and “Southeast: 1982-91, 1992-97” were references within broader reports rather than standalone data assets.\n\nAfter these exclusions, the remaining 1,959 records represented the initial list of ERS data assets.\nPhase 2: Refinement with CSU Team\nA team of agricultural economists at CSU were consulted to refine the list so that it accurately captured key USDA datasets that may have been overlooked in the initial process. This involved:\n\nReviewing dataset usage in prior USDA research – Identifying which datasets were frequently cited.\nCross-checking with known data users – Ensuring that key datasets used by agricultural economists were included.\nExpanding alias definitions – Recognizing dataset acronyms and alternative naming conventions.\n\nAs part of this process, an additional set of assets was incorporated, including datasets that had been previously identified in the Year 1 USDA project. Notably, datasets such as the Census of Agriculture and the Agricultural Resource Management Survey (ARMS) were added, along with key acronyms like FoodAPS. This phase contributed:\n\n12 new parent records\n8 additional alias records\nTotal: 20 new search terms\n\nFinal Data Asset Identification\nUnlike NASS data assets, which had ISSNs and DOIs, ERS datasets were primarily linked through URLs. The final structured dataset included:\n\n1,959 parent records (main ERS datasets)\n1,959 alias records (URLs serving as dataset identifiers)\n20 additional records from the CSU consultation\nTotal: 3,918 search terms\n\nThrough this two-phase process, the list of ERS data assets evolved from an initial broad set of records into a refined, structured collection of datasets that could be effectively tracked across citation databases.\n\n\n\nThe data assets represent those most frequently used in agricultural economics research, spanning topics from farm management to food security. The final set of data assets, their producing agencies, and descriptions are presented in Table 1.\n\n\n\nTable 1: List of USDA Data Assets\n\n\n\n\n\nDataset Name\nProduced By\nDescription\n\n\n\n\nCensus of Agriculture\nNASS\nConducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.\n\n\nAgricultural Resource Management Survey (ARMS)\nERS\nA USDA survey on farm financials, production practices, and resource use.\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\nERS\nA nationally representative survey tracking U.S. household food purchases and acquisitions.\n\n\nCurrent Population Survey Food Security Supplement (CPS-FSS)\nERS\nAn annual supplement to the Current Population Survey (CPS) measuring U.S. household food security.\n\n\nFood Access Research Atlas (FARA)\nERS\nA USDA tool mapping food access based on store locations and socioeconomic data.\n\n\nRural-Urban Continuum Code (RUCC)\nERS\nA classification system distinguishing U.S. counties by rural and urban characteristics.\n\n\nHousehold Food Security Survey Module\nERS\nA USDA survey module used to assess food insecurity levels in households.\n\n\nLocal Food Marketing Practices Survey\nNASS\nA USDA survey on U.S. farms’ local food sales, direct-to-consumer marketing, and supply chains.\n\n\nFarm to School Census\nFNS\nA USDA survey tracking school food procurement and local farm partnerships.\n\n\nQuarterly Food at Home Price Database (QFAHPD)\nERS\nA database of U.S. retail food prices by product, region, and time.\n\n\nTenure Ownership and Transition of Agricultural Land (TOTAL)\nNASS\nA survey collecting data on farmland ownership, leasing, and transfer.\n\n\nTransition of Agricultural Land Survey\nNASS\nA component of TOTAL that examines farmland ownership changes and succession plans.\n\n\nInformation Resources, Inc. (IRI) InfoScan\nCircana (formerly IRI)\nA commercial scanner dataset tracking retail food and consumer goods purchases.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo provide a comprehensive reference for dataset tracking, this Appendix includes a detailed list of data assets and their corresponding aliases, collectively referred to as dyads. Each dyad represents a dataset-name and alias pair used in citation database searches, allowing for more precise identification of dataset mentions in research publications. These aliases include acronyms, alternate spellings, dataset variations, and associated URLs, ensuring broad coverage across different citation practices. The dyad list serves as the foundation for dataset extraction and disambiguation across Scopus, OpenAlex, and Dimensions.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 01: Define Data Assets"
    ]
  },
  {
    "objectID": "workflow/step01/define_data_assets.html#sec-data",
    "href": "workflow/step01/define_data_assets.html#sec-data",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to compile a structured list of dataset names and their commonly used variations.\n\n\n\n\n\n\n\nNote\n\n\n\nThe data assets featured here consist of those collected by the USDA, primarily from the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). These data assets are widely used in agricultural economics and food systems research.\n\n\n\n\nIn late July 2023, an initial set of 21 reports were received containing a report name and a URL link to database curated by Cornell University. These reports are part of the USDA’s efforts to track data usage across various research applications. However, the names of these reports were highly generic, making it difficult to precisely identify them in citation databases. Examples include reports titled “Agricultural Prices” and “Farm Labor,” which lack specificity when compared to more structured dataset identifiers.\nData Processing and Standardization\nTo improve identification and searchability, the input was analyzed and transformed into a structured list that included:\n\nInternational Standard Serial Numbers (ISSNs): Each of the 21 reports was assigned an ISSN, where available, to provide a standardized identifier.\nAlias Creation: Generic report names were appended with the term report to better distinguish them from other similarly named publications in research literature.\nExpanded Search Terms: Additional variations of dataset names were included to account for different citation styles and possible ways authors reference these reports.\n\nThe final dataset classification involved:\n\nMain Data Asset (Parent Record): The original 21 reports, each representing a distinct dataset.\nAliases: ISSNs and URLs served as aliases to improve retrieval accuracy.\nSearch Term Expansion: Combining report names with different citation formats led to a total of 64 search terms (21 parent records + 43 aliases).\n\nThis standardization process improved the efficiency of identifying NASS datasets across publications indexed by citation databases such as Scopus, OpenAlex, and Dimensions.\n\n\n\nThe process of identifying ERS data assets occurred in two phases: (1) an initial dataset compilation, and (2) a refinement process incorporating feedback from a team of agricultural economists at Colorado State University (CSU). This process was meant to yield a list of data assets was both comprehensive and relevant to the research community tracking USDA dataset usage.\nPhase 1: Initial Compilation of ERS Data Assets\nIn October 2023, an initial list of 2,103 ERS records was compiled. These records included dataset names and, in some cases, associated aliases. The list was then reviewed by Professor Julia Lane, who identified and removed 144 records that were not suitable for machine learning-based dataset tracking.\nReasons for Exclusion\n\nRecords were too generic – Terms such as “Milk, Cotton, and CSV Format of National Data” were too broad to be meaningfully identified in citation databases.\nRecords were too specific – Entries such as “Table 15—Agricultural Chemical Input” and “Southeast: 1982-91, 1992-97” were references within broader reports rather than standalone data assets.\n\nAfter these exclusions, the remaining 1,959 records represented the initial list of ERS data assets.\nPhase 2: Refinement with CSU Team\nA team of agricultural economists at CSU were consulted to refine the list so that it accurately captured key USDA datasets that may have been overlooked in the initial process. This involved:\n\nReviewing dataset usage in prior USDA research – Identifying which datasets were frequently cited.\nCross-checking with known data users – Ensuring that key datasets used by agricultural economists were included.\nExpanding alias definitions – Recognizing dataset acronyms and alternative naming conventions.\n\nAs part of this process, an additional set of assets was incorporated, including datasets that had been previously identified in the Year 1 USDA project. Notably, datasets such as the Census of Agriculture and the Agricultural Resource Management Survey (ARMS) were added, along with key acronyms like FoodAPS. This phase contributed:\n\n12 new parent records\n8 additional alias records\nTotal: 20 new search terms\n\nFinal Data Asset Identification\nUnlike NASS data assets, which had ISSNs and DOIs, ERS datasets were primarily linked through URLs. The final structured dataset included:\n\n1,959 parent records (main ERS datasets)\n1,959 alias records (URLs serving as dataset identifiers)\n20 additional records from the CSU consultation\nTotal: 3,918 search terms\n\nThrough this two-phase process, the list of ERS data assets evolved from an initial broad set of records into a refined, structured collection of datasets that could be effectively tracked across citation databases.\n\n\n\nThe data assets represent those most frequently used in agricultural economics research, spanning topics from farm management to food security. The final set of data assets, their producing agencies, and descriptions are presented in Table 1.\n\n\n\nTable 1: List of USDA Data Assets\n\n\n\n\n\nDataset Name\nProduced By\nDescription\n\n\n\n\nCensus of Agriculture\nNASS\nConducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.\n\n\nAgricultural Resource Management Survey (ARMS)\nERS\nA USDA survey on farm financials, production practices, and resource use.\n\n\nFood Acquisition and Purchase Survey (FoodAPS)\nERS\nA nationally representative survey tracking U.S. household food purchases and acquisitions.\n\n\nCurrent Population Survey Food Security Supplement (CPS-FSS)\nERS\nAn annual supplement to the Current Population Survey (CPS) measuring U.S. household food security.\n\n\nFood Access Research Atlas (FARA)\nERS\nA USDA tool mapping food access based on store locations and socioeconomic data.\n\n\nRural-Urban Continuum Code (RUCC)\nERS\nA classification system distinguishing U.S. counties by rural and urban characteristics.\n\n\nHousehold Food Security Survey Module\nERS\nA USDA survey module used to assess food insecurity levels in households.\n\n\nLocal Food Marketing Practices Survey\nNASS\nA USDA survey on U.S. farms’ local food sales, direct-to-consumer marketing, and supply chains.\n\n\nFarm to School Census\nFNS\nA USDA survey tracking school food procurement and local farm partnerships.\n\n\nQuarterly Food at Home Price Database (QFAHPD)\nERS\nA database of U.S. retail food prices by product, region, and time.\n\n\nTenure Ownership and Transition of Agricultural Land (TOTAL)\nNASS\nA survey collecting data on farmland ownership, leasing, and transfer.\n\n\nTransition of Agricultural Land Survey\nNASS\nA component of TOTAL that examines farmland ownership changes and succession plans.\n\n\nInformation Resources, Inc. (IRI) InfoScan\nCircana (formerly IRI)\nA commercial scanner dataset tracking retail food and consumer goods purchases.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo provide a comprehensive reference for dataset tracking, this Appendix includes a detailed list of data assets and their corresponding aliases, collectively referred to as dyads. Each dyad represents a dataset-name and alias pair used in citation database searches, allowing for more precise identification of dataset mentions in research publications. These aliases include acronyms, alternate spellings, dataset variations, and associated URLs, ensuring broad coverage across different citation practices. The dyad list serves as the foundation for dataset extraction and disambiguation across Scopus, OpenAlex, and Dimensions.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 01: Define Data Assets"
    ]
  },
  {
    "objectID": "workflow/step02_01/03openalex.html",
    "href": "workflow/step02_01/03openalex.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Describe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API\nTo collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”\nThis method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.\nRefer to this Appendix for additional details on file construction."
  },
  {
    "objectID": "workflow/step02_01/03openalex.html#openalex",
    "href": "workflow/step02_01/03openalex.html#openalex",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "Describe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API\nTo collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”\nThis method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.\nRefer to this Appendix for additional details on file construction."
  },
  {
    "objectID": "workflow/step02_01/extract_dataset_mentions.html",
    "href": "workflow/step02_01/extract_dataset_mentions.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to build a dataset of publications that reference the dataset name aliases for the USDA data assets across Scopus, OpenAlex, and Dimensions.\n\nTo generate this dataset, the process requires:\n\nDataset name aliases (from Step 1)\nSearch routines tailored to each citation database to extract relevant publications\n\nSearch routines, described below, guide this step, as dataset mentions are often inconsistent across publications—appearing in titles, abstracts, full text, or reference lists. Scopus uses a structured seed corpus to refine searches, while OpenAlex and Dimensions rely on direct queries across their full publication records. The outputs of this step are three publication-level datasets, one for each citation database, which will be further analyzed in subsequent steps.\n\nScopusOpenAlexDimensions\n\n\n\n\nThe search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.\n\n\n\n\n\nDescribe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API\nTo collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”\nThis method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.\nRefer to this Appendix for additional details on file construction.\n\n\nComing Soon",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 02: Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "workflow/step02_01/extract_dataset_mentions.html#sec-data-idn",
    "href": "workflow/step02_01/extract_dataset_mentions.html#sec-data-idn",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to build a dataset of publications that reference the dataset name aliases for the USDA data assets across Scopus, OpenAlex, and Dimensions.\n\nTo generate this dataset, the process requires:\n\nDataset name aliases (from Step 1)\nSearch routines tailored to each citation database to extract relevant publications\n\nSearch routines, described below, guide this step, as dataset mentions are often inconsistent across publications—appearing in titles, abstracts, full text, or reference lists. Scopus uses a structured seed corpus to refine searches, while OpenAlex and Dimensions rely on direct queries across their full publication records. The outputs of this step are three publication-level datasets, one for each citation database, which will be further analyzed in subsequent steps.\n\nScopusOpenAlexDimensions\n\n\n\n\nThe search routines for Scopus were designed to systematically identify mentions of USDA data assets across a vast collection of academic publications. Multiple approaches were used to maximize dataset identification. These included (1) full-text searches, which leveraged Scopus’s licensed access to retrieve dataset mentions directly from publication text, (2) reference searches, which scanned citation lists for dataset appearances, and (3) machine learning models, which applied text-matching algorithms to improve accuracy.\n\n\n\n\n\n\nProcess of Running Search Routines\n\n\n\nThe process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.\nIdentifying references to datasets within scientific publications is inherently difficult for a number of reasons including:\n\nNo defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.\nName disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,\nConflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.\nSimple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.\n\nTo address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.\n\n\n\n\nScopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.\nThe USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors.\nThe full text records associated with the USDA search corpus is shown in Table 1:\n\n\n\nTable 1: Full Text Records Associated with USDA Search Corpus\n\n\n\n\n\n\n\n\n\n\nNumber of Records\n\n\n\n\n2017-2023 Articles from Topics\n726,423\n\n\n2017-2023 Articles from Journals\n1,537,851\n\n\n2017-2023 Articles from Top Authors\n21,938\n\n\nDe-duplicated Articles from Above\n2,089,728\n\n\nDeduplicated articles where we have full text\n1,630,958\n\n\nDeduplicated articles where we have full text and are licensed to search\n1,450,086\n\n\n\n\n\n\n\n\n\nA search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.\nBecause of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.\nThe reference search employs an exact text string matching routine across the references of the identified Scopus records.\nBecause of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.\n\n\n\nTable 2: Number of Records from Scopus References Search Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified in reference search\n25,588\n\n\nNumber of those publications that were unique to the reference search (i.e. not found by Kaggle models).\n22,818\n\n\nNumber of target data assets matched with the above publications\n34,526\n\n\n\n\n\n\n\n\n\nThe top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.\nThe models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.\nAs well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.\nWith a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:\n\nNASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service\n\nIn total, the use of flags was identified as being appropriate for 112 of the data assets.\nThe Kaggle routines were run in early December 2023 with the process completing on 14 December.\nA summary of some of the key results from the Full Text search is provided in Table 3:\n\n\n\nTable 3: Full Text Search Generated by Kaggle Routine\n\n\n\n\n\n\n\n\n\nProcess Step Outputs\nNumber of Records\n\n\n\n\nNumber of unique Scopus publications identified by the three Kaggle algorithms\n635,831\n\n\nNumber of unique publications identified after Fuzzy text matching to target data assets\n4,104\n\n\nNumber of target data assets matched in the above publications\n4,3921\n\n\nNumber of snippets generated\n14,3772\n\n\n\n\n\n\nPost Processing Adjustments – RUCC and QuickStat Increment\nNote that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:\n\nA new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.\nA fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.\n\n\n\n\n\nDescribe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API\nTo collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”\nThis method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.\nRefer to this Appendix for additional details on file construction.\n\n\nComing Soon",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 02: Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "workflow/step02_01/extract_dataset_mentions.html#footnotes",
    "href": "workflow/step02_01/extract_dataset_mentions.html#footnotes",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nExplanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.↩︎\nExplanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.↩︎",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 02: Extract Dataset Mentions"
    ]
  },
  {
    "objectID": "workflow/step02_02/02openalex.html",
    "href": "workflow/step02_02/02openalex.html",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "This report describes the process of generating a Seed Corpus and Search Corpus in the context of the Democratizing Data project, specifically using OpenAlex as the publication catalog. The goal is to facilitate more accurate identification of USDA dataset mentions in scholarly publications by using local full-text searches.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025)."
  },
  {
    "objectID": "workflow/step02_02/02openalex.html#openalex",
    "href": "workflow/step02_02/02openalex.html#openalex",
    "title": "Citation Database Assessment",
    "section": "",
    "text": "This report describes the process of generating a Seed Corpus and Search Corpus in the context of the Democratizing Data project, specifically using OpenAlex as the publication catalog. The goal is to facilitate more accurate identification of USDA dataset mentions in scholarly publications by using local full-text searches.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025)."
  },
  {
    "objectID": "workflow/step02_02/create_seed_corpus.html",
    "href": "workflow/step02_02/create_seed_corpus.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "After defining the data assets and aliases in Step 1, the next step is to identify where these datasets are referenced in research publications. Unlike OpenAlex and Dimensions, which allow for direct full-text searches, Scopus requires a structured seed corpus to establish a more targeted search space.\nFor Scopus, this seed corpus approach was necessary to balance recall (capturing relevant mentions) and precision (minimizing false positives). The process involved:\n\nRestricted search strategies using reference lists and available full-text searches\nMachine learning-assisted review to refine dataset mentions\nManual refinements to resolve ambiguities, consolidate duplicate aliases, and incorporate missing terms.\n\nThis structured search space helped mitigate the constraints of Scopus’s API and ensured that dataset mentions were captured as comprehensively as possible before proceeding to the data identification step.\n\nScopusOpenAlexDimensions\n\n\n\n\nThere are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.\n\n\n\n\n\nThis report describes the process of generating a Seed Corpus and Search Corpus in the context of the Democratizing Data project, specifically using OpenAlex as the publication catalog. The goal is to facilitate more accurate identification of USDA dataset mentions in scholarly publications by using local full-text searches.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025).\n\n\n\nThe seed corpus approach was only applied to Scopus.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Creating a Seed Corpus"
    ]
  },
  {
    "objectID": "workflow/step02_02/create_seed_corpus.html#sec-seed-corpus",
    "href": "workflow/step02_02/create_seed_corpus.html#sec-seed-corpus",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "After defining the data assets and aliases in Step 1, the next step is to identify where these datasets are referenced in research publications. Unlike OpenAlex and Dimensions, which allow for direct full-text searches, Scopus requires a structured seed corpus to establish a more targeted search space.\nFor Scopus, this seed corpus approach was necessary to balance recall (capturing relevant mentions) and precision (minimizing false positives). The process involved:\n\nRestricted search strategies using reference lists and available full-text searches\nMachine learning-assisted review to refine dataset mentions\nManual refinements to resolve ambiguities, consolidate duplicate aliases, and incorporate missing terms.\n\nThis structured search space helped mitigate the constraints of Scopus’s API and ensured that dataset mentions were captured as comprehensively as possible before proceeding to the data identification step.\n\nScopusOpenAlexDimensions\n\n\n\n\nThere are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision.\nIncreasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time.\nThese three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.\n\n\n\nThe process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with:\n\nfull-text records in ScienceDirect which are within a specified range of publication years, and\nthe reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).\n\nBecause some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,\n\n12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.\n71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service\n\nThe search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.\nThe metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:\n\nSciVal Topic – 2,699 unique topics in the seed corpus\nJournal – 2,650 unique journals in the seed corpus\nTop Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.\n\nIt should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.\nAs well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.\nThe results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of\n\ndecisions were taken with regards to the parameters to be used for creation of the search corpus, and\nthe implications of that decision on search corpus\n\n\n\n\nTable 1: Creating a Seed Corpus\n\n\n\n\n\n\n\n\n\n\nParameter\nSeed Corpus Detection\nConsequence / Implication for Seed Corpus\n\n\n\n\nSciVal Topics\nInclude those SciVal Topics where the article count in the Seed Corpus\nAll articles associated with 262 SciVal Topics\n\n\nJournals\nInclude those Journals where the article count in the Seed Corpus was 7 or more\nAll articles associated with 280 journals\n\n\nTop Authors\nInclude those with US affiliation\nAll articles associated with the US-affiliated 769 Top Authors\n\n\n\n\n\n\n\n\n\nFollowing the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.\nSpecifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.\nFinally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.\n\n\n\n\n\nThis report describes the process of generating a Seed Corpus and Search Corpus in the context of the Democratizing Data project, specifically using OpenAlex as the publication catalog. The goal is to facilitate more accurate identification of USDA dataset mentions in scholarly publications by using local full-text searches.\n\n\n\nPublications identified by dataset mention searches using Scopus were cross-verified in OpenAlex by searching their DOIs. These publications were confirmed to be open-access and available for full-text searches in OpenAlex. However, upon closer investigation, two primary issues were identified with OpenAlex’s full-text indexing methods:\n\nPDF vs. NGRAMS Indexing Methods:\n\nPDF Method: OpenAlex receives the publication’s full text in PDF format and indexes the content directly.\nNGRAMS Method: OpenAlex receives from the author or publisher a preprocessed set of words or phrases (ngrams) extracted from the publication’s full text.\n\nSpecific Issues:\n\nPDF Method Issue: Although undocumented, we observed that the text from the references section of the publications was not indexed by OpenAlex. This occurs because OpenAlex processes the references section specifically to create pointers to other OpenAlex works being referenced. While this approach functions well for publications referencing other scholarly publications, it fails to identify dataset mentions in the references.\nNGRAMS Method Issue: The provided set of ngrams might not include all relevant words or phrases required for dataset identification. For example, if searching for a specific alias such as “USDA Census,” the provided ngrams might not contain the exact phrase or all necessary words, causing missed dataset mentions.\n\n\nThese limitations with OpenAlex’s indexing methods highlighted the need to create dedicated seed and search corpora for accurate dataset mention identification.\n\n\n\nThe seed corpus generation aims to create an effective subset of publications available in OpenAlex to download locally and subsequently run text searches for dataset aliases and flagged terms.\n\n\n\nTo define the seed corpus, several criteria were established based on topics, publication type, publication year, language, and open-access availability. Below are detailed descriptions of the chosen criteria and associated publication counts.\n\n\n\nWe identified relevant topics based on their frequency and relevance. Below are the top 100 topics by publication count:\n\n\n\n\n\n\n\n\n\nTopic ID\nTopic Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nT11610\nImpact of Food Insecurity on Health Outcomes\n313\n78661\n\n\nT11610\nFood Security and Health in Diverse Populations\n236\n78661\n\n\nT10010\nGlobal Trends in Obesity and Overweight Research\n149\n111686\n\n\nT11066\nComparative Analysis of Organic Agricultural Practices\n141\n41275\n\n\nT12253\nUrban Agriculture and Community Development\n140\n27383\n\n\nT10010\nObesity, Physical Activity, Diet\n123\n111686\n\n\nT10367\nAgricultural Innovation and Livelihood Diversification\n110\n49818\n\n\nT11066\nOrganic Food and Agriculture\n106\n41275\n\n\nT11464\nImpact of Homelessness on Health and Well-being\n101\n101019\n\n\nT12253\nUrban Agriculture and Sustainability\n82\n27383\n\n\nT12033\nEuropean Agricultural Policy and Reform\n77\n88980\n\n\nT10367\nAgricultural Innovations and Practices\n76\n49818\n\n\nT11464\nHomelessness and Social Issues\n74\n101019\n\n\nT10841\nDiscrete Choice Models in Economics and Health Care\n72\n66757\n\n\nT10596\nMaternal and Child Nutrition in Developing Countries\n71\n118727\n\n\nT11898\nImpacts of Food Prices on Consumption and Poverty\n70\n29110\n\n\nT11259\nSustainable Diets and Environmental Impact\n65\n45082\n\n\nT12033\nAgricultural Economics and Policy\n60\n88980\n\n\nT10841\nEconomic and Environmental Valuation\n54\n66757\n\n\nT10439\nAdaptation to Climate Change in Agriculture\n50\n27311\n\n\nT10235\nImpact of Social Factors on Health Outcomes\n49\n86076\n\n\nT10866\nRole of Mediterranean Diet in Health Outcomes\n48\n76894\n\n\nT10596\nChild Nutrition and Water Access\n45\n118727\n\n\nT11259\nAgriculture Sustainability and Environmental Impact\n44\n45082\n\n\nT10330\nHydrological Modeling and Water Resource Management\n43\n132216\n\n\nT11886\nRisk Management and Vulnerability in Agriculture\n43\n44755\n\n\nT11898\nEconomics of Agriculture and Food Markets\n43\n29110\n\n\nT11311\nSoil and Water Nutrient Dynamics\n42\n52847\n\n\nT11311\nBiogeochemical Cycling of Nutrients in Aquatic Ecosystems\n42\n52847\n\n\nT10226\nGlobal Analysis of Ecosystem Services and Land Use\n40\n84104\n\n\nT10969\nOptimal Operation of Water Resources Systems\n39\n97570\n\n\nT12732\nImpact of Farming on Health and Safety\n33\n29731\n\n\nT10235\nHealth disparities and outcomes\n32\n86076\n\n\nT10226\nLand Use and Ecosystem Services\n31\n84104\n\n\nT11753\nForest Management and Policy\n31\n75196\n\n\nT10969\nWater resources management and optimization\n31\n97570\n\n\nT12098\nRural development and sustainability\n30\n62114\n\n\nT12724\nIntegrated Management of Water, Energy, and Food Resources\n30\n40148\n\n\nT11886\nAgricultural risk and resilience\n30\n44755\n\n\nT11753\nClimate Change Impacts on Forest Carbon Sequestration\n29\n75196\n\n\nT11711\nImpacts of COVID-19 on Global Economy and Markets\n29\n69059\n\n\nT10111\nRemote Sensing in Vegetation Monitoring and Phenology\n28\n56452\n\n\nT11404\nDeficit Irrigation for Agricultural Water Management\n27\n49715\n\n\nT10439\nClimate change impacts on agriculture\n27\n27311\n\n\nT11862\nAgroecology and Global Food Systems\n26\n34753\n\n\nT12583\nFood Waste Management and Reduction\n26\n27144\n\n\nT10004\nSoil Carbon Dynamics and Nutrient Cycling in Ecosystems\n26\n101907\n\n\nT10330\nHydrology and Watershed Management Studies\n26\n132216\n\n\nT10556\nGlobal Cancer Incidence and Mortality Patterns\n25\n64063\n\n\nT12098\nRural Development and Change in Agricultural Landscapes\n24\n62114\n\n\nT10111\nRemote Sensing in Agriculture\n24\n56452\n\n\nT10556\nGlobal Cancer Incidence and Screening\n24\n64063\n\n\nT10866\nNutritional Studies and Diet\n22\n76894\n\n\nT11560\nDynamics of Livestock Disease Transmission and Control\n22\n68578\n\n\nT10266\nGlobal Forest Drought Response and Climate Change\n22\n73291\n\n\nT12904\nAgricultural Education and School Gardening Research\n21\n110210\n\n\nT12003\nDevelopment and Impacts of Bioenergy Crops\n21\n36853\n\n\nT10298\nInfluence of Built Environment on Active Travel\n21\n86890\n\n\nT10029\nClimate Change and Variability Research\n20\n113541\n\n\nT11711\nCOVID-19 Pandemic Impacts\n20\n69059\n\n\nT10266\nPlant Water Relations and Carbon Dynamics\n20\n73291\n\n\nT11544\nGender Inequality and Labor Force Dynamics\n19\n98755\n\n\nT13388\nFactors Affecting Sagebrush Ecosystems and Wildlife Conservation\n19\n58614\n\n\nT12904\nDiverse Educational Innovations Studies\n18\n110210\n\n\nT12773\nWater Quality and Hydrogeology Research\n18\n50724\n\n\nT10435\nEnvironmental Impact and Sustainability\n18\n55580\n\n\nT11862\nAgriculture, Land Use, Rural Development\n18\n34753\n\n\nT10435\nLife Cycle Assessment and Environmental Impact Analysis\n18\n55580\n\n\nT13393\nFeeding Disorders in Children with Autism Spectrum Disorders\n17\n50595\n\n\nT12724\nWater-Energy-Food Nexus Studies\n17\n40148\n\n\nT11404\nIrrigation Practices and Water Management\n17\n49715\n\n\nT11560\nAnimal Disease Management and Epidemiology\n17\n68578\n\n\nT13393\nChild Nutrition and Feeding Issues\n16\n50595\n\n\nT11544\nGender, Labor, and Family Dynamics\n16\n98755\n\n\nT10298\nUrban Transport and Accessibility\n15\n86890\n\n\nT11789\nLand Tenure and Property Rights in Agriculture\n15\n46627\n\n\nT10391\nEconomics of Health Care Systems and Policies\n15\n260472\n\n\nT10692\nImpact of Urban Green Space on Public Health\n15\n40686\n\n\nT10889\nSoil Erosion and Agricultural Sustainability\n15\n72441\n\n\nT10004\nSoil Carbon and Nitrogen Dynamics\n14\n101907\n\n\nT10446\nIncome, Poverty, and Inequality\n14\n62906\n\n\nT12057\nImpact of Ultra-Processed Foods on Health\n14\n28199\n\n\nT12873\nImpact of Nutrition and Eating Habits on Health\n14\n43157\n\n\nT11645\nEffects of Residential Segregation on Communities and Individuals\n14\n50639\n\n\nT12583\nFood Waste Reduction and Sustainability\n13\n27144\n\n\nT12310\nFactors Affecting Maize Yield and Lodging Resistance\n13\n105863\n\n\nT10889\nSoil erosion and sediment transport\n13\n72441\n\n\nT10487\nImpact of Pollinator Decline on Ecosystems and Agriculture\n13\n218697\n\n\nT10576\nOpioid Epidemic in the United States\n13\n50143\n\n\nT11186\nGlobal Drought Monitoring and Assessment\n13\n35695\n\n\nT10552\nGlobal Trends in Colorectal Cancer Research\n13\n70491\n\n\nT11925\nFood Tourism and Gastronomy Research\n13\n95356\n\n\nT12399\nFactors Influencing Wine Tourism and Consumer Behavior\n13\n50383\n\n\nT12003\nBioenergy crop production and management\n13\n36853\n\n\nT13388\nRangeland and Wildlife Management\n12\n58614\n\n\nT10410\nModeling the Dynamics of COVID-19 Pandemic\n12\n67192\n\n\nT10190\nHealth Effects of Air Pollution\n12\n125501\n\n\nT12733\nBluetongue Virus and Culicoides-Borne Diseases in Europe\n12\n34477\n\n\nT11546\nPlant Physiology and Cultivation Studies\n12\n189058\n\n\nT11552\nGovernance of Global Value Chains and Production Networks\n12\n46357\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 1,192,809.\n\n\n\nWe selected the top journals to further refine our corpus. The following table lists the top 100 journals by publication count:\n\n\n\n\n\n\n\n\n\nJournal ID\nJournal Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nS2764628096\nJournal of Agriculture Food Systems and Community Development\n57\n825\n\n\nS115427279\nPublic Health Nutrition\n51\n3282\n\n\nS206696595\nJournal of Nutrition Education and Behavior\n41\n3509\n\n\nS15239247\nInternational Journal of Environmental Research and Public Health\n39\n59130\n\n\nS4210201861\nApplied Economic Perspectives and Policy\n39\n647\n\n\nS10134376\nSustainability\n35\n87533\n\n\nS5832799\nJournal of Soil and Water Conservation\n34\n556\n\n\nS2739393555\nJournal of Agricultural and Applied Economics\n34\n329\n\n\nS202381698\nPLoS ONE\n30\n143568\n\n\nS124372222\nRenewable Agriculture and Food Systems\n30\n426\n\n\nS91754907\nAmerican Journal of Agricultural Economics\n28\n876\n\n\nS200437886\nBMC Public Health\n28\n18120\n\n\nS18733340\nJournal of the Academy of Nutrition and Dietetics\n27\n5301\n\n\nS78512408\nAgriculture and Human Values\n27\n938\n\n\nS2764593300\nAgricultural and Resource Economics Review\n25\n247\n\n\nS110785341\nNutrients\n25\n30911\n\n\nS4210212157\nFrontiers in Sustainable Food Systems\n23\n3776\n\n\nS69340840\nThe Journal of Rural Health\n20\n749\n\n\nS63571384\nFood Policy\n20\n1069\n\n\nS19383905\nAgricultural Finance Review\n18\n327\n\n\nS4210234824\nEDIS\n18\n3714\n\n\nS119228529\nJournal of Hunger & Environmental Nutrition\n17\n467\n\n\nS204691207\nHortTechnology\n14\n847\n\n\nS4210212179\nJournal of Extension\n14\n1004\n\n\nS43295729\nRemote Sensing\n14\n33899\n\n\nS2738397068\nLand\n14\n9774\n\n\nS80485027\nLand Use Policy\n14\n4559\n\n\nS4210217848\nJAMA Network Open\n13\n12933\n\n\nS139338987\nEnvironmental Research Letters\n13\n6399\n\n\nS2595931848\nFrontiers in Public Health\n12\n19316\n\n\nS122347013\nAmerican Journal of Obstetrics and Gynecology\n12\n15259\n\n\nS204847658\nWater Resources Research\n12\n5305\n\n\nS73449225\nFood Security\n12\n899\n\n\nS4210219560\nCurrent Developments in Nutrition\n12\n10807\n\n\nS183652945\nHortScience\n11\n2415\n\n\nS196734849\nScientific Reports\n11\n198095\n\n\nS139950591\nAgronomy Journal\n10\n2675\n\n\nS86852077\nThe Science of The Total Environment\n10\n56249\n\n\nS37976914\nJAWRA Journal of the American Water Resources Association\n9\n852\n\n\nS2764587901\nJournal of Applied Communications\n9\n250\n\n\nS2607323502\nScientific Data\n9\n5287\n\n\nS44455300\nJournal of Environmental Management\n9\n17835\n\n\nS4210220469\nJournal of Applied Farm Economics\n8\n39\n\n\nS141808269\nRemote Sensing of Environment\n8\n4135\n\n\nS129060628\nDiabetes\n8\n17439\n\n\nS2475403985\nPreventing Chronic Disease\n8\n1068\n\n\nS156283932\nCalifornia Agriculture\n8\n233\n\n\nS157560195\nAgricultural Systems\n8\n1722\n\n\nS136211407\nEcological Economics\n8\n2684\n\n\nS23642417\nSociety & Natural Resources\n8\n792\n\n\nS2574783\nGynecologic Oncology\n8\n8756\n\n\nS149285975\nLand Economics\n8\n399\n\n\nS2594976040\nFrontiers in Veterinary Science\n7\n9896\n\n\nS8391440\nCancer Epidemiology Biomarkers & Prevention\n7\n6099\n\n\nS6596815\nRural Sociology\n7\n467\n\n\nS4210180312\nJournal of the Agricultural and Applied Economics Association\n7\n161\n\n\nS4210202585\nAgriculture\n7\n9931\n\n\nS79054089\nBMJ Open\n7\n31973\n\n\nS2764832999\nScientific investigations report\n7\n1270\n\n\nS180723199\nAgribusiness\n7\n583\n\n\nS154775064\nAgricultural Economics\n7\n729\n\n\nS2738534743\nJournal of Nutritional Science\n6\n659\n\n\nS2754843627\nCancer Medicine\n6\n7317\n\n\nS2228914\nHealth Services Research\n6\n1855\n\n\nS2764680059\nStatistical Journal of the IAOS\n6\n852\n\n\nS76844451\nAnnual Review of Resource Economics\n6\n206\n\n\nS207068962\nCommunity Development\n6\n516\n\n\nS148307540\nEcology and Society\n6\n1281\n\n\nS4210194219\nAntarctica A Keystone in a Changing World\n6\n1110\n\n\nS4210186936\nJournal of Agricultural Science\n6\n2412\n\n\nS12132826\nThe International Food and Agribusiness Management Review\n6\n464\n\n\nS4210197466\nAgroecology and Sustainable Food Systems\n6\n645\n\n\nS204799461\nClimatic Change\n6\n1992\n\n\nS139838620\nObstetrics and Gynecology\n6\n8132\n\n\nS2596909297\nFrontiers in Nutrition\n6\n9700\n\n\nS168049282\nAmerican Journal of Public Health\n6\n4777\n\n\nS106822843\nSocial Science & Medicine\n5\n5847\n\n\nS134216166\nWater\n5\n25819\n\n\nS28036099\nJournal of Rural Studies\n5\n2034\n\n\nS2737313858\nAgricultural & Environmental Letters\n5\n262\n\n\nS32361082\nEuropean Review of Agricultural Economics\n5\n362\n\n\nS178566096\nPreventive Veterinary Medicine\n5\n1907\n\n\nS150168663\nCancer Causes & Control\n5\n1136\n\n\nS106908163\nNeuro-Oncology\n5\n18986\n\n\nS178182516\nJournal of Agromedicine\n5\n565\n\n\nS116775814\nComputers and Electronics in Agriculture\n5\n5965\n\n\nS176659572\nHealth & Social Care in the Community\n5\n2064\n\n\nS2764613780\nJournal of Agricultural Safety and Health\n5\n138\n\n\nS99400149\nJournal of Health Care for the Poor and Underserved\n5\n1197\n\n\nS42419699\nPrecision Agriculture\n5\n1130\n\n\nS130750583\nGlobal Environmental Change\n5\n1092\n\n\nS2492648963\nTransactions of the ASABE\n5\n894\n\n\nS135458494\nPlant Disease\n5\n8264\n\n\nS72684844\nJournal of Animal Science\n5\n15499\n\n\nS173554290\nJournal of Community Health\n5\n1126\n\n\nS28349394\nJournal of Dairy Science\n5\n8060\n\n\nS88153332\nJournal of Nutrition\n5\n3469\n\n\nS199825796\nApplied Engineering in Agriculture\n5\n722\n\n\nS95823145\nForest Policy and Economics\n5\n1509\n\n\nS104641133\nAgricultural Water Management\n5\n4298\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 770,522.\n\n\n\nAuthors with American affiliations were selected to enhance corpus relevance:\n\n\n\n\n\n\n\n\n\nAuthor ID\nAuthor Name\nFirst Run Count\nOpenAlex Total Count\n\n\n\n\nA5016803484\nHeather A. Eicher‐Miller\n15\n140\n\n\nA5024975191\nEdward A. Frongillo\n13\n351\n\n\nA5055158106\nBecca B.R. Jablonski\n12\n60\n\n\nA5047780964\nMeredith T. Niles\n11\n200\n\n\nA5015017711\nJeffrey K. O’Hara\n10\n27\n\n\nA5062679478\nJ. Gordon Arbuckle\n10\n68\n\n\nA5068812455\nCindy W. Leung\n10\n170\n\n\nA5076121862\nSheri D. Weiser\n10\n241\n\n\nA5081656928\nWhitney E. Zahnd\n9\n147\n\n\nA5008463933\nCatherine Brinkley\n8\n34\n\n\nA5027684365\nDayton M. Lambert\n8\n110\n\n\nA5002438645\nPhyllis C. Tien\n8\n244\n\n\nA5081012770\nLinda J. Young\n8\n51\n\n\nA5030548116\nMichele Ver Ploeg\n8\n33\n\n\nA5035584432\nAngela D. Liese\n8\n172\n\n\nA5032940306\nLisa Harnack\n7\n89\n\n\nA5008296893\nEryka Wentz\n7\n33\n\n\nA5006129622\nCarmen Byker Shanks\n7\n103\n\n\nA5053170901\nAni L. Katchova\n7\n62\n\n\nA5024127854\nEduardo Villamor\n7\n84\n\n\nA5060802257\nTracey E. Wilson\n7\n102\n\n\nA5050792105\nJennifer L. Moss\n7\n90\n\n\nA5040727809\nGeorge B. Frisvold\n7\n66\n\n\nA5056021318\nNathan Hendricks\n7\n320\n\n\nA5034750133\nLila A. Sheira\n7\n61\n\n\nA5044317355\nDaniel Merenstein\n7\n113\n\n\nA5002732604\nJulia A. Wolfson\n7\n137\n\n\nA5015455112\nHikaru Hanawa Peterson\n7\n56\n\n\nA5024248662\nAdebola Adedimeji\n7\n137\n\n\nA5038610136\nChristopher N. Boyer\n7\n115\n\n\nA5101813658\nChristian J. Peters\n7\n32\n\n\nA5035164673\nStephan J. Goetz\n6\n90\n\n\nA5029397288\nAmy L. Yaroch\n6\n113\n\n\nA5022651324\nSeth A. Berkowitz\n6\n158\n\n\nA5083470674\nMardge H. Cohen\n6\n205\n\n\nA5070284513\nTimothy S. Griffin\n6\n59\n\n\nA5026810637\nJoleen C. Hadrich\n6\n30\n\n\nA5013419936\nNigel Key\n6\n25\n\n\nA5062332393\nAlessandro Bonanno\n6\n61\n\n\nA5012666568\nHilary K. Seligman\n6\n123\n\n\nA5071854708\nBurton C. English\n6\n68\n\n\nA5069981543\nMegan Konar\n6\n86\n\n\nA5083406390\nZach Conrad\n6\n123\n\n\nA5074296013\nSuat Irmak\n6\n151\n\n\nA5079036202\nJames A. Larson\n6\n49\n\n\nA5038417176\nAdaora A. Adimora\n6\n334\n\n\nA5045489628\nSelena Ahmed\n6\n89\n\n\nA5057302432\nAlan W. Hodges\n6\n73\n\n\nA5091590760\nCraig Gundersen\n6\n69\n\n\nA5089578074\nParke Wilde\n6\n107\n\n\nA5063008522\nA. D. Kendall\n6\n119\n\n\nA5100771544\nHanqin Tian\n6\n434\n\n\nA5072286156\nD. W. Hyndman\n6\n130\n\n\nA5052456209\nKartika Palar\n6\n59\n\n\nA5042679164\nJeffrey Gillespie\n6\n30\n\n\nA5091103546\nKimberly L. Jensen\n6\n65\n\n\nA5014800024\nKartik K. Venkatesh\n5\n244\n\n\nA5003088939\nFrances Hardin‐Fanning\n5\n32\n\n\nA5028409673\nLauri M. Baker\n5\n60\n\n\nA5087431618\nGabrielle Roesch‐McNally\n5\n36\n\n\nA5112481717\nJianhong E. Mu\n5\n20\n\n\nA5067158518\nLisa R. Metsch\n5\n133\n\n\nA5051019392\nDawn Thilmany McFadden\n5\n20\n\n\nA5065308164\nEdward C. Jaenicke\n5\n59\n\n\nA5035062421\nKatherine Dentzman\n5\n35\n\n\nA5011693138\nRyan S. Miller\n5\n163\n\n\nA5019910416\nHolly Gibbs\n5\n69\n\n\nA5014991206\nMargarita Velandia\n5\n29\n\n\nA5081521085\nMark Lubell\n5\n80\n\n\nA5007931812\nTyler J. Lark\n5\n77\n\n\nA5078358162\nJanet M. Turan\n5\n189\n\n\nA5089582462\nLynn M. Yee\n5\n426\n\n\nA5040186224\nNathanael M. Thompson\n5\n32\n\n\nA5070695418\nIghovwerha Ofotokun\n5\n105\n\n\nA5018179894\nAmir M. Rahmani\n5\n264\n\n\nA5057015263\nDawn Thilmany\n5\n34\n\n\nA5038972534\nJyotsna S. Jagai\n5\n48\n\n\nA5003676504\nLandon Marston\n5\n84\n\n\nA5079390198\nChen Zhen\n5\n48\n\n\nA5043968039\nW. David Mulkey\n5\n7\n\n\nA5072793478\nClayton Hallman\n5\n11\n\n\nA5016915956\nJohn Tyndall\n5\n35\n\n\nA5044462604\nJohn M. Antle\n5\n49\n\n\nA5105267439\nColleen T. Webb\n5\n44\n\n\nA5016997673\nMiguel I. Gómez\n5\n138\n\n\nA5006518901\nAndrea Leschewski\n5\n18\n\n\nA5022734861\nAllison Bauman\n5\n32\n\n\nA5010819579\nLisa Chase\n5\n34\n\n\nA5044003446\nW. Jay Christian\n5\n50\n\n\nA5022220353\nBailey Houghtaling\n5\n72\n\n\nA5066919611\nRick Welsh\n5\n20\n\n\nA5053832932\nEric M. Clark\n4\n41\n\n\nA5002482027\nBenjamin M. Gramig\n4\n46\n\n\nA5029506929\nCourtney D. Lynch\n4\n84\n\n\nA5031318120\nJessica Rudnick\n4\n15\n\n\nA5046729938\nSteven R. Browning\n4\n23\n\n\nA5052396793\nLindsay M. Beck‐Johnson\n4\n13\n\n\nA5027592346\nDennis P. Swaney\n4\n26\n\n\nA5042166415\nDavid H. Fleisher\n4\n69\n\n\nA5008867112\nKatie Portacci\n4\n14\n\n\n\nFilters applied: - Language: English (en) - Publication Year: &gt;2017 - Type: article, review - Open Access: True\nFiltered publications count: 3,714.\n\n\n\nUpon applying the agreed filters, the final seed corpus resulted in 1,774,245 unique publications. An initial Python script was developed to collect full texts of these publications.\n\n\n\n\n\n\nMetric\nResult\n\n\n\n\nTotal publications attempted\n2,774\n\n\nSuccessfully downloaded full-texts\n974\n\n\nSuccess Rate\n35%\n\n\nEstimated full texts (projected)\n625,000 out of 1,774,245\n\n\nTotal estimated processing time\n~124 days\n\n\n\nThe relatively low success rate indicates significant challenges in accessing full texts, primarily due to missing or inaccessible OA URLs.\n\n\n\n\nOnly 35% success rate in downloading full texts.\nThe existing process is slow, computationally intensive, and likely to require improvements or distributed computing.\nComparison with OpenAlex’s built-in full-text search shows it might be sufficient in certain cases, potentially reducing the necessity of local processing.\n\n\n\n\n\nImplement distributed processing to accelerate corpus generation.\nAssess the adequacy of OpenAlex’s built-in full-text search for practical usage scenarios.\nBalance the need for accuracy with available resources (time and cost).\n\n\n\n\n\nOpenAlex API documentation: OpenAlex Works API\nOA filtered results: OpenAlex Filtered Corpus\nOpenAlex: https://docs.openalex.org\n\n\n\n\nCreating a locally processed seed corpus from OpenAlex significantly improves dataset mention accuracy but poses considerable resource demands. While local full-text processing enhances specificity, careful consideration is required regarding when OpenAlex’s native search capabilities are sufficient.\n\nReferences: - OpenAlex API Documentation: https://docs.openalex.org - Democratizing Data project repository and guidelines (internal documentation, 2025). - USDA Dataset Project Documentation (Internal Document, 2025).\n\n\n\nThe seed corpus approach was only applied to Scopus.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Creating a Seed Corpus"
    ]
  },
  {
    "objectID": "workflow/step03/clean_pub_data.html",
    "href": "workflow/step03/clean_pub_data.html",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to standardize and resolve inconsistencies in publication records by disambiguating journal names, author affiliations, and institutions across the three databases.\n\nTo compare publication coverage across citation databases, we first identify all journals that contain publications using each dataset in Scopus, OpenAlex, and Dimensions. Refer to “Define Data Assets” for the list of the datasets for which we evaluate coverage.\nWe subset the publication dataset from Step 2 by filtering for dataset mentions. For example, if a publication references Ag Census, it is included in the Ag Census sub-dataset; otherwise, it is excluded. This process identifies dataset-specific publication patterns in Scopus, OpenAlex, and Dimensions.\nOur approach follows a hierarchical approach to understand how USDA data assets appear in these citation databases.\n\nJournal Level – Identifies journals publishing research using USDA datasets. A journal is included if at least one of its publications references the dataset, but this does not indicate overall dataset prevalence within that journal.\nPublication Level – Examines individual publications within these journals to assess how often and in what context USDA datasets appear.\nAuthor Level – Tracks authors of these publications, analyzing institutional affiliations and research networks to understand dataset reach.\nInstitution Level – Maps dataset usage across institutions to identify geographic and organizational research patterns.\n\nThis structured approach standardizes dataset mention analysis across databases, allowing for direct comparisons of coverage and research impact.\n\n\n\nTo illustrate the data cleaning and disambiguation process, we use the Census of Agriculture as a case study to systematically compare coverage, overlap, and differences between the three citation databases. The Census of Agriculture (also referred to as “Ag Census”) is widely used in agricultural and economic research, making it an ideal dataset for assessing database differences.\n\n\n\nScopus\n\n\n\n\nTo analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON\n\n\n\n\n\n\n\n\n\nThis section presents overall statistics for Scopus and OA. Each subsection will have results reported for each dataset\nStep 4 produces two publication-level datasets: one of all academic papers released through Scopus that use Ag Census data and a similar one for OpenAlex.\nThere are 4712 unique publications reported in Scopus and 1266 in OpenAlex. These data are collapsed into a journal-level dataset based on the International Standard Serial Number (ISSN) that is unique to each academic journal.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 03: Clean Publication Data"
    ]
  },
  {
    "objectID": "workflow/step03/clean_pub_data.html#sec-disambiguation",
    "href": "workflow/step03/clean_pub_data.html#sec-disambiguation",
    "title": "Methodology for Comparing Citation Database Coverage of Dataset Usage",
    "section": "",
    "text": "The goal of this step is to standardize and resolve inconsistencies in publication records by disambiguating journal names, author affiliations, and institutions across the three databases.\n\nTo compare publication coverage across citation databases, we first identify all journals that contain publications using each dataset in Scopus, OpenAlex, and Dimensions. Refer to “Define Data Assets” for the list of the datasets for which we evaluate coverage.\nWe subset the publication dataset from Step 2 by filtering for dataset mentions. For example, if a publication references Ag Census, it is included in the Ag Census sub-dataset; otherwise, it is excluded. This process identifies dataset-specific publication patterns in Scopus, OpenAlex, and Dimensions.\nOur approach follows a hierarchical approach to understand how USDA data assets appear in these citation databases.\n\nJournal Level – Identifies journals publishing research using USDA datasets. A journal is included if at least one of its publications references the dataset, but this does not indicate overall dataset prevalence within that journal.\nPublication Level – Examines individual publications within these journals to assess how often and in what context USDA datasets appear.\nAuthor Level – Tracks authors of these publications, analyzing institutional affiliations and research networks to understand dataset reach.\nInstitution Level – Maps dataset usage across institutions to identify geographic and organizational research patterns.\n\nThis structured approach standardizes dataset mention analysis across databases, allowing for direct comparisons of coverage and research impact.\n\n\n\nTo illustrate the data cleaning and disambiguation process, we use the Census of Agriculture as a case study to systematically compare coverage, overlap, and differences between the three citation databases. The Census of Agriculture (also referred to as “Ag Census”) is widely used in agricultural and economic research, making it an ideal dataset for assessing database differences.\n\n\n\nScopus\n\n\n\n\nTo analyze journal coverage in Scopus, we generate a dataset containing all unique journals that include at least one publication referencing Ag Census data. This dataset is built from an initial publication-level dataset, which captures individual research articles mentioning Ag Census.\nWe construct the publication-level dataset for only Ag Census mentions using the following metadata from the publication-level data:\n\nPublication identifier (DOI)\nJournal name\nPublisher\nISSN (International Standard Serial Number, a unique journal identifier)\nDataset alias (alternate names used to reference Ag Census)\nDyad (dataset mention pair)\n\nThis data structure follows the format outlined in the data schema (Figure XX).\n\n\n\n\n\n\nCrosswalk of Dataset Identifiers between Scopus and OpenAlex\n\n\n\n\n\nScopus assigns multiple identifiers to the same dataset depending on how it is reported, rather than a single, standardized identifier. Therefore, the authors create a crosswalk between Scopus and OpenAlex so that each dataset can have one common identifier.\nLink to crosswalk file\n\n\n\nAfter assembling the publication-level dataset, the final step in preparing the Scopus journal-level dataset is to aggregate publications at the journal level based on their ISSN.\n\n\n\nCOMING SOON\n\n\n\nCOMING SOON\n\n\n\n\n\n\n\n\n\nThis section presents overall statistics for Scopus and OA. Each subsection will have results reported for each dataset\nStep 4 produces two publication-level datasets: one of all academic papers released through Scopus that use Ag Census data and a similar one for OpenAlex.\nThere are 4712 unique publications reported in Scopus and 1266 in OpenAlex. These data are collapsed into a journal-level dataset based on the International Standard Serial Number (ISSN) that is unique to each academic journal.",
    "crumbs": [
      "Appendices",
      "Project Workflow",
      "Step 03: Clean Publication Data"
    ]
  }
]