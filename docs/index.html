<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lauren Chenarides, Ph.D.">
<meta name="author" content="Calvin Bryan, Ph.D.">
<meta name="author" content="Rafael Ladislau">
<meta name="author" content="Julia Lane, Ph.D.">
<meta name="author" content="Ming Wang">
<meta name="dcterms.date" content="2025-02-20">

<title>Methodology for Comparing Citation Database Coverage of Dataset Usage – Citation Database Assessment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Citation Database Assessment</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Technical Report</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">Contributors</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./appendices.html"> 
<span class="menu-text">Appendices</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/laurenchenarides/compare_scopus_openalex_report"> <i class="bi bi-github" role="img" aria-label="GitHub Repository">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#executive-summary" id="toc-executive-summary" class="nav-link active" data-scroll-target="#executive-summary"><span class="header-section-number">1</span> Executive Summary</a></li>
  <li><a href="#terminology" id="toc-terminology" class="nav-link" data-scroll-target="#terminology"><span class="header-section-number">2</span> Terminology</a></li>
  <li><a href="#project-background" id="toc-project-background" class="nav-link" data-scroll-target="#project-background"><span class="header-section-number">3</span> Project Background</a>
  <ul class="collapse">
  <li><a href="#sec-scopus" id="toc-sec-scopus" class="nav-link" data-scroll-target="#sec-scopus"><span class="header-section-number">3.1</span> Scopus</a></li>
  <li><a href="#sec-openalex" id="toc-sec-openalex" class="nav-link" data-scroll-target="#sec-openalex"><span class="header-section-number">3.2</span> OpenAlex</a></li>
  <li><a href="#sec-dimensions" id="toc-sec-dimensions" class="nav-link" data-scroll-target="#sec-dimensions"><span class="header-section-number">3.3</span> Dimensions</a></li>
  </ul></li>
  <li><a href="#project-workflow" id="toc-project-workflow" class="nav-link" data-scroll-target="#project-workflow"><span class="header-section-number">4</span> Project Workflow</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">4.1</span> Overview</a></li>
  <li><a href="#sec-data" id="toc-sec-data" class="nav-link" data-scroll-target="#sec-data"><span class="header-section-number">4.2</span> Step 1: Define Data Assets and Aliases</a>
  <ul class="collapse">
  <li><a href="#national-agricultural-statistics-service-nass-data-assets" id="toc-national-agricultural-statistics-service-nass-data-assets" class="nav-link" data-scroll-target="#national-agricultural-statistics-service-nass-data-assets"><span class="header-section-number">4.2.1</span> National Agricultural Statistics Service (NASS) Data Assets</a></li>
  <li><a href="#economic-research-service-ers-data-assets" id="toc-economic-research-service-ers-data-assets" class="nav-link" data-scroll-target="#economic-research-service-ers-data-assets"><span class="header-section-number">4.2.2</span> Economic Research Service (ERS) Data Assets</a></li>
  </ul></li>
  <li><a href="#sec-seed-corpus" id="toc-sec-seed-corpus" class="nav-link" data-scroll-target="#sec-seed-corpus"><span class="header-section-number">4.3</span> Step 2: Create a Seed Corpus</a></li>
  <li><a href="#sec-data-extraction" id="toc-sec-data-extraction" class="nav-link" data-scroll-target="#sec-data-extraction"><span class="header-section-number">4.4</span> Step 3: Dataset Extraction</a></li>
  <li><a href="#sec-disambiguation" id="toc-sec-disambiguation" class="nav-link" data-scroll-target="#sec-disambiguation"><span class="header-section-number">4.5</span> Step 4: Disambiguation Process</a>
  <ul class="collapse">
  <li><a href="#results-from-disambiguation" id="toc-results-from-disambiguation" class="nav-link" data-scroll-target="#results-from-disambiguation"><span class="header-section-number">4.5.10</span> Results from Disambiguation</a></li>
  </ul></li>
  <li><a href="#sec-matching" id="toc-sec-matching" class="nav-link" data-scroll-target="#sec-matching"><span class="header-section-number">4.6</span> Step 5: Comparison across Datasets</a>
  <ul class="collapse">
  <li><a href="#results-from-database-comparison" id="toc-results-from-database-comparison" class="nav-link" data-scroll-target="#results-from-database-comparison"><span class="header-section-number">4.6.10</span> Results from Database Comparison</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#recommendations" id="toc-recommendations" class="nav-link" data-scroll-target="#recommendations"><span class="header-section-number">5</span> Recommendations</a>
  <ul class="collapse">
  <li><a href="#technical-recommendations" id="toc-technical-recommendations" class="nav-link" data-scroll-target="#technical-recommendations"><span class="header-section-number">5.1</span> Technical Recommendations</a></li>
  <li><a href="#expanding-dataset-usage" id="toc-expanding-dataset-usage" class="nav-link" data-scroll-target="#expanding-dataset-usage"><span class="header-section-number">5.2</span> Expanding Dataset Usage</a></li>
  </ul></li>
  <li><a href="#conclusion-and-next-steps" id="toc-conclusion-and-next-steps" class="nav-link" data-scroll-target="#conclusion-and-next-steps"><span class="header-section-number">6</span> Conclusion and Next Steps</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">7</span> References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Methodology for Comparing Citation Database Coverage of Dataset Usage</h1>
<p class="subtitle lead">Technical Report</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Lauren Chenarides, Ph.D. <a href="mailto:Lauren.Chenarides@colostate.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Colorado State University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Calvin Bryan, Ph.D. <a href="mailto:calvinrbryan@gmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Colorado State University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Rafael Ladislau <a href="mailto:rafa.ladis@gmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            RL Desenvolvimento de Sistemas LTDA
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Julia Lane, Ph.D. <a href="mailto:julia.lane@nyu.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            New York University
          </p>
      </div>
    <div class="quarto-title-meta-contents">
    <p class="author">Ming Wang <a href="mailto:Ming.Wang@colostate.edu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Colorado State University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 20, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="executive-summary" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Executive Summary</h1>
<p>Federal agencies like the US Department of Agriculture (USDA) track how their datasets are referenced in research papers and disseminate data usage statistics through platforms like <a href="https://democratizingdata.ai/tools/dashboards/">DemocratizingData.ai</a> and <a href="https://www.nass.usda.gov/Data_Visualization/5W/index.php">NASS’s 5’s Data Usage Dashboard</a>. This report presents a methodology for comparing citation databases as potential data sources for identifying dataset mentions within research papers, using Scopus, OpenAlex, and Dimensions as test cases. The methods described can be applied to evaluate other citation databases such as Web of Science, Crossref, and Microsoft Academic, to name a few.</p>
<p>Citation databases track academic research output. Different databases curate content (i.e., research output) in different ways - some focus on peer-reviewed journals while others include preprints and technical reports. Tracking dataset usage requires developing methods that scan publication text for dataset mentions. The accuracy of dataset tracking depends on the scope of research output we can access and analyze. Not to mention, dataset tracking requires reliable citation data from citation databases.</p>
<p>The <strong>three</strong> citation databases we are comparing are Elsevier’s Scopus, OurResearch’s OpenAlex, and Digital Science’s Dimensions.ai. <strong>Scopus</strong> (<a href="#sec-scopus" class="quarto-xref">Section&nbsp;3.1</a>) charges for access to its citation database. It focuses on peer-reviewed literature and provides metadata about authors, institutions, and citations for academic journals. <strong>OpenAlex</strong> (<a href="#sec-openalex" class="quarto-xref">Section&nbsp;3.2</a>), an open-source platform, offers free metadata access. It covers both traditional academic publications and other research outputs like preprints and technical reports. <strong>Dimensions</strong> (<a href="#sec-dimensions" class="quarto-xref">Section&nbsp;3.3</a>), developed by Digital Science, offers a hybrid model that provides both free and subscription-based access to its citation database. Unlike Scopus, which primarily indexes peer-reviewed journal articles, and OpenAlex, which emphasizes open-access content, Dimensions aggregates a broad spectrum of research outputs, including journal articles, books, clinical trials, patents, datasets, and policy documents. It integrates citation data with funding information, making it a useful tool for assessing the impact of research beyond traditional academic publishing.</p>
<p>Our methodology provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. We developed procedures for:</p>
<ul>
<li>Identifying publication coverage across citation databases</li>
<li>Deduplicating author records</li>
<li>Standardizing institution names</li>
<li>Cross-referencing publications between datasets</li>
<li>Analyzing research themes and institutional representation</li>
</ul>
<!---Beyond platform comparison, this methodology examines inclusivity in research coverage, particularly representation of MSIs. This component helps identify potential gaps in dataset accessibility and adoption across different types of research institutions.--->
<p>Our comparison of citation databases found:</p>
<ul>
<li>After deduplication, the number of distinct authors decreased by XX% in Scopus and XX% in OpenAlex, indicating significant duplicate entries in the raw data</li>
<li>Institutional coverage was broader in XX, with XX% more institutions represented compared to XX</li>
<li>Analysis revealed XX major themes in USDA dataset usage, with ?? and ?? being the most prominent</li>
<li>Minority-Serving Institutions (MSIs) represented only XX% of institutional users, highlighting opportunities for broader engagement</li>
</ul>
<p>The methodology produced these reusable components:</p>
<ul>
<li>Code repository for data cleaning and standardization</li>
<li>Cleaned author tables with disambiguated names and institutional affiliations</li>
<li>Standardized institution tables using IPEDS identifiers</li>
<li>Crosswalk table structure linking Scopus and OpenAlex publication records, authors, and institutions</li>
<li>Data schema documentation [Last updated: January 3, 2025]</li>
</ul>
</section>
<section id="terminology" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Terminology</h1>
<p>Citation databases form the foundation of modern research tracking and analysis. Digital repositories, like the test cases featured in this report, systematically catalog scholarly publications and their references to each other <span class="citation" data-cites="debellis2009bibliometrics">(<a href="#ref-debellis2009bibliometrics" role="doc-biblioref">De Bellis, 2009</a>)</span>. Citation databases differ in their approaches to curating and maintaining this information. Some focus exclusively on peer-reviewed journal articles with strict inclusion criteria, while others index a broader range of research outputs including preprints, technical reports, and conference proceedings <span class="citation" data-cites="martin2021google mongeon2016journal">(<a href="#ref-martin2021google" role="doc-biblioref">Martín-Martín et al., 2021</a>; <a href="#ref-mongeon2016journal" role="doc-biblioref">Mongeon &amp; Paul-Hus, 2016</a>)</span>. These curation approaches affect how comprehensively each database captures research impact <span class="citation" data-cites="visser2021large">(<a href="#ref-visser2021large" role="doc-biblioref">Visser et al., 2021</a>)</span>.</p>
<p>Understanding how these databases work requires familiarity with bibliometrics - the statistical analysis of published works and their impact <span class="citation" data-cites="broadus1987toward">(<a href="#ref-broadus1987toward" role="doc-biblioref">Broadus, 1987</a>)</span>. Bibliometric analysis examines patterns in publication, citation networks, and research influence <span class="citation" data-cites="hood2001literature">(<a href="#ref-hood2001literature" role="doc-biblioref">Hood &amp; Wilson, 2001</a>)</span>. The field emerged from early citation indices, which mapped relationships between papers through their references <span class="citation" data-cites="garfield1955citation">(<a href="#ref-garfield1955citation" role="doc-biblioref">Garfield, 1955</a>)</span>.</p>
<p>For tracking USDA dataset usage, these concepts directly apply. Accurate tracking of dataset usage in scientific literature serves multiple purposes. For federal agencies like the USDA, it helps monitor the return on public data investments, find gaps in dataset use, plan future data collection, and support evidence-based policy decisions. This tracking requires reliable citation data from citation databases. Unlike standard citations, researchers often reference datasets within the text of their publications rather than citing them formally. This makes tracking dataset usage more complex.</p>
<p>To solve this tracking challenge, methods have been developed that scan publication text for dataset mentions <span class="citation" data-cites="lane2022data">(<a href="#ref-lane2022data" role="doc-biblioref">Lane et al., 2022</a>)</span>. The scope and accuracy of our dataset tracking depends on what publications we can access and analyze. Because different databases curate content in different ways, it creates variation in what dataset mentions they capture and their frequency. Variations in content across sources affect our ability to accurately track dataset impact and adoption. The DemocratizingData.ai platform, for example, uses bibliometric data to monitor these dataset usage patterns, helping USDA understand how its data supports research. By comparing how different citation databases track this information, we can better understand their strengths and limitations for monitoring research impact.</p>
</section>
<section id="project-background" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Project Background</h1>
<p>The DemocratizingData.ai platform currently uses Scopus, a fee-based service, to track USDA dataset usage. OpenAlex, an open-source alternative, offers potential cost savings and broader access. Moving to OpenAlex would reduce operational costs while maintaining public access to USDA’s dataset usage metrics. However, the decision to transition from Scopus to OpenAlex requires systematic evaluation of their coverage and data quality.</p>
<p>Initial comparisons between Scopus and OpenAlex revealed unexpected patterns in coverage overlap. These findings suggested that simply replacing one database with another might affect the platform’s ability to track dataset usage accurately.</p>
<p>This led to the development of a methodology for comparing citation databases, focusing on four areas:</p>
<ol type="1">
<li>Journal coverage: Determining which journals each platform indexes</li>
<li>Publication tracking: Comparing how each platform captures publications within indexed journals</li>
<li>Author identification: Evaluating how each platform handles author names and affiliations</li>
<li>Institution recognition: Determining how each platform records and standardizes institutional information</li>
</ol>
<p>Research partners at the University of Utah have access to Dimensions. The scope of work expanded to include Dimensions alongside Scopus and OpenAlex. This inclusion provides a more comprehensive assessment of citation databases, particularly in evaluating dataset coverage across both proprietary and open-access platforms.</p>
<p>Our methodology provides a systematic approach for assessing citation databases’ strengths and limitations in tracking dataset usage across research papers. Beyond platform comparison, this methodology examines differences in research coverage, particularly the presence of MSIs. This component helps identify variations in dataset coverage and usage across different types of research institutions.</p>
<p>The methods described in this report can be applied to other citation databases as alternatives to current data sources.</p>
<section id="sec-scopus" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-scopus"><span class="header-section-number">3.1</span> Scopus</h2>
</section>
<section id="sec-openalex" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-openalex"><span class="header-section-number">3.2</span> OpenAlex</h2>
</section>
<section id="sec-dimensions" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sec-dimensions"><span class="header-section-number">3.3</span> Dimensions</h2>
</section>
</section>
<section id="project-workflow" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Project Workflow</h1>
<section id="overview" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">4.1</span> Overview</h2>
<p>The project workflow outlines the steps involved to evaluate how different citation databases track USDA dataset mentions in research papers. In searching for dataset mentions, the goal is to identify a set of publications that can be compared across the citation database test cases.</p>
<p>The process of deriving the list of publications consists of five steps:</p>
<p><strong>1. Define Data Assets and Aliases</strong> (<a href="#sec-data" class="quarto-xref">Section&nbsp;4.2</a>)</p>
<ul>
<li>Identify USDA datasets that will be searched for and tracked.</li>
<li>Collect official dataset names along with common abbreviations, acronyms, and alternative references used.</li>
</ul>
<p><strong>Result:</strong> A structured list of dataset names and aliases to be used for search strategies.</p>
<p><strong>2. Create a Seed Corpus</strong> (<a href="#sec-seed-corpus" class="quarto-xref">Section&nbsp;4.3</a>)</p>
<ul>
<li>Collect an initial set of publications.</li>
<li>Analyze how datasets are referenced.</li>
<li>Determine how well the dataset name variations (from Step 1) are retreived from the publications.</li>
<li>Adjust searches to improve accuracy.</li>
</ul>
<p><strong>Result:</strong> A set of seed publications to inform dataset extraction procedure.</p>
<p><strong>3. Dataset Extraction</strong> (<a href="#sec-data-extraction" class="quarto-xref">Section&nbsp;4.4</a>)</p>
<ul>
<li>Extract dataset mentions using various search strategies:
<ul>
<li>Machine Learning Models: Apply Kaggle competition models trained to detect dataset mentions.</li>
<li>Full-Text (String) Search: Scan entire articles for relevant dataset names.</li>
<li>Reference Search: Identify dataset citations within publication references.</li>
</ul></li>
</ul>
<p><strong>Result:</strong> Different extraction methods yield different sets of publication results.</p>
<p><strong>4. Disambiguation Process</strong> (<a href="#sec-disambiguation" class="quarto-xref">Section&nbsp;4.5</a>)</p>
<ul>
<li>Pre-process and clean publication metadata for each citation database.</li>
<li>Standardize journal, institution, and author names.</li>
<li>Deduplicate records.</li>
</ul>
<p><strong>Result:</strong> Cleaned publication metadata, removed of duplicates, inconsistencies, and missing information.</p>
<p><strong>5. Comparison across Databases</strong> (<a href="#sec-matching" class="quarto-xref">Section&nbsp;4.6</a>)</p>
<ul>
<li>Compare dataset coverage across Scopus, OpenAlex, and Dimensions.</li>
<li>Apply fuzzy matching techniques to identify overlapping and unique dataset mentions.</li>
<li>Analyze differences in journal coverage, citation patterns, and author affiliations.</li>
</ul>
<p><strong>Result:</strong> In generating these statistics, we can evaluate the impact of switching databases on dataset tracking accuracy.</p>
</section>
<section id="sec-data" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-data"><span class="header-section-number">4.2</span> Step 1: Define Data Assets and Aliases</h2>
<p>The data assets featured here consist of those collected by the USDA, primarily from the Economic Research Service (ERS) and the National Agricultural Statistics Service (NASS). These datasets are widely used in agricultural economics and food systems research. The goal of this step is to compile a structured list of dataset names and their commonly used variations.</p>
<section id="national-agricultural-statistics-service-nass-data-assets" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="national-agricultural-statistics-service-nass-data-assets"><span class="header-section-number">4.2.1</span> National Agricultural Statistics Service (NASS) Data Assets</h3>
<p>In late July 2023, an initial set of 21 reports were received containing a report name and a URL link to the Cornell database. The names of these reports were characterized be being very generic in nature e.g.&nbsp;“Agricultural Prices” and “Farm Labor”. This input was analysed and transformed into a list that also contained ISSN inputs and which appended generic names with the term report. An ISSN term was identified for each of the 21 reports. The report names were characterized as the main data asset (the parent record) and the ISSNs and URLs were used as aliases. There were 43 such aliases. In total there were therefore 64 (43 + 21) search terms associated with this input.</p>
</section>
<section id="economic-research-service-ers-data-assets" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="economic-research-service-ers-data-assets"><span class="header-section-number">4.2.2</span> Economic Research Service (ERS) Data Assets</h3>
<p>The list of ERS Data Assets was provided during October 2023. In the original list 2,103 records were provided, many of which also had identified aliases. The list was reviewed by professor Julia Lane and 144 records were removed on the basis that they were not amendable for use within the Machine Learning routines. That review was completed on 29 October. The principal reasons for exclusion were terms either being too generic or they were too specific (and likely to be references within a broader report). Examples of the former were records such as “Milk”, “Cotton” and “CSV Format of National Data “. Examples of the latter were records such as “Table 15—Agricultural chemical input” and “Southeast: 1982-91 1992-97”. Once these records were removed, a total of 1,959 records were left from this input.</p>
<p>These records represented the main data assets (the parent record). These records were then subject to review to identify their associated aliases. Unlike the NASS data assets, it was not possible to reliably find an ISSNs of DoIs for these assets. However, for each of these records, a URL link had been provided and these were used as aliases. There were this a further 1,959 terms used as an alias. In total there were therefore 3,918 (1,959 + 1,959) search terms associated with this input.</p>
<p>Before the run to create the seed corpus was conducted, a further list of assets was identified. This includes some terms that had been searched for in the Year 1 USDA project (e.g.&nbsp;Census of Agriculture and Agricultural Resource Management Survey) alongside some associated acronyms e.g.&nbsp;FoodAPS. It proved possible to incorporate these late additions. In total these added an additional 20 search terms, comprising 12 main (parent) records and a further 8 alias records.</p>
<p>Through consultation with USDA stakeholders and recognition that agricultural economists represent a significant user group of USDA-produced datasets, we identified 13 key datasets to feature on the dashboard. This selection emerged from a broader review of USDA data assets that included over 2,000 ERS records and 21 NASS reports, as described above. The selected datasets represent those most frequently used in agricultural economics research, spanning topics from farm management to food security. <a href="#tbl-usda-datasets" class="quarto-xref">Table&nbsp;1</a> presents these datasets, their producing agencies, and brief descriptions.</p>
<div id="tbl-usda-datasets" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-usda-datasets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: List of USDA Data Assets
</figcaption>
<div aria-describedby="tbl-usda-datasets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Dataset Name</th>
<th style="text-align: left;">Produced By</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.nass.usda.gov/AgCensus/">Census of Agriculture</a></td>
<td style="text-align: left;">NASS</td>
<td style="text-align: left;">Conducted every five years, it provides comprehensive data on U.S. farms, ranches, and producers.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/arms-farm-financial-and-crop-production-practices/">Agricultural Resource Management Survey (ARMS)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A USDA survey on farm financials, production practices, and resource use.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/foodaps-national-household-food-acquisition-and-purchase-survey/">Food Acquisition and Purchase Survey (FoodAPS)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A nationally representative survey tracking U.S. household food purchases and acquisitions.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/food-security-in-the-united-states">Current Population Survey Food Security Supplement (CPS-FSS)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">An annual supplement to the Current Population Survey (CPS) measuring U.S. household food security.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/food-access-research-atlas/">Food Access Research Atlas (FARA)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A USDA tool mapping food access based on store locations and socioeconomic data.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/">Rural-Urban Continuum Code (RUCC)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A classification system distinguishing U.S. counties by rural and urban characteristics.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/topics/food-nutrition-assistance/food-security-in-the-u-s/survey-tools/">Household Food Security Survey Module</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A USDA survey module used to assess food insecurity levels in households.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/Local_Food/">Local Food Marketing Practices Survey</a></td>
<td style="text-align: left;">NASS</td>
<td style="text-align: left;">A USDA survey on U.S. farms’ local food sales, direct-to-consumer marketing, and supply chains.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://farmtoschoolcensus.fns.usda.gov/">Farm to School Census</a></td>
<td style="text-align: left;">FNS</td>
<td style="text-align: left;">A USDA survey tracking school food procurement and local farm partnerships.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.ers.usda.gov/data-products/quarterly-food-at-home-price-database/">Quarterly Food at Home Price Database (QFAHPD)</a></td>
<td style="text-align: left;">ERS</td>
<td style="text-align: left;">A database of U.S. retail food prices by product, region, and time.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/TOTAL/">Tenure Ownership and Transition of Agricultural Land (TOTAL)</a></td>
<td style="text-align: left;">NASS</td>
<td style="text-align: left;">A survey collecting data on farmland ownership, leasing, and transfer.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><a href="https://www.nass.usda.gov/Surveys/Guide_to_NASS_Surveys/TOTAL/">Transition of Agricultural Land Survey</a></td>
<td style="text-align: left;">NASS</td>
<td style="text-align: left;">A component of TOTAL that examines farmland ownership changes and succession plans.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><a href="https://www.iriworldwide.com/en-us/solutions/consumer-panel/infoscan">Information Resources, Inc.&nbsp;(IRI) InfoScan</a></td>
<td style="text-align: left;">Circana (formerly IRI)</td>
<td style="text-align: left;">A commercial scanner dataset tracking retail food and consumer goods purchases.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="sec-seed-corpus" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-seed-corpus"><span class="header-section-number">4.3</span> Step 2: Create a Seed Corpus</h2>
<p>Once the data assets (<a href="#tbl-usda-datasets" class="quarto-xref">Table&nbsp;1</a>) and aliases were defined, the team identified the set of documents within which to conduct the search (i.e., the “search space”). This was done by first creating a seed corpus, as described below, and then using the seed corpus to infer the types of publications in which the targeted data assets would most likely be found.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Scopus</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">OpenAlex</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Dimensions</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision. Increasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time. These three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.</p>
<p>Following the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.</p>
<p>Specifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.</p>
<p>Finally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.</p>
<section id="creating-a-seed-corpus" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="creating-a-seed-corpus"><span class="header-section-number">4.3.1</span> Creating a Seed Corpus</h3>
<p>The process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with: i) full-text records in ScienceDirect which are within a specified range of publication years and ii) the reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).</p>
<p>Because some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,</p>
<ul>
<li>12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.</li>
<li>71 aliases were included in the search with a flag term i.e.&nbsp;they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service</li>
</ul>
<p>The search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.</p>
<p>The metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:</p>
<ul>
<li>SciVal Topic – 2,699 unique topics in the seed corpus</li>
<li>Journal – 2,650 unique journals in the seed corpus</li>
<li>Top Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.</li>
</ul>
<p>It should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.</p>
<p>As well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.</p>
<p>The results of the seed corpus generation (i.e.&nbsp;the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of i) decisions were taken with regards to the parameters to be used for creation of the search corpus ii) the implications of that decision on search corpus</p>
<div id="tbl-seed-corpus" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-seed-corpus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Creating a Seed Corpus
</figcaption>
<div aria-describedby="tbl-seed-corpus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Seed Corpus Detection</th>
<th style="text-align: left;">Consequence / Implication for Seed Corpus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">SciVal Topics</td>
<td style="text-align: left;">Include those SciVal Topics where the article count in the Seed Corpus</td>
<td style="text-align: left;">All articles associated with 262 SciVal Topics</td>
</tr>
<tr class="even">
<td style="text-align: left;">Journals</td>
<td style="text-align: left;">Include those Journals where the article count in the Seed Corpus was 7 or more</td>
<td style="text-align: left;">All articles associated with 280 journals</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Top Authors</td>
<td style="text-align: left;">Include those with US affiliation</td>
<td style="text-align: left;">All articles associated with the US-affiliated 769 Top Authors</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="creating-the-full-text-search-corpus" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="creating-the-full-text-search-corpus"><span class="header-section-number">4.3.2</span> Creating the Full Text Search Corpus</h3>
<p>The search of full text upon which we apply the Machine Learning algorithm relies on the availability of Scopus.</p>
<p>Scopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.</p>
<p>In summary, the USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors as defined in the Table above.</p>
<p>The full text records associated with the USDA search corpus is shown below:</p>
<div id="tbl-usda-full-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-usda-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Full Text Records Associated with USDA Search Corpus
</figcaption>
<div aria-describedby="tbl-usda-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2017-2023 Articles from Topics</td>
<td style="text-align: center;">726,423</td>
</tr>
<tr class="even">
<td style="text-align: left;">2017-2023 Articles from Journals</td>
<td style="text-align: center;">1,537,851</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2017-2023 Articles from Top Authors</td>
<td style="text-align: center;">21,938</td>
</tr>
<tr class="even">
<td style="text-align: left;">De-duplicated Articles from Above</td>
<td style="text-align: center;">2,089,728</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deduplicated articles where we have full text</td>
<td style="text-align: center;">1,630,958</td>
</tr>
<tr class="even">
<td style="text-align: left;">Deduplicated articles where we have full text and are licensed to search</td>
<td style="text-align: center;">1,450,086</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="scopus-references-search-corpus" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="scopus-references-search-corpus"><span class="header-section-number">4.3.3</span> Scopus References Search Corpus</h3>
<p>A search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.</p>
<p>Because of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.</p>
</section>
<section id="running-the-search-routines" class="level3" data-number="4.3.4">
<h3 data-number="4.3.4" class="anchored" data-anchor-id="running-the-search-routines"><span class="header-section-number">4.3.4</span> Running the Search Routines</h3>
<p>The process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.</p>
<p>Identifying references to datasets within scientific publications is inherently difficult for a number of reasons including:</p>
<ol type="1">
<li>No defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.</li>
<li>Name disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,</li>
<li>Conflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.</li>
<li>Simple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.</li>
</ol>
<p>To address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.</p>
</section>
<section id="machine-learning-kaggle-routines-full-text-search" class="level3" data-number="4.3.5">
<h3 data-number="4.3.5" class="anchored" data-anchor-id="machine-learning-kaggle-routines-full-text-search"><span class="header-section-number">4.3.5</span> Machine Learning (Kaggle) Routines (Full Text Search)</h3>
<p>The three models differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.</p>
<p>The models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.</p>
<p>As well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.</p>
<p>With a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:</p>
<blockquote class="blockquote">
<p>NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service</p>
</blockquote>
<p>In total, the use of flags was identified as being appropriate for 112 of the data assets.</p>
<p>The Kaggle routines were run in early December 2023 with the process completing on 14 December.</p>
<p>A summary of some of the key results from the Full Text search is provided in the Table below:</p>
<div id="tbl-kaggle-full-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-kaggle-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;4: Full Text Search Generated by Kaggle Routine
</figcaption>
<div aria-describedby="tbl-kaggle-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Process Step Outputs</th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of unique Scopus publications identified by the three Kaggle algorithms</td>
<td style="text-align: center;">635,831</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of unique publications identified after Fuzzy text matching to target data assets</td>
<td style="text-align: center;">4,104</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of target data assets matched in the above publications</td>
<td style="text-align: center;">4,392<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of snippets generated</td>
<td style="text-align: center;">14,377<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="scopus-references-search-routine" class="level3" data-number="4.3.6">
<h3 data-number="4.3.6" class="anchored" data-anchor-id="scopus-references-search-routine"><span class="header-section-number">4.3.6</span> Scopus References Search Routine</h3>
<p>The reference search employs an exact text string matching routine across the references of the identified Scopus records.</p>
<p>Because of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.</p>
<div id="tbl-scopus-refs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-scopus-refs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;5: Number of Records from Scopus References Search Routine
</figcaption>
<div aria-describedby="tbl-scopus-refs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Process Step Outputs</th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of unique Scopus publications identified in reference search</td>
<td style="text-align: center;">25,588</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of those publications that were unique to the reference search (i.e.&nbsp;not found by Kaggle models).</td>
<td style="text-align: center;">22,818</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of target data assets matched with the above publications</td>
<td style="text-align: center;">34,526</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="post-processing-adjustments-rucc-and-quickstat-increment" class="level3" data-number="4.3.7">
<h3 data-number="4.3.7" class="anchored" data-anchor-id="post-processing-adjustments-rucc-and-quickstat-increment"><span class="header-section-number">4.3.7</span> Post Processing Adjustments – RUCC and QuickStat Increment</h3>
<p>Note that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:</p>
<ul>
<li>A new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.</li>
<li>A fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.</li>
</ul>
</section>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p><em>Describe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API</em></p>
<p>To collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”</p>
<p>This method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.</p>
<p>Refer to the <a href="appendices.html#sec-app-openalex">Appendix</a> for additional details on file construction.</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">

</div>
</div>
</div>
</section>
<section id="sec-data-extraction" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-data-extraction"><span class="header-section-number">4.4</span> Step 3: Dataset Extraction</h2>
<p>Our analysis builds a hierarchical understanding of how USDA datasets appear in Scopus<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, OpenAlex, and Dimensions. We start at the journal level, identifying which journals publish research using USDA data to establish publication patterns across different research fields. We then examine individual publications within these journals, focusing on how researchers use and cite USDA datasets in their work. At a more granular level, we analyze the authors who work with these datasets, tracking their institutional affiliations and research networks (e.g., coauthors). Finally, we examine the institutions themselves, mapping where USDA data usage concentrates geographically and across different types of research organizations.</p>
<p>Before conducting this analysis, we perform a series of steps to prepare the data. This includes extracting dataset mentions from publication text, disambiguating author names to identify distinct individuals, standardizing institution names, and developing methods to match records across the two databases. The following sections detail these preparatory steps.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Scopus</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">OpenAlex</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">Dimensions</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision. Increasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time. These three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.</p>
<p>Following the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.</p>
<p>Specifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.</p>
<p>Finally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.</p>
<section id="creating-a-seed-corpus-1" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="creating-a-seed-corpus-1"><span class="header-section-number">4.4.1</span> Creating a Seed Corpus</h3>
<p>The process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with: i) full-text records in ScienceDirect which are within a specified range of publication years and ii) the reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).</p>
<p>Because some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,</p>
<ul>
<li>12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.</li>
<li>71 aliases were included in the search with a flag term i.e.&nbsp;they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service</li>
</ul>
<p>The search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.</p>
<p>The metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:</p>
<ul>
<li>SciVal Topic – 2,699 unique topics in the seed corpus</li>
<li>Journal – 2,650 unique journals in the seed corpus</li>
<li>Top Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.</li>
</ul>
<p>It should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.</p>
<p>As well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.</p>
<p>The results of the seed corpus generation (i.e.&nbsp;the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of i) decisions were taken with regards to the parameters to be used for creation of the search corpus ii) the implications of that decision on search corpus</p>
<div id="tbl-seed-corpus" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-seed-corpus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;6: Creating a Seed Corpus
</figcaption>
<div aria-describedby="tbl-seed-corpus-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Seed Corpus Detection</th>
<th style="text-align: left;">Consequence / Implication for Seed Corpus</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">SciVal Topics</td>
<td style="text-align: left;">Include those SciVal Topics where the article count in the Seed Corpus</td>
<td style="text-align: left;">All articles associated with 262 SciVal Topics</td>
</tr>
<tr class="even">
<td style="text-align: left;">Journals</td>
<td style="text-align: left;">Include those Journals where the article count in the Seed Corpus was 7 or more</td>
<td style="text-align: left;">All articles associated with 280 journals</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Top Authors</td>
<td style="text-align: left;">Include those with US affiliation</td>
<td style="text-align: left;">All articles associated with the US-affiliated 769 Top Authors</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="creating-the-full-text-search-corpus-1" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="creating-the-full-text-search-corpus-1"><span class="header-section-number">4.4.2</span> Creating the Full Text Search Corpus</h3>
<p>The search of full text upon which we apply the Machine Learning algorithm relies on the availability of Scopus.</p>
<p>Scopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.</p>
<p>In summary, the USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors as defined in the Table above.</p>
<p>The full text records associated with the USDA search corpus is shown below:</p>
<div id="tbl-usda-full-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-usda-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;7: Full Text Records Associated with USDA Search Corpus
</figcaption>
<div aria-describedby="tbl-usda-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">2017-2023 Articles from Topics</td>
<td style="text-align: center;">726,423</td>
</tr>
<tr class="even">
<td style="text-align: left;">2017-2023 Articles from Journals</td>
<td style="text-align: center;">1,537,851</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2017-2023 Articles from Top Authors</td>
<td style="text-align: center;">21,938</td>
</tr>
<tr class="even">
<td style="text-align: left;">De-duplicated Articles from Above</td>
<td style="text-align: center;">2,089,728</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Deduplicated articles where we have full text</td>
<td style="text-align: center;">1,630,958</td>
</tr>
<tr class="even">
<td style="text-align: left;">Deduplicated articles where we have full text and are licensed to search</td>
<td style="text-align: center;">1,450,086</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="scopus-references-search-corpus-1" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="scopus-references-search-corpus-1"><span class="header-section-number">4.4.3</span> Scopus References Search Corpus</h3>
<p>A search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.</p>
<p>Because of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.</p>
</section>
<section id="running-the-search-routines-1" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="running-the-search-routines-1"><span class="header-section-number">4.4.4</span> Running the Search Routines</h3>
<p>The process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.</p>
<p>Identifying references to datasets within scientific publications is inherently difficult for a number of reasons including:</p>
<ol type="1">
<li>No defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.</li>
<li>Name disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,</li>
<li>Conflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.</li>
<li>Simple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.</li>
</ol>
<p>To address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.</p>
</section>
<section id="machine-learning-kaggle-routines-full-text-search-1" class="level3" data-number="4.4.5">
<h3 data-number="4.4.5" class="anchored" data-anchor-id="machine-learning-kaggle-routines-full-text-search-1"><span class="header-section-number">4.4.5</span> Machine Learning (Kaggle) Routines (Full Text Search)</h3>
<p>The three models differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.</p>
<p>The models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.</p>
<p>As well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.</p>
<p>With a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:</p>
<blockquote class="blockquote">
<p>NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service</p>
</blockquote>
<p>In total, the use of flags was identified as being appropriate for 112 of the data assets.</p>
<p>The Kaggle routines were run in early December 2023 with the process completing on 14 December.</p>
<p>A summary of some of the key results from the Full Text search is provided in the Table below:</p>
<div id="tbl-kaggle-full-text" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-kaggle-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;8: Full Text Search Generated by Kaggle Routine
</figcaption>
<div aria-describedby="tbl-kaggle-full-text-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Process Step Outputs</th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of unique Scopus publications identified by the three Kaggle algorithms</td>
<td style="text-align: center;">635,831</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of unique publications identified after Fuzzy text matching to target data assets</td>
<td style="text-align: center;">4,104</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of target data assets matched in the above publications</td>
<td style="text-align: center;">4,392<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of snippets generated</td>
<td style="text-align: center;">14,377<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="scopus-references-search-routine-1" class="level3" data-number="4.4.6">
<h3 data-number="4.4.6" class="anchored" data-anchor-id="scopus-references-search-routine-1"><span class="header-section-number">4.4.6</span> Scopus References Search Routine</h3>
<p>The reference search employs an exact text string matching routine across the references of the identified Scopus records.</p>
<p>Because of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.</p>
<div id="tbl-scopus-refs" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-scopus-refs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;9: Number of Records from Scopus References Search Routine
</figcaption>
<div aria-describedby="tbl-scopus-refs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Process Step Outputs</th>
<th style="text-align: center;">Number of Records</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Number of unique Scopus publications identified in reference search</td>
<td style="text-align: center;">25,588</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of those publications that were unique to the reference search (i.e.&nbsp;not found by Kaggle models).</td>
<td style="text-align: center;">22,818</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of target data assets matched with the above publications</td>
<td style="text-align: center;">34,526</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="post-processing-adjustments-rucc-and-quickstat-increment-1" class="level3" data-number="4.4.7">
<h3 data-number="4.4.7" class="anchored" data-anchor-id="post-processing-adjustments-rucc-and-quickstat-increment-1"><span class="header-section-number">4.4.7</span> Post Processing Adjustments – RUCC and QuickStat Increment</h3>
<p>Note that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:</p>
<ul>
<li>A new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.</li>
<li>A fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.</li>
</ul>
</section>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p><em>Describe Rafael’s methodology for searching for dataset names in OpenAlex articles and additional steps Cal did to pull data from the OpenAlex API</em></p>
<p>To collect publications mentioning the NASS Census of Agriculture from the OpenAlex Catalog, I conducted a string search using a predefined set of dataset aliases: “Census of Agriculture,” “USDA Census,” “NASS Census,” “Agricultural Census,” and “AG Census.” To minimize false positives, I applied several filters: the publications had to be in English, published between 2017 and 2024, and include at least one author affiliated with an American institution. Additionally, to ensure that the publications were indeed referring to the correct dataset, I required that they also contain specific flag terms within the full text body, such as “USDA,” “US Department of Agriculture,” “United States Department of Agriculture,” “NASS,” or “National Agricultural Statistics Service.”</p>
<p>This method closely mirrors the approach used in the USDA Briefing Book sent by Julia (Appendix 1: Data Search), where a similar string search was applied to the Scopus catalog. In the Scopus analysis, the string search was performed primarily on the references text body rather than the full text and was executed only within a seed corpus. In contrast, our search in OpenAlex was conducted across the entire OpenAlex database. Notably, the references string search in Scopus identified over 80% of the findings, as documented in the briefing book, highlighting the effectiveness of this approach.</p>
<p>Refer to the <a href="appendices.html#sec-app-openalex">Appendix</a> for additional details on file construction.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">

</div>
</div>
</div>
</section>
<section id="sec-disambiguation" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="sec-disambiguation"><span class="header-section-number">4.5</span> Step 4: Disambiguation Process</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Metadata Processing</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Metadata Processing</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Metadata Processing</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<section id="disambiguating-journals" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="disambiguating-journals"><span class="header-section-number">4.5.1</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="disambiguating-authors"><span class="header-section-number">4.5.2</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="disambiguating-institutions"><span class="header-section-number">4.5.3</span> Disambiguating Institutions</h3>
</section>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<section id="disambiguating-journals-1" class="level3" data-number="4.5.4">
<h3 data-number="4.5.4" class="anchored" data-anchor-id="disambiguating-journals-1"><span class="header-section-number">4.5.4</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors-1" class="level3" data-number="4.5.5">
<h3 data-number="4.5.5" class="anchored" data-anchor-id="disambiguating-authors-1"><span class="header-section-number">4.5.5</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions-1" class="level3" data-number="4.5.6">
<h3 data-number="4.5.6" class="anchored" data-anchor-id="disambiguating-institutions-1"><span class="header-section-number">4.5.6</span> Disambiguating Institutions</h3>
</section>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<section id="disambiguating-journals-2" class="level3" data-number="4.5.7">
<h3 data-number="4.5.7" class="anchored" data-anchor-id="disambiguating-journals-2"><span class="header-section-number">4.5.7</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors-2" class="level3" data-number="4.5.8">
<h3 data-number="4.5.8" class="anchored" data-anchor-id="disambiguating-authors-2"><span class="header-section-number">4.5.8</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions-2" class="level3" data-number="4.5.9">
<h3 data-number="4.5.9" class="anchored" data-anchor-id="disambiguating-institutions-2"><span class="header-section-number">4.5.9</span> Disambiguating Institutions</h3>
</section>
</div>
</div>
</div>
<section id="results-from-disambiguation" class="level3" data-number="4.5.10">
<h3 data-number="4.5.10" class="anchored" data-anchor-id="results-from-disambiguation"><span class="header-section-number">4.5.10</span> Results from Disambiguation</h3>
<p><em>This section presents overall statistics for Scopus and OA. Each subsection will have results reported for each dataset</em></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">Metadata Processing</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Metadata Processing</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Metadata Processing</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<section id="disambiguating-journals-3" class="level3" data-number="4.5.11">
<h3 data-number="4.5.11" class="anchored" data-anchor-id="disambiguating-journals-3"><span class="header-section-number">4.5.11</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors-3" class="level3" data-number="4.5.12">
<h3 data-number="4.5.12" class="anchored" data-anchor-id="disambiguating-authors-3"><span class="header-section-number">4.5.12</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions-3" class="level3" data-number="4.5.13">
<h3 data-number="4.5.13" class="anchored" data-anchor-id="disambiguating-institutions-3"><span class="header-section-number">4.5.13</span> Disambiguating Institutions</h3>
</section>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<section id="disambiguating-journals-4" class="level3" data-number="4.5.14">
<h3 data-number="4.5.14" class="anchored" data-anchor-id="disambiguating-journals-4"><span class="header-section-number">4.5.14</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors-4" class="level3" data-number="4.5.15">
<h3 data-number="4.5.15" class="anchored" data-anchor-id="disambiguating-authors-4"><span class="header-section-number">4.5.15</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions-4" class="level3" data-number="4.5.16">
<h3 data-number="4.5.16" class="anchored" data-anchor-id="disambiguating-institutions-4"><span class="header-section-number">4.5.16</span> Disambiguating Institutions</h3>
</section>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<section id="disambiguating-journals-5" class="level3" data-number="4.5.17">
<h3 data-number="4.5.17" class="anchored" data-anchor-id="disambiguating-journals-5"><span class="header-section-number">4.5.17</span> Disambiguating Journals</h3>
</section>
<section id="disambiguating-authors-5" class="level3" data-number="4.5.18">
<h3 data-number="4.5.18" class="anchored" data-anchor-id="disambiguating-authors-5"><span class="header-section-number">4.5.18</span> Disambiguating Authors</h3>
</section>
<section id="disambiguating-institutions-5" class="level3" data-number="4.5.19">
<h3 data-number="4.5.19" class="anchored" data-anchor-id="disambiguating-institutions-5"><span class="header-section-number">4.5.19</span> Disambiguating Institutions</h3>
</section>
</div>
</div>
</div>
</section>
</section>
<section id="sec-matching" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="sec-matching"><span class="header-section-number">4.6</span> Step 5: Comparison across Datasets</h2>
<p>Matching methods:</p>
<ol type="1">
<li>Rule-based matching for exact matches</li>
<li>Probabilistic matching for handling variations</li>
<li>Machine learning methods for complex cases</li>
</ol>
<div id="tbl-methods-summary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-methods-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10: Summary of Methods
</figcaption>
<div aria-describedby="tbl-methods-summary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Considerations</th>
<th style="text-align: left;">Example</th>
<th style="text-align: left;">Pros</th>
<th style="text-align: left;">Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Searching for dataset names within Scopus</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Searching for dataset names within OpenAlex</td>
<td style="text-align: left;">“Location” field set to “journal”</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Disambiguation of authors</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Disambiguation of institutions</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Standardization of institutions</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Searching based on the frequency of dataset appearance in journals</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">MORE . . .</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Filtering on keywords to determine themes</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">Scopus</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">OpenAlex</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-3" role="tab" aria-controls="tabset-5-3" aria-selected="false">Dimensions</a></li></ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<section id="journal-identification" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="journal-identification"><span class="header-section-number">4.6.1</span> Journal Identification</h3>
</section>
<section id="author-disambiguation" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="author-disambiguation"><span class="header-section-number">4.6.2</span> Author Disambiguation</h3>
</section>
<section id="institution-disambiguation" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="institution-disambiguation"><span class="header-section-number">4.6.3</span> Institution Disambiguation</h3>
<section id="ipeds-ming" class="level4" data-number="4.6.3.1">
<h4 data-number="4.6.3.1" class="anchored" data-anchor-id="ipeds-ming"><span class="header-section-number">4.6.3.1</span> IPEDS <em>Ming</em></h4>
</section>
<section id="msi-data-ming" class="level4" data-number="4.6.3.2">
<h4 data-number="4.6.3.2" class="anchored" data-anchor-id="msi-data-ming"><span class="header-section-number">4.6.3.2</span> MSI Data <em>Ming</em></h4>
</section>
</section>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<section id="journal-identification-1" class="level3" data-number="4.6.4">
<h3 data-number="4.6.4" class="anchored" data-anchor-id="journal-identification-1"><span class="header-section-number">4.6.4</span> Journal Identification</h3>
</section>
<section id="author-disambiguation-1" class="level3" data-number="4.6.5">
<h3 data-number="4.6.5" class="anchored" data-anchor-id="author-disambiguation-1"><span class="header-section-number">4.6.5</span> Author Disambiguation</h3>
</section>
<section id="institution-disambiguation-1" class="level3" data-number="4.6.6">
<h3 data-number="4.6.6" class="anchored" data-anchor-id="institution-disambiguation-1"><span class="header-section-number">4.6.6</span> Institution Disambiguation</h3>
<section id="ipeds-ming-1" class="level4" data-number="4.6.6.1">
<h4 data-number="4.6.6.1" class="anchored" data-anchor-id="ipeds-ming-1"><span class="header-section-number">4.6.6.1</span> IPEDS <em>Ming</em></h4>
</section>
<section id="msi-data-ming-1" class="level4" data-number="4.6.6.2">
<h4 data-number="4.6.6.2" class="anchored" data-anchor-id="msi-data-ming-1"><span class="header-section-number">4.6.6.2</span> MSI Data *Ming**</h4>
</section>
</section>
</div>
<div id="tabset-5-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-3-tab">
<section id="journal-identification-2" class="level3" data-number="4.6.7">
<h3 data-number="4.6.7" class="anchored" data-anchor-id="journal-identification-2"><span class="header-section-number">4.6.7</span> Journal Identification</h3>
</section>
<section id="author-disambiguation-2" class="level3" data-number="4.6.8">
<h3 data-number="4.6.8" class="anchored" data-anchor-id="author-disambiguation-2"><span class="header-section-number">4.6.8</span> Author Disambiguation</h3>
</section>
<section id="institution-disambiguation-2" class="level3" data-number="4.6.9">
<h3 data-number="4.6.9" class="anchored" data-anchor-id="institution-disambiguation-2"><span class="header-section-number">4.6.9</span> Institution Disambiguation</h3>
<section id="ipeds-ming-2" class="level4" data-number="4.6.9.1">
<h4 data-number="4.6.9.1" class="anchored" data-anchor-id="ipeds-ming-2"><span class="header-section-number">4.6.9.1</span> IPEDS <em>Ming</em></h4>
</section>
<section id="msi-data-ming-2" class="level4" data-number="4.6.9.2">
<h4 data-number="4.6.9.2" class="anchored" data-anchor-id="msi-data-ming-2"><span class="header-section-number">4.6.9.2</span> MSI Data <em>Ming</em></h4>
</section>
</section>
</div>
</div>
</div>
<section id="results-from-database-comparison" class="level3" data-number="4.6.10">
<h3 data-number="4.6.10" class="anchored" data-anchor-id="results-from-database-comparison"><span class="header-section-number">4.6.10</span> Results from Database Comparison</h3>
<p><em>This section presents results after matching (which type varies – deterministic vs fuzzy)</em></p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">Scopus</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">OpenAlex</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-3" role="tab" aria-controls="tabset-6-3" aria-selected="false">Dimensions</a></li></ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<section id="journal-coverage-cal" class="level3" data-number="4.6.11">
<h3 data-number="4.6.11" class="anchored" data-anchor-id="journal-coverage-cal"><span class="header-section-number">4.6.11</span> Journal Coverage <em>Cal</em></h3>
</section>
<section id="publication-coverage-cal" class="level3" data-number="4.6.12">
<h3 data-number="4.6.12" class="anchored" data-anchor-id="publication-coverage-cal"><span class="header-section-number">4.6.12</span> Publication Coverage <em>Cal</em></h3>
</section>
<section id="author-coverage-cal" class="level3" data-number="4.6.13">
<h3 data-number="4.6.13" class="anchored" data-anchor-id="author-coverage-cal"><span class="header-section-number">4.6.13</span> Author Coverage <em>Cal</em></h3>
</section>
<section id="institution-coverage-ming" class="level3" data-number="4.6.14">
<h3 data-number="4.6.14" class="anchored" data-anchor-id="institution-coverage-ming"><span class="header-section-number">4.6.14</span> Institution Coverage <em>Ming</em></h3>
</section>
<section id="insitutional-representation-ming" class="level3" data-number="4.6.15">
<h3 data-number="4.6.15" class="anchored" data-anchor-id="insitutional-representation-ming"><span class="header-section-number">4.6.15</span> Insitutional Representation <em>Ming</em></h3>
<section id="geographic-coverage-ming" class="level4" data-number="4.6.15.1">
<h4 data-number="4.6.15.1" class="anchored" data-anchor-id="geographic-coverage-ming"><span class="header-section-number">4.6.15.1</span> Geographic Coverage <em>Ming</em></h4>
</section>
<section id="sec-inst-rep" class="level4" data-number="4.6.15.2">
<h4 data-number="4.6.15.2" class="anchored" data-anchor-id="sec-inst-rep"><span class="header-section-number">4.6.15.2</span> Institution Types <em>Ming</em></h4>
</section>
</section>
<section id="thematic-analysis-callauren" class="level3" data-number="4.6.16">
<h3 data-number="4.6.16" class="anchored" data-anchor-id="thematic-analysis-callauren"><span class="header-section-number">4.6.16</span> Thematic Analysis <em>Cal/Lauren</em></h3>
<section id="publication-topics-callauren" class="level4" data-number="4.6.16.1">
<h4 data-number="4.6.16.1" class="anchored" data-anchor-id="publication-topics-callauren"><span class="header-section-number">4.6.16.1</span> Publication Topics <em>Cal/Lauren</em></h4>
</section>
<section id="patterns-over-time-callauren" class="level4" data-number="4.6.16.2">
<h4 data-number="4.6.16.2" class="anchored" data-anchor-id="patterns-over-time-callauren"><span class="header-section-number">4.6.16.2</span> Patterns over Time <em>Cal/Lauren</em></h4>
</section>
</section>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<section id="journal-coverage-cal-1" class="level3" data-number="4.6.17">
<h3 data-number="4.6.17" class="anchored" data-anchor-id="journal-coverage-cal-1"><span class="header-section-number">4.6.17</span> Journal Coverage <em>Cal</em></h3>
</section>
<section id="publication-coverage-cal-1" class="level3" data-number="4.6.18">
<h3 data-number="4.6.18" class="anchored" data-anchor-id="publication-coverage-cal-1"><span class="header-section-number">4.6.18</span> Publication Coverage <em>Cal</em></h3>
</section>
<section id="author-coverage-cal-1" class="level3" data-number="4.6.19">
<h3 data-number="4.6.19" class="anchored" data-anchor-id="author-coverage-cal-1"><span class="header-section-number">4.6.19</span> Author Coverage <em>Cal</em></h3>
</section>
<section id="institution-coverage-ming-1" class="level3" data-number="4.6.20">
<h3 data-number="4.6.20" class="anchored" data-anchor-id="institution-coverage-ming-1"><span class="header-section-number">4.6.20</span> Institution Coverage <em>Ming</em></h3>
</section>
<section id="insitutional-representation-ming-1" class="level3" data-number="4.6.21">
<h3 data-number="4.6.21" class="anchored" data-anchor-id="insitutional-representation-ming-1"><span class="header-section-number">4.6.21</span> Insitutional Representation <em>Ming</em></h3>
<section id="geographic-coverage-ming-1" class="level4" data-number="4.6.21.1">
<h4 data-number="4.6.21.1" class="anchored" data-anchor-id="geographic-coverage-ming-1"><span class="header-section-number">4.6.21.1</span> Geographic Coverage <em>Ming</em></h4>
</section>
<section id="sec-inst-rep" class="level4" data-number="4.6.21.2">
<h4 data-number="4.6.21.2" class="anchored" data-anchor-id="sec-inst-rep"><span class="header-section-number">4.6.21.2</span> Institution Types <em>Ming</em></h4>
</section>
</section>
<section id="thematic-analysis-callauren-1" class="level3" data-number="4.6.22">
<h3 data-number="4.6.22" class="anchored" data-anchor-id="thematic-analysis-callauren-1"><span class="header-section-number">4.6.22</span> Thematic Analysis <em>Cal/Lauren</em></h3>
<section id="publication-topics-callauren-1" class="level4" data-number="4.6.22.1">
<h4 data-number="4.6.22.1" class="anchored" data-anchor-id="publication-topics-callauren-1"><span class="header-section-number">4.6.22.1</span> Publication Topics <em>Cal/Lauren</em></h4>
</section>
<section id="patterns-over-time-callauren-1" class="level4" data-number="4.6.22.2">
<h4 data-number="4.6.22.2" class="anchored" data-anchor-id="patterns-over-time-callauren-1"><span class="header-section-number">4.6.22.2</span> Patterns over Time <em>Cal/Lauren</em></h4>
</section>
</section>
</div>
<div id="tabset-6-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-3-tab">
<section id="journal-coverage-cal-2" class="level3" data-number="4.6.23">
<h3 data-number="4.6.23" class="anchored" data-anchor-id="journal-coverage-cal-2"><span class="header-section-number">4.6.23</span> Journal Coverage <em>Cal</em></h3>
</section>
<section id="publication-coverage-cal-2" class="level3" data-number="4.6.24">
<h3 data-number="4.6.24" class="anchored" data-anchor-id="publication-coverage-cal-2"><span class="header-section-number">4.6.24</span> Publication Coverage <em>Cal</em></h3>
</section>
<section id="author-coverage-cal-2" class="level3" data-number="4.6.25">
<h3 data-number="4.6.25" class="anchored" data-anchor-id="author-coverage-cal-2"><span class="header-section-number">4.6.25</span> Author Coverage <em>Cal</em></h3>
</section>
<section id="institution-coverage-ming-2" class="level3" data-number="4.6.26">
<h3 data-number="4.6.26" class="anchored" data-anchor-id="institution-coverage-ming-2"><span class="header-section-number">4.6.26</span> Institution Coverage <em>Ming</em></h3>
</section>
<section id="insitutional-representation-ming-2" class="level3" data-number="4.6.27">
<h3 data-number="4.6.27" class="anchored" data-anchor-id="insitutional-representation-ming-2"><span class="header-section-number">4.6.27</span> Insitutional Representation <em>Ming</em></h3>
<section id="geographic-coverage-ming-2" class="level4" data-number="4.6.27.1">
<h4 data-number="4.6.27.1" class="anchored" data-anchor-id="geographic-coverage-ming-2"><span class="header-section-number">4.6.27.1</span> Geographic Coverage <em>Ming</em></h4>
</section>
<section id="sec-inst-rep" class="level4" data-number="4.6.27.2">
<h4 data-number="4.6.27.2" class="anchored" data-anchor-id="sec-inst-rep"><span class="header-section-number">4.6.27.2</span> Institution Types <em>Ming</em></h4>
</section>
</section>
<section id="thematic-analysis-callauren-2" class="level3" data-number="4.6.28">
<h3 data-number="4.6.28" class="anchored" data-anchor-id="thematic-analysis-callauren-2"><span class="header-section-number">4.6.28</span> Thematic Analysis <em>Cal/Lauren</em></h3>
<section id="publication-topics-callauren-2" class="level4" data-number="4.6.28.1">
<h4 data-number="4.6.28.1" class="anchored" data-anchor-id="publication-topics-callauren-2"><span class="header-section-number">4.6.28.1</span> Publication Topics <em>Cal/Lauren</em></h4>
</section>
<section id="patterns-over-time-callauren-2" class="level4" data-number="4.6.28.2">
<h4 data-number="4.6.28.2" class="anchored" data-anchor-id="patterns-over-time-callauren-2"><span class="header-section-number">4.6.28.2</span> Patterns over Time <em>Cal/Lauren</em></h4>
</section>
</section>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="recommendations" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Recommendations</h1>
<section id="technical-recommendations" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="technical-recommendations"><span class="header-section-number">5.1</span> Technical Recommendations</h2>
</section>
<section id="expanding-dataset-usage" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="expanding-dataset-usage"><span class="header-section-number">5.2</span> Expanding Dataset Usage</h2>
<p>This report analyzes USDA dataset usage patterns across both platforms and recommends specific strategies for expanding dataset use in underrepresented research communities.</p>
<p>Given the small percentage of MSI’s represented in our institutional analysis, it is evident that user engagement is central to increasing usage rates of the datasets, regardless of citation database.</p>
</section>
</section>
<section id="conclusion-and-next-steps" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Conclusion and Next Steps</h1>
</section>
<section id="references" class="level1" data-number="7">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">7 References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-broadus1987toward" class="csl-entry" role="listitem">
Broadus, R. N. (1987). Toward a definition of <span>“bibliometrics.”</span> <em>Scientometrics</em>, <em>12</em>, 373–379. <a href="https://doi.org/10.1007/bf02016680">https://doi.org/10.1007/bf02016680</a>
</div>
<div id="ref-debellis2009bibliometrics" class="csl-entry" role="listitem">
De Bellis, N. (2009). <em>Bibliometrics and citation analysis: From the science citation index to cybermetrics</em>. Scarecrow Press. <a href="https://doi.org/10.1002/asi.21181">https://doi.org/10.1002/asi.21181</a>
</div>
<div id="ref-garfield1955citation" class="csl-entry" role="listitem">
Garfield, E. (1955). Citation indexes for science: A new dimension in documentation through association of ideas. <em>Science</em>, <em>122</em>(3159), 108–111. <a href="https://doi.org/10.1126/science.122.3159.108">https://doi.org/10.1126/science.122.3159.108</a>
</div>
<div id="ref-hood2001literature" class="csl-entry" role="listitem">
Hood, W. W., &amp; Wilson, C. S. (2001). The literature of bibliometrics, scientometrics, and informetrics. <em>Scientometrics</em>, <em>52</em>, 291–314. <a href="https://doi.org/10.1023/A:1017919924342">https://doi.org/10.1023/A:1017919924342</a>
</div>
<div id="ref-lane2022data" class="csl-entry" role="listitem">
Lane, J., Gimeno, E., Levitskaya, E., Zhang, Z., &amp; Zigoni, A. (2022). Data inventories for the modern age? Using data science to open government data. <em>Harvard Data Science Review</em>, <em>4</em>(2). <a href="https://doi.org/10.1162/99608f92.8a3f2336">https://doi.org/10.1162/99608f92.8a3f2336</a>
</div>
<div id="ref-martin2021google" class="csl-entry" role="listitem">
Martín-Martín, A., Thelwall, M., Orduna-Malea, E., &amp; Delgado López-Cózar, E. (2021). Google scholar, microsoft academic, scopus, dimensions, web of science, and OpenCitations’ COCI: A multidisciplinary comparison of coverage via citations. <em>Scientometrics</em>, <em>126</em>(1), 871–906. <a href="https://doi.org/10.1007/s11192-020-03690-4">https://doi.org/10.1007/s11192-020-03690-4</a>
</div>
<div id="ref-mongeon2016journal" class="csl-entry" role="listitem">
Mongeon, P., &amp; Paul-Hus, A. (2016). The journal coverage of web of science and scopus: A comparative analysis. <em>Scientometrics</em>, <em>106</em>, 213–228. <a href="https://doi.org/10.1007/s11192-015-1765-5">https://doi.org/10.1007/s11192-015-1765-5</a>
</div>
<div id="ref-visser2021large" class="csl-entry" role="listitem">
Visser, M., Van Eck, N. J., &amp; Waltman, L. (2021). Large-scale comparison of bibliographic data sources: Scopus, web of science, dimensions, crossref, and microsoft academic. <em>Quantitative Science Studies</em>, <em>2</em>(1), 20–41. <a href="https://doi.org/10.1162/qss_a_00112">https://doi.org/10.1162/qss_a_00112</a>
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Explanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Explanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>The Scopus work was generated by a team provided under contract to USDA (NASS and ERS), which included NYU, Rafael Ladislau, and Elsevier.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Explanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Explanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>