## Dataset Extraction in Scopus *Julia*

Once the data assets (@tbl-usda-datasets) and aliases were defined, the team identified the set of documents within which to conduct the search (i.e., the “search space”). This was done by first creating a seed corpus, as described below, and then using the seed corpus to infer the types of publications in which the targeted data assets would most likely be found.

There are several factors that motivate the use of a restricted search space. Although an increasing number of research publications cite datasets in a standard way, data citation has not been adopted as a uniform practice in the research community. Consequently, searches of publication metadata (e.g., the publication reference list) alone is not sufficient. A full text search is required to find all citations of the relevant data assets. However, full text searching is much more intensive in terms of computation, and more expensive in terms of the validation process. As a consequence, the search space is restricted to balance recall and precision. Increasing recall means more of the data assets will be found and hence will provide a broader picture of the data asset’s impact. However, increasing recall comes at the expense of precision, i.e., it will result in more false positives. No matter how attractive achieving high levels of recall may be, that objective rapidly becomes prohibitive in terms of both cost (subject matter expert effort) and time. These three inputs were then combined to provide one list of data assets that could be used in the subsequent process steps. The combined list comprised 2,006 parent records and a further 1,996 aliases (some of which were acronyms). There was therefore a total of 4,002 search terms.

Following the Machine Learning routines and during the review of the results, some ambiguities were found in the Data Asset list leading to a set of post-search refinements. In a search list of the scale being dealt with (over 4,000) records, finding these ambiguities was not unexpected.

Specifically, in the original list a small number of duplicate alias terms were noted and these were consolidated. A specific example was multiple entries for the data asset “Measuring Access to Food in Tanzania: A Food Basket Approach” and its aliases. Furthermore, it was noted a small number of aliases were attributed to the wrong parent. These were corrected. These changes resulted in a data asset, as at 22 December 2023, that had 3,991 parent and alias records.

Finally, and again only following the original Kaggle search, it was noted that terms relating to Rural Urban Continuum Codes and Quick Stats had not featured in the original list. An additional eight terms were therefore added as an incremental addition to the list on 29 December 2023. These eight terms comprised two parent records with a further six associated aliases. A specific additional search was conducted for these eight records as explained later.

### Creating a Seed Corpus

The process of creating the search corpus, that is, the body of texts that will be searched, begins with the creation of a seed corpus. The purpose of the seed corpus is to define the parameters that can be used for creating the final search corpus. The seed corpus is, to a first approximation, created by text matching the name for each parent data asset and its aliases with: i) full-text records in ScienceDirect which are within a specified range of publication years and ii) the reference section for Scopus records that are within the specified range of publication years. For the USDA Year 2 project, the date range period was publications produced between 2017 and 2023 (inclusive).

Because some of the alias terms are very generic and/or otherwise could result in false positives, they are either excluded from the seed corpus process or only included where they are associated with a flag. In this respect,

-   12 aliases from the total of 4,002 were excluded completely from both the seed corpus creation reference search and the ScienceDirect search.
-   71 aliases were included in the search with a flag term i.e. they returned results only when associated with one or more flag terms. The flag terms were: NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service

The search through ScienceDirect and Scopus references resulted in a set of research publication records matched to the data asset names and aliases. Of the 3,990 (4,002 – 12) aliases included in the search, 328 were found in the references and 163 in ScienceDirect. Of course, there are overlaps between these two datasets and the number of unique data assets found within the seed corpus was 334.

The metadata associated with these publications provides insight into what types of research are leveraging these data assets. The “entities” used for this purpose were as follows:

-   SciVal Topic – 2,699 unique topics in the seed corpus
-   Journal – 2,650 unique journals in the seed corpus
-   Top Authors – Authors are grouped by numbers of output in seed corpus and the top 1,000 are selected. In our sample 769 relevant authors were from USA.

It should be noted that Scopus Topics are intended to identify the subject area most likely to use these data assets. These topics are intended to uncover clusters of researchers likely to use similar resources, such as datasets, based on the citation links between their work. It should also be noted that in the Year 1 USDA project, the seed corpus was created just be reviewing list of target journals.

As well as recording the entities, the number of records associated with them that was found in the seed corpus is also collected. This provides the basis by which a filtering can be undertaken to focus down on those entities that should be used in search corpus creation.

The results of the seed corpus generation (i.e. the entities and record counts) were provided for review to Professor Julia Lane on 15 November 2023. Based on that review, the following table provides a summary of i) decisions were taken with regards to the parameters to be used for creation of the search corpus ii) the implications of that decision on search corpus

| Parameter | Seed Corpus Detection | Consequence / Implication for Seed Corpus |
|:---|:---|:---|
| SciVal Topics | Include those SciVal Topics where the article count in the Seed Corpus | All articles associated with 262 SciVal Topics |
| Journals | Include those Journals where the article count in the Seed Corpus was 7 or more | All articles associated with 280 journals |
| Top Authors | Include those with US affiliation | All articles associated with the US-affiliated 769 Top Authors |

: Creating a Seed Corpus {#tbl-seed-corpus}

### Creating the Full Text Search Corpus

The search of full text upon which we apply the Machine Learning algorithm relies on the availability of Scopus.

Scopus is a large, curated abstract and citation database of scientific literature including scientific journals, books, and conference proceedings. Around 11,000 new records are added each day from over 7,000 publishers worldwide. Elsevier is also licensed to access the full text of publications from many, although not all, of these publishers for internal analysis (the full text is not licensed for public use). Where the appropriate licenses do not exist, the records are excluded from the search. To provide some context in this respect, for calendar year 2022, Elsevier estimates that full text records exist for 91% of records published and captured in that year. With license restrictions also considered, the estimate is that it is possible to undertake full text searches on approximately 82% of the total records for that year.

In summary, the USDA full text search corpus was created using Scopus, with a publication year range of 2017 to 2023 inclusive and using the Topics, Journals and Top Authors as defined in the Table above.

The full text records associated with the USDA search corpus is shown below:

|   | Number of Records |
|:---|:--:|
| 2017-2023 Articles from Topics | 726,423 |
| 2017-2023 Articles from Journals | 1,537,851 |
| 2017-2023 Articles from Top Authors | 21,938 |
| De-duplicated Articles from Above | 2,089,728 |
| Deduplicated articles where we have full text | 1,630,958 |
| Deduplicated articles where we have full text and are licensed to search | 1,450,086 |

: Full Text Records Associated with USDA Search Corpus {#tbl-usda-full-text}

### Scopus References Search Corpus

A search through the references list of Scopus records is also undertaken as a separate and distinct step from the full text search. The search corpus here is broader than for full text, as there are no license conditions restricting the search. In addition, because references contain highly structured data, it is feasible to search through all of Scopus, as the computational limitations of full-text search do not apply.

Because of this, all Scopus records within the publication date range are searched. For the USDA search period of 2017 to 2023, this amounted to 25,110,182 records.

### Running the Search Routines

The process of running the search routines is to identify a candidate match with the list of data assets. The candidate match is effectively the “publication ID – dataset ID” combination and is referred to as a dyad. For any given publication, there may be multiple dyads.

Identifying references to datasets within scientific publications is inherently difficult for a number of reasons including:

1.  No defined format for dataset references: Datasets are often not cited formally and rather are referred to using unpredictable textual context and formats.
2.  Name disambiguation: Datasets can be referred to by their full name, acronym, and many other valid ways. For instance, the dataset “Rural-Urban Continuum Codes” may also be referred to as “Rural Urban Continuum Codes” or “RUCC” or by using a URL reference,
3.  Conflicts with other terms and phrases: Contextual cues need to be used to ensure, for example, that a data asset such as “Feed Outlook” is indeed the relevant USDA reference.
4.  Simple spelling and other invalid references: Ideally, search algorithms need to allow for “fuzzy” matching to catch slightly misspelled or mis-named datasets.

To address this challenge, the project employed the top three models from the 2021 Kaggle competition sponsored by the Coleridge Initiative.

### Machine Learning (Kaggle) Routines (Full Text Search)

The three models differ in their approaches, strengths, and weaknesses, and the strategy was to use all three to generate results, aggregating and filtering the results to achieve a synergy that would outperform any of the models individually. The same Kaggle models that were used in support of the Year 1 USDA project were employed on the data assets available to this project.

The models are applied to the full text search corpus and generate a series of outputs identifying potential dataset matches. For two of the Kaggle models, the focus is on identifying general data assets so many matches will be generated that are not relevant to USDA and its target data assets. Thus, a further fuzzy text matching routine is applied to the Kaggle output to produce a subset of candidate matches (dyads) that are linked to the target data assets.

As well as producing metadata for the publications and associated dyads, the process records the Kaggle record that produced the dyad and the scores associated with the matching routines. In addition, for all returned records where publisher licensing allows, a snippet is produced. The snippet is a fragment of text that shows both the referenced dataset and the contextual text that surrounds it, to provide human validators sufficient context to enable them to determine the validity of that candidate reference. The machine learning phase of the project therefore aims to locate all mentions of the target data assets within the search corpus of full text publications and to provide the candidate matches along with their snippets of text to a database that can facilitate subsequent validation by subject matter experts.

With a focus on data assets rather than datasets and with some of the name aliases comprising short acronyms and/or very generic terms, there is a risk that high levels of false positives would be generated. For example, one of the search terms was “Crop Progress Report”. There are likely to many other countries beyond the US that all issue reports on Crop Progress. Hence, as well as searching for the terms, a set of flags/filters were also included thus ensuring dyads could be identified which also had the flagged terms. Typically, the filters chosen were linked either to focusing on the agency or to focusing on the research produced in the US. Specifically, for the full text search in the USDA project, the following terms were employed as filters:

> NASS, USDA, US Department of Agriculture, United States Department of Agriculture, National Agricultural Statistics Service, Economic Research Service

In total, the use of flags was identified as being appropriate for 112 of the data assets.

The Kaggle routines were run in early December 2023 with the process completing on 14 December.

A summary of some of the key results from the Full Text search is provided in the Table below:

| Process Step Outputs | Number of Records |
|:---|:--:|
| Number of unique Scopus publications identified by the three Kaggle algorithms | 635,831 |
| Number of unique publications identified after Fuzzy text matching to target data assets | 4,104 |
| Number of target data assets matched in the above publications | 4,392[^2] |
| Number of snippets generated | 14,377[^3] |

: Full Text Search Generated by Kaggle Routine {#tbl-kaggle-full-text}

[^2]: Explanatory Note 1: A publication may contain references to more than one target data assets. It may also contain multiple references to the same target data asset. As an example, a publication may contain the following references to target assets (Data Asset A = 3 references, Data Asset B = 2 references, Data asset C = 4 reference then in this field three target data assets, the value included would be “3”.

[^3]: Explanatory Note 2: For the same publication as in Explanatory Note 1, the value here would be 9 provided the license for the publication allowed for snippet generation.

### Scopus References Search Routine

The reference search employs an exact text string matching routine across the references of the identified Scopus records.

Because of the issues associated with generic terms, the same flags as applied in the Machine Learning step were also applied here.

| Process Step Outputs | Number of Records |
|:---|:--:|
| Number of unique Scopus publications identified in reference search | 25,588 |
| Number of those publications that were unique to the reference search (i.e. not found by Kaggle models). | 22,818 |
| Number of target data assets matched with the above publications | 34,526 |

: Number of Records from Scopus References Search Routine {#tbl-scopus-refs}

### Post Processing Adjustments – RUCC and QuickStat Increment

Note that the RUCC and Quickstat increment was applied after the Kaggle routines were initially run. The process for running that increment involved two steps:

-   A new search of the Scopus reference search corpus using the RUCC and Quickstat aliases.
-   A fuzzy text search of the Kaggle output that had been generated using the RUCC and Quickstat aliases.